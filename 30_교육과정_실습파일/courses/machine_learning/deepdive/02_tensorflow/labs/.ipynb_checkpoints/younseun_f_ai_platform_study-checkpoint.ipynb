{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting younseun_input/train_data.csv\n"
     ]
    }
   ],
   "source": [
    "%%writefile younseun_input/train_data.csv\n",
    "country,age,sex,height\n",
    "kr,10,boy,120.0\n",
    "kr,10,girl,110.0\n",
    "kr,13,boy,150.0\n",
    "kr,13,girl,140.0\n",
    "kr,16,boy,170.0\n",
    "kr,16,girl,155.0\n",
    "kr,19,boy,180.0\n",
    "kr,19,girl,165.0\n",
    "kr,22,boy,182.0\n",
    "kr,22,girl,167.0\n",
    "ca,10,boy,122.0\n",
    "ca,10,girl,113.0\n",
    "ca,13,boy,153.0\n",
    "ca,13,girl,143.0\n",
    "ca,16,boy,173.0\n",
    "ca,16,girl,157.0\n",
    "ca,19,boy,182.0\n",
    "ca,19,girl,165.0\n",
    "ca,22,boy,185.0\n",
    "ca,22,girl,169.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['country', 'age', 'sex', 'height'], [['z1'], [10], ['none'], [150]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CSV_COLUMN_NAMES = [\"country\",\"age\",\"sex\",\"height\"]\n",
    "CSV_DEFAULTS = [['z1'],[10],['none'],[150]]\n",
    "CSV_COLUMN_NAMES,CSV_DEFAULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_row(row):\n",
    "    fields = tf.decode_csv(records = row, record_defaults = CSV_DEFAULTS)\n",
    "    features = dict(zip(CSV_COLUMN_NAMES, fields))\n",
    "    label = features.pop(\"height\")\n",
    "    return features, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(csv_path):\n",
    "    dataset = tf.data.TextLineDataset(filenames = csv_path).skip(count = 1) # skip header\n",
    "    dataset = dataset.map(map_func = parse_row)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_fn(csv_path, batch_size = 3):\n",
    "    dataset = read_dataset(csv_path)\n",
    "    dataset = dataset.shuffle(buffer_size = 1000).repeat(count = None).batch(batch_size = batch_size)\n",
    "    print(dataset)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_input_fn(csv_path, batch_size = 3):\n",
    "    dataset = read_dataset(csv_path)\n",
    "    dataset = dataset.batch(batch_size = batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[VocabularyListCategoricalColumn(key='country', vocabulary_list=('kr', 'ca'), dtype=tf.string, default_value=-1, num_oov_buckets=0),\n",
       " NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " IdentityCategoricalColumn(key='sex', number_buckets=3, default_value=None)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FEATURE_NAMES = CSV_COLUMN_NAMES[:-1] # all but first column\n",
    "\n",
    "feature_cols = [tf.feature_column.categorical_column_with_vocabulary_list(key = 'country',\n",
    "                                                       vocabulary_list = ['kr','ca']) ,\n",
    "                tf.feature_column.numeric_column(key = 'age') ,\n",
    "                tf.feature_column.categorical_column_with_identity(key = 'sex', num_buckets = 3) ,\n",
    "                ]\n",
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kr</td>\n",
       "      <td>10</td>\n",
       "      <td>boy</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kr</td>\n",
       "      <td>10</td>\n",
       "      <td>girl</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kr</td>\n",
       "      <td>13</td>\n",
       "      <td>boy</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kr</td>\n",
       "      <td>13</td>\n",
       "      <td>girl</td>\n",
       "      <td>140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kr</td>\n",
       "      <td>16</td>\n",
       "      <td>boy</td>\n",
       "      <td>170.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kr</td>\n",
       "      <td>16</td>\n",
       "      <td>girl</td>\n",
       "      <td>155.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kr</td>\n",
       "      <td>19</td>\n",
       "      <td>boy</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>kr</td>\n",
       "      <td>19</td>\n",
       "      <td>girl</td>\n",
       "      <td>165.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>kr</td>\n",
       "      <td>22</td>\n",
       "      <td>boy</td>\n",
       "      <td>182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>kr</td>\n",
       "      <td>22</td>\n",
       "      <td>girl</td>\n",
       "      <td>167.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ca</td>\n",
       "      <td>10</td>\n",
       "      <td>boy</td>\n",
       "      <td>122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ca</td>\n",
       "      <td>10</td>\n",
       "      <td>girl</td>\n",
       "      <td>113.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ca</td>\n",
       "      <td>13</td>\n",
       "      <td>boy</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ca</td>\n",
       "      <td>13</td>\n",
       "      <td>girl</td>\n",
       "      <td>143.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ca</td>\n",
       "      <td>16</td>\n",
       "      <td>boy</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ca</td>\n",
       "      <td>16</td>\n",
       "      <td>girl</td>\n",
       "      <td>157.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ca</td>\n",
       "      <td>19</td>\n",
       "      <td>boy</td>\n",
       "      <td>182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ca</td>\n",
       "      <td>19</td>\n",
       "      <td>girl</td>\n",
       "      <td>165.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ca</td>\n",
       "      <td>22</td>\n",
       "      <td>boy</td>\n",
       "      <td>185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ca</td>\n",
       "      <td>22</td>\n",
       "      <td>girl</td>\n",
       "      <td>169.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country  age   sex  height\n",
       "0       kr   10   boy   120.0\n",
       "1       kr   10  girl   110.0\n",
       "2       kr   13   boy   150.0\n",
       "3       kr   13  girl   140.0\n",
       "4       kr   16   boy   170.0\n",
       "5       kr   16  girl   155.0\n",
       "6       kr   19   boy   180.0\n",
       "7       kr   19  girl   165.0\n",
       "8       kr   22   boy   182.0\n",
       "9       kr   22  girl   167.0\n",
       "10      ca   10   boy   122.0\n",
       "11      ca   10  girl   113.0\n",
       "12      ca   13   boy   153.0\n",
       "13      ca   13  girl   143.0\n",
       "14      ca   16   boy   173.0\n",
       "15      ca   16  girl   157.0\n",
       "16      ca   19   boy   182.0\n",
       "17      ca   19  girl   165.0\n",
       "18      ca   22   boy   185.0\n",
       "19      ca   22  girl   169.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data 확인\n",
    "df_train = pd.read_csv(filepath_or_buffer = \"./younseun_input/train_data.csv\")\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_receiver_fn():\n",
    "    receiver_tensors = {'country':tf.placeholder(dtype = tf.string,shape=[None]),\n",
    "                        'age'    :tf.placeholder(dtype = tf.float32,shape=[None]),\n",
    "                        'sex'    :tf.placeholder(dtype = tf.stgring,shape=[None]),\n",
    "                        }\n",
    "    features = receiver_tensors\n",
    "    return tf.estimator.export.ServingInputReceiver(features = features, receiver_tensors = receiver_tensors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTDIR = \"younseun_trained\"\n",
    "\n",
    "config = tf.estimator.RunConfig(\n",
    "    model_dir=OUTDIR,\n",
    "    save_summary_steps=100,\n",
    "    save_checkpoints_steps=2000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_tf_random_seed': None, '_log_step_count_steps': 100, '_master': '', '_keep_checkpoint_max': 5, '_train_distribute': None, '_save_summary_steps': 100, '_session_creation_timeout_secs': 7200, '_global_id_in_cluster': 0, '_evaluation_master': '', '_task_type': 'worker', '_experimental_distribute': None, '_save_checkpoints_steps': 2000, '_task_id': 0, '_experimental_max_worker_delay_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f339c288438>, '_device_fn': None, '_num_ps_replicas': 0, '_eval_distribute': None, '_num_worker_replicas': 1, '_protocol': None, '_model_dir': 'younseun_trained', '_service': None, '_keep_checkpoint_every_n_hours': 10000, '_is_chief': True, '_save_checkpoints_secs': None}\n"
     ]
    }
   ],
   "source": [
    "myopt = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "model = tf.estimator.DNNRegressor(model_dir=OUTDIR,\n",
    "                                  hidden_units=[10, 10],\n",
    "                                  feature_columns=feature_cols,\n",
    "                                  activation_fn=tf.nn.relu,\n",
    "                                  optimizer=myopt,\n",
    "                                  config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_spec = tf.estimator.TrainSpec(\n",
    "    input_fn = lambda: train_input_fn('./younseun_input/train_data.csv'),\n",
    "    max_steps = 500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "exporter = tf.estimator.FinalExporter('./exporter', serving_input_receiver_fn=serving_input_receiver_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_spec = tf.estimator.EvalSpec(\n",
    "    input_fn = lambda: eval_input_fn(\"./younseun_input/train_data.csv\"),\n",
    "    steps = None,\n",
    "    start_delay_secs = 1,\n",
    "    throttle_secs = 1,\n",
    "    exporters = exporter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 2000 or save_checkpoints_secs None.\n",
      "<DatasetV1Adapter shapes: ({country: (?,), age: (?,), sex: (?,)}, (?,)), types: ({country: tf.string, age: tf.int32, sex: tf.string}, tf.int32)>\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Items of feature_columns must be a <class 'tensorflow.python.feature_column.feature_column_v2.DenseColumn'>. You can wrap a categorical column with an embedding_column or indicator_column. Given: VocabularyListCategoricalColumn(key='country', vocabulary_list=('kr', 'ca'), dtype=tf.string, default_value=-1, num_oov_buckets=0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-3db7cfe6a4df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m tf.estimator.train_and_evaluate(estimator = model, \n\u001b[1;32m      6\u001b[0m                                 \u001b[0mtrain_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                                 eval_spec = eval_spec)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(estimator, train_spec, eval_spec)\u001b[0m\n\u001b[1;32m    471\u001b[0m         '(with task id 0).  Given task id {}'.format(config.task_id))\n\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    611\u001b[0m         config.task_type != run_config_lib.TaskType.EVALUATOR):\n\u001b[1;32m    612\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Running training and evaluation locally (non-distributed).'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m     \u001b[0;31m# Distributed case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\u001b[0m in \u001b[0;36mrun_local\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m         \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_hooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m         saving_listeners=saving_listeners)\n\u001b[0m\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m     eval_result = listener_for_eval.eval_result or _EvalResult(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1159\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1189\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m       estimator_spec = self._call_model_fn(\n\u001b[0;32m-> 1191\u001b[0;31m           features, labels, ModeKeys.TRAIN, self.config)\n\u001b[0m\u001b[1;32m   1192\u001b[0m       \u001b[0mglobal_step_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_global_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/canned/dnn.py\u001b[0m in \u001b[0;36m_model_fn\u001b[0;34m(features, labels, mode, config)\u001b[0m\n\u001b[1;32m   1212\u001b[0m           \u001b[0minput_layer_partitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_layer_partitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m           \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1214\u001b[0;31m           batch_norm=batch_norm)\n\u001b[0m\u001b[1;32m   1215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m     super(DNNRegressor, self).__init__(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/canned/dnn.py\u001b[0m in \u001b[0;36m_dnn_model_fn\u001b[0;34m(features, labels, mode, head, hidden_units, feature_columns, optimizer, activation_fn, dropout, input_layer_partitioner, config, use_tpu, batch_norm)\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0minput_layer_partitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_layer_partitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         batch_norm=batch_norm)\n\u001b[0;32m--> 463\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogit_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     return _get_dnn_estimator_spec(use_tpu, head, features, labels, mode,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/canned/dnn.py\u001b[0m in \u001b[0;36mdnn_logit_fn\u001b[0;34m(features, mode)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0minput_layer_partitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mbatch_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         name='dnn')\n\u001b[0m\u001b[1;32m    109\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdnn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/canned/dnn.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, units, hidden_units, feature_columns, activation_fn, dropout, input_layer_partitioner, batch_norm, name, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfeature_column_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feature_column_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m       self._input_layer = dense_features.DenseFeatures(\n\u001b[0;32m--> 186\u001b[0;31m           feature_columns=feature_columns, name='input_layer')\n\u001b[0m\u001b[1;32m    187\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m       self._input_layer = feature_column.InputLayer(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/feature_column/dense_features.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, feature_columns, trainable, name, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mexpected_column_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDenseColumn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/feature_column/feature_column_v2.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, feature_columns, expected_column_type, trainable, name, **kwargs)\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;34m'You can wrap a categorical column with an '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m             'embedding_column or indicator_column. Given: {}'.format(\n\u001b[0;32m--> 380\u001b[0;31m                 expected_column_type, column))\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Items of feature_columns must be a <class 'tensorflow.python.feature_column.feature_column_v2.DenseColumn'>. You can wrap a categorical column with an embedding_column or indicator_column. Given: VocabularyListCategoricalColumn(key='country', vocabulary_list=('kr', 'ca'), dtype=tf.string, default_value=-1, num_oov_buckets=0)"
     ]
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO) \n",
    "shutil.rmtree(path = OUTDIR, ignore_errors = True)\n",
    "tf.summary.FileWriterCache.clear() # ensure filewriter cache is clear for TensorBoard events file\n",
    "\n",
    "tf.estimator.train_and_evaluate(estimator = model, \n",
    "                                train_spec = train_spec, \n",
    "                                eval_spec = eval_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
