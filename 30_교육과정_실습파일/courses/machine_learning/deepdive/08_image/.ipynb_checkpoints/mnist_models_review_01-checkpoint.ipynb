{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# Copyright 2017 Google Inc. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "tf.logging.set_verbosity(v = tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 28\n",
    "WIDTH = 28\n",
    "NCLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_model(img, mode, hparams):\n",
    "    X = tf.reshape(tensor = img, shape = [-1,HEIGHT * WIDTH]) #flatten\n",
    "    ylogits = tf.layers.dense(input = X, units = NCLASSES, activation = None)\n",
    "    return ylogits, NCLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnn_model(img, mode, hparams):\n",
    "    X = tf.reshape(tensor = img, shape = [-1, HEIGHT * WIDTH]) #flatten\n",
    "    h1 = tf.layers.dense(inputs = X, units = 300, activation = tf.nn.relu)\n",
    "    h2 = tf.layers.dense(inputs = h1, units = 100, activation = tf.nn.relu)\n",
    "    h3 = tf.layers.dense(inputs = h2, units = 30, activation = tf.nn.relu)\n",
    "    ylogits = tf.layers.dense(inputs = h3, units = NCLASSES, activation = None)\n",
    "    return ylogits, NCLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnn_dropout_model(img, mode, hparams):\n",
    "    dprob = hparams.get(\"dprob\", 0.1)\n",
    "\n",
    "    X = tf.reshape(tensor = img, shape = [-1, HEIGHT * WIDTH]) #flatten\n",
    "    h1 = tf.layers.dense(inputs = X, units = 300, activation = tf.nn.relu)\n",
    "    h2 = tf.layers.dense(inputs = h1, units = 100, activation = tf.nn.relu)\n",
    "    h3 = tf.layers.dense(inputs = h2, units = 30, activation = tf.nn.relu)\n",
    "    h3d = tf.layers.dropout(inputs = h3, rate = dprob, training = (mode == tf.estimator.ModeKeys.TRAIN)) #only dropout when training\n",
    "    ylogits = tf.layers.dense(inputs = h3d, units = NCLASSES, activation = None)\n",
    "    return ylogits, NCLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model(img, mode, hparams):\n",
    "    ksize1 = hparams.get(\"ksize1\", 5)\n",
    "    ksize2 = hparams.get(\"ksize2\", 5)\n",
    "    nfil1 = hparams.get(\"nfil1\", 10)\n",
    "    nfil2 = hparams.get(\"nfil2\", 20)\n",
    "    dprob = hparams.get(\"dprob\", 0.25)\n",
    "\n",
    "    c1 = tf.layers.conv2d(inputs = img, filters = nfil1,\n",
    "                          kernel_size = ksize1, strides = 1,\n",
    "                          padding = \"same\", activation = tf.nn.relu) # shape = (batch_size, HEIGHT, WIDTH, nfil1)\n",
    "    \n",
    "    p1 = tf.layers.max_pooling2d(inputs = c1, pool_size = 2, strides = 2) # shape = (batch_size, HEIGHT // 2, WIDTH // 2, nfil1)\n",
    "    \n",
    "    c2 = tf.layers.conv2d(inputs = p1, filters = nfil2,\n",
    "                          kernel_size = ksize2, strides = 1, \n",
    "                          padding = \"same\", activation = tf.nn.relu) # shape = (batch_size, HEIGHT // 2, WIDTH // 2, nfil2)\n",
    "    \n",
    "    p2 = tf.layers.max_pooling2d(inputs = c2, pool_size = 2, strides = 2) # shape = (batch_size, HEIGHT // 4, WIDTH // 4, nfil2)\n",
    "\n",
    "    outlen = p2.shape[1] * p2.shape[2] * p2.shape[3] # HEIGHT // 4 * WIDTH // 4 * nfil2\n",
    "    p2flat = tf.reshape(tensor = p2, shape = [-1, outlen]) # shape = (batch_size, HEIGHT // 4 * WIDTH // 4 * nfil2)\n",
    "\n",
    "    # Apply batch normalization\n",
    "    if hparams[\"batch_norm\"]:\n",
    "        h3 = tf.layers.dense(inputs = p2flat, units = 300, activation = None)\n",
    "        h3 = tf.layers.batch_normalization(inputs = h3, training = (mode == tf.estimator.ModeKeys.TRAIN)) # only batchnorm when training\n",
    "        h3 = tf.nn.relu(features = h3)\n",
    "    else:  \n",
    "        h3 = tf.layers.dense(inputs = p2flat, units = 300, activation = tf.nn.relu)\n",
    "  \n",
    "    # Apply dropout\n",
    "    h3d = tf.layers.dropout(inputs = h3, rate = dprob, training = (mode == tf.estimator.ModeKeys.TRAIN))\n",
    "\n",
    "    ylogits = tf.layers.dense(inputs = h3d, units = NCLASSES, activation = None)\n",
    "  \n",
    "    # Apply batch normalization once more\n",
    "    if hparams[\"batch_norm\"]:\n",
    "        ylogits = tf.layers.batch_normalization(inputs = ylogits, training = (mode == tf.estimator.ModeKeys.TRAIN))\n",
    "\n",
    "    return ylogits, NCLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_fn():\n",
    "    # Input will be rank 3\n",
    "    feature_placeholders = {\"image\": tf.placeholder(dtype = tf.float32, shape = [None, HEIGHT, WIDTH])}\n",
    "    # But model function requires rank 4\n",
    "    features = {\"image\": tf.expand_dims(input = feature_placeholders[\"image\"], axis = -1)} \n",
    "    return tf.estimator.export.ServingInputReceiver(features = features, receiver_tensors = feature_placeholders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_classifier(features, labels, mode, params):\n",
    "    model_functions = {\n",
    "        \"linear\": linear_model,\n",
    "        \"dnn\": dnn_model,\n",
    "        \"dnn_dropout\": dnn_dropout_model,\n",
    "        \"cnn\": cnn_model}\n",
    "    \n",
    "    model_function = model_functions[params[\"model\"]]\n",
    "    \n",
    "    ylogits, nclasses = model_function(features[\"image\"], mode, params)\n",
    "\n",
    "    probabilities = tf.nn.softmax(logits = ylogits)\n",
    "    class_ids = tf.cast(x = tf.argmax(input = probabilities, axis = 1), dtype = tf.uint8)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN or mode == tf.estimator.ModeKeys.EVAL:\n",
    "        loss = tf.reduce_mean(input_tensor = tf.nn.softmax_cross_entropy_with_logits_v2(logits = ylogits, labels = labels))\n",
    "        \n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            # This is needed for batch normalization, but has no effect otherwise\n",
    "            update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "            with tf.control_dependencies(update_ops):\n",
    "                train_op = tf.contrib.layers.optimize_loss(\n",
    "                    loss = loss, \n",
    "                    global_step = tf.train.get_global_step(),\n",
    "                    learning_rate = params[\"learning_rate\"], \n",
    "                    optimizer = \"Adam\")\n",
    "            eval_metric_ops = None\n",
    "        else:\n",
    "            train_op = None\n",
    "            eval_metric_ops =  {\"accuracy\": tf.metrics.accuracy(labels = tf.argmax(input = labels, axis = 1), predictions = class_ids)}\n",
    "    else:\n",
    "        loss = None\n",
    "        train_op = None\n",
    "        eval_metric_ops = None\n",
    " \n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode = mode,\n",
    "        predictions = {\"probabilities\": probabilities, \"class_ids\": class_ids},\n",
    "        loss = loss,\n",
    "        train_op = train_op,\n",
    "        eval_metric_ops = eval_metric_ops,\n",
    "        export_outputs = {\"predictions\":tf.estimator.export.PredictOutput({\"probabilities\": probabilities, \"class_ids\": class_ids})}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(output_dir, hparams):\n",
    "    tf.summary.FileWriterCache.clear() # ensure filewriter cache is clear for TensorBoard events file\n",
    "    \n",
    "    EVAL_INTERVAL = 60\n",
    "    \n",
    "    mnist = input_data.read_data_sets(\"mnist/data\", one_hot = True, reshape = False)\n",
    "    \n",
    "    train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x = {\"image\": mnist.train.images},\n",
    "        y = mnist.train.labels,\n",
    "        batch_size = 100,\n",
    "        num_epochs = None,\n",
    "        shuffle = True,\n",
    "        queue_capacity = 5000\n",
    "    )\n",
    "\n",
    "    eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x = {\"image\": mnist.test.images},\n",
    "        y = mnist.test.labels,\n",
    "        batch_size = 100,\n",
    "        num_epochs = 1,\n",
    "        shuffle = False,\n",
    "        queue_capacity = 5000\n",
    "    )\n",
    "\n",
    "    estimator = tf.estimator.Estimator(\n",
    "        model_fn = image_classifier,\n",
    "        model_dir = output_dir,\n",
    "        params = hparams)\n",
    "\n",
    "    train_spec = tf.estimator.TrainSpec(\n",
    "        input_fn = train_input_fn,\n",
    "        max_steps = hparams[\"train_steps\"])\n",
    "\n",
    "    exporter = tf.estimator.LatestExporter(name = \"exporter\", serving_input_receiver_fn = serving_input_fn)\n",
    "\n",
    "    eval_spec = tf.estimator.EvalSpec(\n",
    "        input_fn = eval_input_fn,\n",
    "        steps = None,\n",
    "        exporters = exporter)\n",
    "\n",
    "    tf.estimator.train_and_evaluate(estimator = estimator, train_spec = train_spec, eval_spec = eval_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist/data/train-images-idx3-ubyte.gz\n",
      "Extracting mnist/data/train-labels-idx1-ubyte.gz\n",
      "Extracting mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting mnist/data/t10k-labels-idx1-ubyte.gz\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_summary_steps': 100, '_experimental_max_worker_delay_secs': None, '_protocol': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_eval_distribute': None, '_service': None, '_task_type': 'worker', '_keep_checkpoint_every_n_hours': 10000, '_tf_random_seed': None, '_experimental_distribute': None, '_save_checkpoints_secs': 600, '_evaluation_master': '', '_train_distribute': None, '_num_worker_replicas': 1, '_device_fn': None, '_log_step_count_steps': 100, '_model_dir': '/home/jupyter/training-data-analyst/courses/machine_learning/deepdive/08_image/mnist_trained_review', '_session_creation_timeout_secs': 7200, '_task_id': 0, '_master': '', '_num_ps_replicas': 0, '_save_checkpoints_steps': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb8f10a29b0>, '_global_id_in_cluster': 0, '_keep_checkpoint_max': 5, '_is_chief': True}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From <ipython-input-4-5d645aaf7d75>:3: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/training/monitored_session.py:882: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /home/jupyter/training-data-analyst/courses/machine_learning/deepdive/08_image/mnist_trained_review/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.298999, step = 0\n",
      "INFO:tensorflow:Saving checkpoints for 100 into /home/jupyter/training-data-analyst/courses/machine_learning/deepdive/08_image/mnist_trained_review/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-12-02T15:07:01Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/jupyter/training-data-analyst/courses/machine_learning/deepdive/08_image/mnist_trained_review/model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-12-02-15:07:01\n",
      "INFO:tensorflow:Saving dict for global step 100: accuracy = 0.9295, global_step = 100, loss = 0.23998854\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 100: /home/jupyter/training-data-analyst/courses/machine_learning/deepdive/08_image/mnist_trained_review/model.ckpt-100\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default', 'predictions']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from /home/jupyter/training-data-analyst/courses/machine_learning/deepdive/08_image/mnist_trained_review/model.ckpt-100\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /home/jupyter/training-data-analyst/courses/machine_learning/deepdive/08_image/mnist_trained_review/export/exporter/temp-b'1575299221'/saved_model.pb\n",
      "INFO:tensorflow:Loss for final step: 0.23278579.\n"
     ]
    }
   ],
   "source": [
    "output_dir=\"/home/jupyter/training-data-analyst/courses/machine_learning/deepdive/08_image/mnist_trained_review\"\n",
    "hparams={'train_batch_size': 100, 'model':'dnn', 'output_dir': '/home/jupyter/training-data-analyst/courses/machine_learning/deepdive/08_image/mnist_trained', 'job_dir': 'junk', 'ksize2': 5, 'nfil1': 10, 'dprob': 0.25, 'train_steps': 100, 'ksize1': 5, 'batch_norm': False, 'nfil2': 20, 'learning_rate': 0.01}\n",
    "train_and_evaluate(output_dir, hparams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_norm=False, dprob=0.25, job_dir='junk', ksize1=5, ksize2=5, learning_rate=0.01, nfil1=10, nfil2=20, output_dir='/home/jupyter/training-data-analyst/courses/machine_learning/deepdive/08_image/mnist_trained', train_batch_size=100, train_steps=100)\n",
      "{'train_batch_size': 100, 'output_dir': '/home/jupyter/training-data-analyst/courses/machine_learning/deepdive/08_image/mnist_trained', 'job_dir': 'junk', 'ksize2': 5, 'nfil1': 10, 'dprob': 0.25, 'train_steps': 100, 'ksize1': 5, 'batch_norm': False, 'nfil2': 20, 'learning_rate': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-02 14:59:00.863763: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python3 task_review_01.py \\\n",
    "    --output_dir=${PWD}/mnist_trained \\\n",
    "    --train_steps=100 \\\n",
    "    --learning_rate=0.01"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
