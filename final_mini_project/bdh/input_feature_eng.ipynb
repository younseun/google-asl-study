{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN,SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('creditcard.csv',dtype='float32',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train : (227845, 31)\n",
      "df_test : (56962, 31)\n"
     ]
    }
   ],
   "source": [
    "## data setting\n",
    "# setting up testing and training sets\n",
    "df_train, df_test = train_test_split(data, test_size=0.2, random_state=27)\n",
    "print('df_train :', df_train.shape)\n",
    "print('df_test :', df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train : (205060, 31)\n",
      "df_valid : (22785, 31)\n",
      "df_test : (56962, 31)\n",
      "df_train Class: \n",
      " 0.0    204712\n",
      "1.0       348\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_train, df_valid = train_test_split(df_train, test_size=0.1, random_state=27)\n",
    "print('df_train :', df_train.shape)\n",
    "print('df_valid :', df_valid.shape)\n",
    "print('df_test :', df_test.shape)\n",
    "print('df_train Class: \\n', df_train.Class.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 1. OUTLIER Delete in train data => 시각화 분석 결과 정상유저의 threshold 범위 안에 사기유저 있음\n",
    "###### 즉, threshold 를 얼마정도 잡고 데이터를 없애도 크게 상관은 없어보임\n",
    "def outlier_treatment(df,col,beta):\n",
    "    q1,q3 = df.describe().loc['25%',col], df.describe().loc['75%',col]\n",
    "    IQR = q3 - q1\n",
    "    lower_range = q1 - (beta * IQR)\n",
    "    upper_range = q3 + (beta * IQR)\n",
    "#     print(col,'lower_range :',lower_range)\n",
    "#     print(col,'upper_range :',upper_range)\n",
    "    df = df[(df[col] > lower_range) & (df[col] < upper_range)]\n",
    "    return df\n",
    "\n",
    "def cleaning_df(df,cols,beta=10):\n",
    "    for i in cols:\n",
    "        df = outlier_treatment(df,i,beta=beta)\n",
    "    print('outlier delete')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 2. feature engineering\n",
    "def add_engineered_features(features):\n",
    "    features = features.astype('float32')\n",
    "    features['V14pV12'] = features['V14'] + features['V12']\n",
    "    features['V2pV11'] = features['V2'] + features['V11']\n",
    "    features['V10pV3'] = features['V10'] + features['V3']\n",
    "    features['V17pV14'] = features['V17'] + features['V14']\n",
    "    features['V4pV2'] = features['V4'] + features['V2']\n",
    "\n",
    "    features['sqV3-V2'] = (features['V3'] - features['V2']) **2\n",
    "    features['sqV8'] = (features['V8']) **2\n",
    "    features['sqV2'] = (features['V2']) **2\n",
    "    features['sqV17'] = (features['V17']) **2\n",
    "\n",
    "    features['V17-V11'] = features['V17'] - features['V11'] \n",
    "    print('generate feature engineered')\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### deprecated - 3. normalization --> only Amount\n",
    "def zscore(col):\n",
    "    mean = df_train['Amount'].mean()\n",
    "    std = df_train['Amount'].std()\n",
    "    return (col - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 4.DATA Augmentation --> oversampling SMOTE\n",
    "def add_smote_features(features):\n",
    "    sm = SMOTE(random_state=27, k_neighbors=5)\n",
    "    features, _ = sm.fit_sample(features, features.Class)\n",
    "    features = pd.DataFrame(features, columns=list(features))\n",
    "    print(features.Class.value_counts())\n",
    "    features = features.astype('float32')\n",
    "    print('augmentation using SMOTE')\n",
    "    return features\n",
    "\n",
    "def add_smoteenn_features(features):\n",
    "    sm = SMOTEENN(random_state=27)\n",
    "    features, _ = sm.fit_resample(features, features.Class)\n",
    "    features = pd.DataFrame(features, columns=list(features))\n",
    "    print(features.Class.value_counts())\n",
    "    features = features.astype('float32')\n",
    "    print('augmentation using SMOTEENN')\n",
    "    return features\n",
    "\n",
    "def add_smotetomek_features(features):\n",
    "    sm = SMOTETomek(random_state=27)\n",
    "    features, _ = sm.fit_resample(features, features.Class)\n",
    "    features = pd.DataFrame(features, columns=list(features))\n",
    "    print(features.Class.value_counts())\n",
    "    features = features.astype('float32')\n",
    "    print('augmentation using SMOTETomek')\n",
    "    return features\n",
    "\n",
    "def add_adasyn_features(features):\n",
    "    ada = ADASYN(random_state=27)\n",
    "    features, _ = ada.fit_resample(features, features.Class)\n",
    "    features = pd.DataFrame(features, columns=list(features))\n",
    "    print(features.Class.value_counts())\n",
    "    features = features.astype('float32')\n",
    "    print('augmentation using ADASYN')\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outlier delete\n",
      "generate feature engineered\n",
      "1.0    199840\n",
      "0.0    199840\n",
      "Name: Class, dtype: int64\n",
      "augmentation using SMOTE\n",
      "generate feature engineered\n",
      "generate feature engineered\n"
     ]
    }
   ],
   "source": [
    "outlier_cols = ['V2','V6','V7','V13','V16','V23','V24','V25','V26','V28','Amount']\n",
    "df_train = cleaning_df(df_train,cols=outlier_cols,beta=10)\n",
    "df_train = add_engineered_features(df_train)\n",
    "df_train = add_smote_features(df_train) ### 원하는 sampling model 선택 (adasyn, smoteenn, smotetomek 등)\n",
    "\n",
    "df_valid = add_engineered_features(df_valid)\n",
    "df_test = add_engineered_features(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('train.csv',index=False)\n",
    "df_valid.to_csv('valid.csv',index=False)\n",
    "df_test.to_csv('test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7321428571428571"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "82/112"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
