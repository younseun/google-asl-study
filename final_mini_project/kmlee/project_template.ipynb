{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = \"qwiklabs-gcp-ml-8d503f4cdc07\"  # Replace with your PROJECT\n",
    "BUCKET = PROJECT  # Replace with your BUCKET\n",
    "\n",
    "REGION = \"us-central1\"            # Choose an available region for Cloud CAIP\n",
    "TFVERSION = \"1.14\"                # TF version for CMLE to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJ_NAME='miniproj'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"BUCKET\"] = BUCKET\n",
    "os.environ[\"PROJECT\"] = PROJECT\n",
    "os.environ[\"REGION\"] = REGION\n",
    "os.environ[\"TFVERSION\"] = TFVERSION\n",
    "os.environ[\"PROJ_NAME\"] = PROJ_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [compute/region].\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://qwiklabs-gcp-ml-8d503f4cdc07/data/creditcard.csv\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil ls gs://${BUCKET}/data/*.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs_data = pd.read_csv('gs://{}/data/creditcard.csv'.format(BUCKET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7        V8        V9       V10       V11       V12       V13       V14       V15       V16       V17       V18       V19       V20       V21       V22       V23       V24       V25       V26       V27       V28  Amount  Class\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62      0\n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69      0\n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0\n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50      0\n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99      0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcs_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Time',\n",
       " 'V1',\n",
       " 'V2',\n",
       " 'V3',\n",
       " 'V4',\n",
       " 'V5',\n",
       " 'V6',\n",
       " 'V7',\n",
       " 'V8',\n",
       " 'V9',\n",
       " 'V10',\n",
       " 'V11',\n",
       " 'V12',\n",
       " 'V13',\n",
       " 'V14',\n",
       " 'V15',\n",
       " 'V16',\n",
       " 'V17',\n",
       " 'V18',\n",
       " 'V19',\n",
       " 'V20',\n",
       " 'V21',\n",
       " 'V22',\n",
       " 'V23',\n",
       " 'V24',\n",
       " 'V25',\n",
       " 'V26',\n",
       " 'V27',\n",
       " 'V28',\n",
       " 'Amount',\n",
       " 'Class']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list(gcs_data.columns.values)\n",
    "list(gcs_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 제거할 feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "제거할 feature 이름들을 입력하세요: Time,V1,V2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time,V1,V2\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    DROP_FEATURE_NAMES=input('제거할 feature 이름들을 입력하세요:')\n",
    "    if len(DROP_FEATURE_NAMES) < 1:\n",
    "        DROP_FEATURE_NAMES=''\n",
    "except ValueError:\n",
    "    DROP_FEATURE_NAMES=''\n",
    "print(DROP_FEATURE_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Time,V1,V2'"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DROP_FEATURE_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Time', 'V1', 'V2']"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DROP_FEATURE_NAMES=DROP_FEATURE_NAMES.split(\",\")\n",
    "DROP_FEATURE_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         V3        V4        V5        V6        V7        V8        V9       V10       V11       V12       V13       V14       V15       V16       V17       V18       V19       V20       V21       V22       V23       V24       V25       V26       V27       V28  Amount  Class\n",
       "0  2.536347  1.378155 -0.338321  0.462388  0.239599  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62      0\n",
       "1  0.166480  0.448154  0.060018 -0.082361 -0.078803  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69      0\n",
       "2  1.773209  0.379780 -0.503198  1.800499  0.791461  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0\n",
       "3  1.792993 -0.863291 -0.010309  1.247203  0.237609  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50      0\n",
       "4  1.548718  0.403034 -0.407193  0.095921  0.592941 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99      0"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcs_data = gcs_data.drop(DROP_FEATURE_NAMES, axis=1)\n",
    "gcs_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 선택할 feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "선택할 feature 이름들을 입력하세요: V3,V4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V3,V4\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    SEL_FEATURE_NAMES=input('선택할 feature 이름들을 입력하세요:')\n",
    "    if len(SEL_FEATURE_NAMES) < 1:\n",
    "        SEL_FEATURE_NAMES=''\n",
    "except ValueError:\n",
    "    SEL_FEATURE_NAMES=''\n",
    "print(SEL_FEATURE_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['V3', 'V4']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEL_FEATURE_NAMES=SEL_FEATURE_NAMES.split(\",\")\n",
    "SEL_FEATURE_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = gcs_data[SEL_FEATURE_NAMES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         V3        V4\n",
       "0  2.536347  1.378155\n",
       "1  0.166480  0.448154\n",
       "2  1.773209  0.379780\n",
       "3  1.792993 -0.863291\n",
       "4  1.548718  0.403034"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(gcs_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_LEN = len(list(gcs_data))\n",
    "os.environ['FEATURE_LEN'] = str(FEATURE_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7        V8        V9       V10       V11       V12       V13       V14       V15       V16       V17       V18       V19       V20       V21       V22       V23       V24       V25       V26       V27       V28  Amount\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62\n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69\n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66\n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50\n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data = gcs_data.drop('Class', axis=1)\n",
    "x_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Time',\n",
       " 'V1',\n",
       " 'V2',\n",
       " 'V3',\n",
       " 'V4',\n",
       " 'V5',\n",
       " 'V6',\n",
       " 'V7',\n",
       " 'V8',\n",
       " 'V9',\n",
       " 'V10',\n",
       " 'V11',\n",
       " 'V12',\n",
       " 'V13',\n",
       " 'V14',\n",
       " 'V15',\n",
       " 'V16',\n",
       " 'V17',\n",
       " 'V18',\n",
       " 'V19',\n",
       " 'V20',\n",
       " 'V21',\n",
       " 'V22',\n",
       " 'V23',\n",
       " 'V24',\n",
       " 'V25',\n",
       " 'V26',\n",
       " 'V27',\n",
       " 'V28',\n",
       " 'Amount']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FEATURE_NAMES = list(x_data)\n",
    "FEATURE_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data = gcs_data['Class']\n",
    "y_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/google-asl-study/final_mini_project/kmlee\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train : (227845, 30), X_test:(56962, 30)\n",
      "Y_train : (227845,), Y_test:(56962,)\n"
     ]
    }
   ],
   "source": [
    "## data setting\n",
    "# setting up testing and training sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=27)\n",
    "\n",
    "print('X_train : {}, X_test:{}'.format(X_train.shape, X_test.shape))\n",
    "print('Y_train : {}, Y_test:{}'.format(Y_train.shape, Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train : (182276, 30), Y_train:(182276,)\n",
      "X_valid : (45569, 30), Y_valid:(45569,)\n",
      "X_test : (56962, 30), Y_test:(56962,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X_train, Y_train, test_size=0.2, random_state=27)\n",
    "print('X_train : {}, Y_train:{}'.format(X_train.shape, Y_train.shape))\n",
    "print('X_valid : {}, Y_valid:{}'.format(X_valid.shape, Y_valid.shape))\n",
    "print('X_test : {}, Y_test:{}'.format(X_test.shape, Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26120</th>\n",
       "      <td>33919.0</td>\n",
       "      <td>-2.388049</td>\n",
       "      <td>-2.490423</td>\n",
       "      <td>1.888346</td>\n",
       "      <td>-1.313157</td>\n",
       "      <td>0.335402</td>\n",
       "      <td>-0.743883</td>\n",
       "      <td>0.576642</td>\n",
       "      <td>-0.071353</td>\n",
       "      <td>1.228283</td>\n",
       "      <td>-1.879936</td>\n",
       "      <td>-0.251486</td>\n",
       "      <td>1.032613</td>\n",
       "      <td>1.031555</td>\n",
       "      <td>-0.620445</td>\n",
       "      <td>0.821064</td>\n",
       "      <td>-0.647349</td>\n",
       "      <td>-0.330973</td>\n",
       "      <td>0.019461</td>\n",
       "      <td>-0.625384</td>\n",
       "      <td>1.240960</td>\n",
       "      <td>0.569097</td>\n",
       "      <td>0.908894</td>\n",
       "      <td>0.826554</td>\n",
       "      <td>0.089925</td>\n",
       "      <td>0.499400</td>\n",
       "      <td>-0.707443</td>\n",
       "      <td>-0.183655</td>\n",
       "      <td>-0.052248</td>\n",
       "      <td>383.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9192</th>\n",
       "      <td>13161.0</td>\n",
       "      <td>1.225984</td>\n",
       "      <td>0.212700</td>\n",
       "      <td>-0.157300</td>\n",
       "      <td>1.082289</td>\n",
       "      <td>0.840563</td>\n",
       "      <td>1.184308</td>\n",
       "      <td>-0.127604</td>\n",
       "      <td>0.139463</td>\n",
       "      <td>1.385294</td>\n",
       "      <td>-0.338083</td>\n",
       "      <td>0.619358</td>\n",
       "      <td>-1.688131</td>\n",
       "      <td>2.046750</td>\n",
       "      <td>1.532657</td>\n",
       "      <td>-1.439979</td>\n",
       "      <td>-0.066174</td>\n",
       "      <td>0.099661</td>\n",
       "      <td>0.316642</td>\n",
       "      <td>0.363952</td>\n",
       "      <td>-0.124836</td>\n",
       "      <td>-0.303960</td>\n",
       "      <td>-0.426814</td>\n",
       "      <td>-0.290104</td>\n",
       "      <td>-1.754287</td>\n",
       "      <td>0.847065</td>\n",
       "      <td>-0.263307</td>\n",
       "      <td>0.007218</td>\n",
       "      <td>-0.015656</td>\n",
       "      <td>19.08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230012</th>\n",
       "      <td>146147.0</td>\n",
       "      <td>-2.188785</td>\n",
       "      <td>-0.958016</td>\n",
       "      <td>0.769310</td>\n",
       "      <td>-3.102286</td>\n",
       "      <td>-0.242737</td>\n",
       "      <td>0.071822</td>\n",
       "      <td>-0.486386</td>\n",
       "      <td>0.269428</td>\n",
       "      <td>-1.919930</td>\n",
       "      <td>1.278307</td>\n",
       "      <td>0.099962</td>\n",
       "      <td>-0.325803</td>\n",
       "      <td>0.976056</td>\n",
       "      <td>-0.716159</td>\n",
       "      <td>-1.215963</td>\n",
       "      <td>0.150129</td>\n",
       "      <td>-0.247955</td>\n",
       "      <td>0.692943</td>\n",
       "      <td>-0.302583</td>\n",
       "      <td>-0.195537</td>\n",
       "      <td>-0.252410</td>\n",
       "      <td>-0.148452</td>\n",
       "      <td>-0.605173</td>\n",
       "      <td>0.213868</td>\n",
       "      <td>0.737452</td>\n",
       "      <td>-0.193485</td>\n",
       "      <td>-0.152167</td>\n",
       "      <td>0.006639</td>\n",
       "      <td>79.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240894</th>\n",
       "      <td>150796.0</td>\n",
       "      <td>2.105378</td>\n",
       "      <td>0.095780</td>\n",
       "      <td>-2.263791</td>\n",
       "      <td>0.091285</td>\n",
       "      <td>0.882610</td>\n",
       "      <td>-0.338245</td>\n",
       "      <td>0.099070</td>\n",
       "      <td>-0.112726</td>\n",
       "      <td>0.483264</td>\n",
       "      <td>-0.297243</td>\n",
       "      <td>0.102136</td>\n",
       "      <td>0.111484</td>\n",
       "      <td>-0.239467</td>\n",
       "      <td>-0.532100</td>\n",
       "      <td>0.387734</td>\n",
       "      <td>0.759846</td>\n",
       "      <td>-0.276178</td>\n",
       "      <td>1.402560</td>\n",
       "      <td>0.307164</td>\n",
       "      <td>-0.185324</td>\n",
       "      <td>0.157169</td>\n",
       "      <td>0.593088</td>\n",
       "      <td>-0.190231</td>\n",
       "      <td>-1.519934</td>\n",
       "      <td>0.379331</td>\n",
       "      <td>-0.028933</td>\n",
       "      <td>-0.007032</td>\n",
       "      <td>-0.056937</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28768</th>\n",
       "      <td>35150.0</td>\n",
       "      <td>-0.328728</td>\n",
       "      <td>-0.476626</td>\n",
       "      <td>1.429567</td>\n",
       "      <td>-0.900624</td>\n",
       "      <td>0.067534</td>\n",
       "      <td>2.167218</td>\n",
       "      <td>-0.040161</td>\n",
       "      <td>0.497778</td>\n",
       "      <td>-1.119866</td>\n",
       "      <td>0.451183</td>\n",
       "      <td>1.583027</td>\n",
       "      <td>-0.418727</td>\n",
       "      <td>-1.115596</td>\n",
       "      <td>-0.194336</td>\n",
       "      <td>0.397377</td>\n",
       "      <td>-0.873577</td>\n",
       "      <td>1.818656</td>\n",
       "      <td>-2.673224</td>\n",
       "      <td>0.918108</td>\n",
       "      <td>0.308120</td>\n",
       "      <td>0.210792</td>\n",
       "      <td>0.801463</td>\n",
       "      <td>0.142101</td>\n",
       "      <td>-1.346529</td>\n",
       "      <td>-0.619436</td>\n",
       "      <td>-0.095093</td>\n",
       "      <td>0.029224</td>\n",
       "      <td>-0.106220</td>\n",
       "      <td>96.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6        V7        V8        V9       V10       V11       V12       V13       V14       V15       V16       V17       V18       V19       V20       V21       V22       V23       V24       V25       V26       V27       V28  Amount  Class\n",
       "26120    33919.0 -2.388049 -2.490423  1.888346 -1.313157  0.335402 -0.743883  0.576642 -0.071353  1.228283 -1.879936 -0.251486  1.032613  1.031555 -0.620445  0.821064 -0.647349 -0.330973  0.019461 -0.625384  1.240960  0.569097  0.908894  0.826554  0.089925  0.499400 -0.707443 -0.183655 -0.052248  383.35      0\n",
       "9192     13161.0  1.225984  0.212700 -0.157300  1.082289  0.840563  1.184308 -0.127604  0.139463  1.385294 -0.338083  0.619358 -1.688131  2.046750  1.532657 -1.439979 -0.066174  0.099661  0.316642  0.363952 -0.124836 -0.303960 -0.426814 -0.290104 -1.754287  0.847065 -0.263307  0.007218 -0.015656   19.08      0\n",
       "230012  146147.0 -2.188785 -0.958016  0.769310 -3.102286 -0.242737  0.071822 -0.486386  0.269428 -1.919930  1.278307  0.099962 -0.325803  0.976056 -0.716159 -1.215963  0.150129 -0.247955  0.692943 -0.302583 -0.195537 -0.252410 -0.148452 -0.605173  0.213868  0.737452 -0.193485 -0.152167  0.006639   79.00      0\n",
       "240894  150796.0  2.105378  0.095780 -2.263791  0.091285  0.882610 -0.338245  0.099070 -0.112726  0.483264 -0.297243  0.102136  0.111484 -0.239467 -0.532100  0.387734  0.759846 -0.276178  1.402560  0.307164 -0.185324  0.157169  0.593088 -0.190231 -1.519934  0.379331 -0.028933 -0.007032 -0.056937    1.80      0\n",
       "28768    35150.0 -0.328728 -0.476626  1.429567 -0.900624  0.067534  2.167218 -0.040161  0.497778 -1.119866  0.451183  1.583027 -0.418727 -1.115596 -0.194336  0.397377 -0.873577  1.818656 -2.673224  0.918108  0.308120  0.210792  0.801463  0.142101 -1.346529 -0.619436 -0.095093  0.029224 -0.106220   96.62      0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.concat([X_train, Y_train],axis=1)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>269400</th>\n",
       "      <td>163647.0</td>\n",
       "      <td>0.129017</td>\n",
       "      <td>1.896071</td>\n",
       "      <td>-1.909277</td>\n",
       "      <td>-0.085467</td>\n",
       "      <td>1.516371</td>\n",
       "      <td>-2.947193</td>\n",
       "      <td>1.922066</td>\n",
       "      <td>-0.649116</td>\n",
       "      <td>-0.797983</td>\n",
       "      <td>-2.458479</td>\n",
       "      <td>1.352833</td>\n",
       "      <td>-0.383150</td>\n",
       "      <td>-0.167108</td>\n",
       "      <td>-3.744940</td>\n",
       "      <td>0.259791</td>\n",
       "      <td>0.505714</td>\n",
       "      <td>3.329779</td>\n",
       "      <td>1.164543</td>\n",
       "      <td>-1.086637</td>\n",
       "      <td>-0.082993</td>\n",
       "      <td>0.046164</td>\n",
       "      <td>0.272604</td>\n",
       "      <td>-0.286842</td>\n",
       "      <td>0.621032</td>\n",
       "      <td>0.080475</td>\n",
       "      <td>0.108701</td>\n",
       "      <td>0.046224</td>\n",
       "      <td>0.123110</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140345</th>\n",
       "      <td>83671.0</td>\n",
       "      <td>-2.810614</td>\n",
       "      <td>-1.255934</td>\n",
       "      <td>0.534252</td>\n",
       "      <td>1.833196</td>\n",
       "      <td>1.266633</td>\n",
       "      <td>-0.336898</td>\n",
       "      <td>-0.524892</td>\n",
       "      <td>0.566502</td>\n",
       "      <td>-0.583604</td>\n",
       "      <td>0.012125</td>\n",
       "      <td>0.826729</td>\n",
       "      <td>1.518163</td>\n",
       "      <td>0.901882</td>\n",
       "      <td>0.390380</td>\n",
       "      <td>-0.398843</td>\n",
       "      <td>-0.723934</td>\n",
       "      <td>0.381441</td>\n",
       "      <td>-0.170178</td>\n",
       "      <td>1.148843</td>\n",
       "      <td>0.058401</td>\n",
       "      <td>0.029318</td>\n",
       "      <td>0.150226</td>\n",
       "      <td>-0.861510</td>\n",
       "      <td>-0.163730</td>\n",
       "      <td>-0.210010</td>\n",
       "      <td>-0.245811</td>\n",
       "      <td>0.605932</td>\n",
       "      <td>-0.486416</td>\n",
       "      <td>108.86</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234612</th>\n",
       "      <td>148046.0</td>\n",
       "      <td>1.632977</td>\n",
       "      <td>-0.650973</td>\n",
       "      <td>-0.700894</td>\n",
       "      <td>1.498131</td>\n",
       "      <td>-0.548833</td>\n",
       "      <td>-0.505637</td>\n",
       "      <td>-0.043126</td>\n",
       "      <td>-0.114222</td>\n",
       "      <td>0.870073</td>\n",
       "      <td>0.130682</td>\n",
       "      <td>-1.093137</td>\n",
       "      <td>0.001141</td>\n",
       "      <td>-0.584909</td>\n",
       "      <td>0.245689</td>\n",
       "      <td>0.420884</td>\n",
       "      <td>0.157755</td>\n",
       "      <td>-0.510354</td>\n",
       "      <td>0.006759</td>\n",
       "      <td>-0.594176</td>\n",
       "      <td>0.041657</td>\n",
       "      <td>0.142117</td>\n",
       "      <td>0.172234</td>\n",
       "      <td>0.036681</td>\n",
       "      <td>-0.121723</td>\n",
       "      <td>-0.148125</td>\n",
       "      <td>-0.681985</td>\n",
       "      <td>0.008653</td>\n",
       "      <td>-0.007497</td>\n",
       "      <td>179.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69669</th>\n",
       "      <td>53524.0</td>\n",
       "      <td>-1.244625</td>\n",
       "      <td>-0.862845</td>\n",
       "      <td>0.902662</td>\n",
       "      <td>-0.220987</td>\n",
       "      <td>-1.363494</td>\n",
       "      <td>0.435640</td>\n",
       "      <td>0.255022</td>\n",
       "      <td>0.640365</td>\n",
       "      <td>-1.588047</td>\n",
       "      <td>-0.069806</td>\n",
       "      <td>0.856695</td>\n",
       "      <td>0.639223</td>\n",
       "      <td>0.512782</td>\n",
       "      <td>0.286660</td>\n",
       "      <td>-0.121909</td>\n",
       "      <td>-0.716399</td>\n",
       "      <td>-0.501456</td>\n",
       "      <td>1.866949</td>\n",
       "      <td>-2.285268</td>\n",
       "      <td>0.056128</td>\n",
       "      <td>0.227404</td>\n",
       "      <td>0.313352</td>\n",
       "      <td>0.719519</td>\n",
       "      <td>-0.067816</td>\n",
       "      <td>-0.091712</td>\n",
       "      <td>-0.451338</td>\n",
       "      <td>-0.153241</td>\n",
       "      <td>-0.125369</td>\n",
       "      <td>310.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80277</th>\n",
       "      <td>58411.0</td>\n",
       "      <td>1.216248</td>\n",
       "      <td>0.217858</td>\n",
       "      <td>-0.185325</td>\n",
       "      <td>0.771201</td>\n",
       "      <td>0.106515</td>\n",
       "      <td>0.003741</td>\n",
       "      <td>-0.162653</td>\n",
       "      <td>0.071036</td>\n",
       "      <td>0.308806</td>\n",
       "      <td>-0.619671</td>\n",
       "      <td>0.665524</td>\n",
       "      <td>0.887186</td>\n",
       "      <td>0.395834</td>\n",
       "      <td>-1.518667</td>\n",
       "      <td>-0.931024</td>\n",
       "      <td>0.517252</td>\n",
       "      <td>0.555034</td>\n",
       "      <td>0.737507</td>\n",
       "      <td>0.580231</td>\n",
       "      <td>-0.003541</td>\n",
       "      <td>-0.177230</td>\n",
       "      <td>-0.274791</td>\n",
       "      <td>-0.216183</td>\n",
       "      <td>-0.543854</td>\n",
       "      <td>0.644877</td>\n",
       "      <td>0.443618</td>\n",
       "      <td>-0.000127</td>\n",
       "      <td>0.025547</td>\n",
       "      <td>12.31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6        V7        V8        V9       V10       V11       V12       V13       V14       V15       V16       V17       V18       V19       V20       V21       V22       V23       V24       V25       V26       V27       V28  Amount  Class\n",
       "269400  163647.0  0.129017  1.896071 -1.909277 -0.085467  1.516371 -2.947193  1.922066 -0.649116 -0.797983 -2.458479  1.352833 -0.383150 -0.167108 -3.744940  0.259791  0.505714  3.329779  1.164543 -1.086637 -0.082993  0.046164  0.272604 -0.286842  0.621032  0.080475  0.108701  0.046224  0.123110    0.30      0\n",
       "140345   83671.0 -2.810614 -1.255934  0.534252  1.833196  1.266633 -0.336898 -0.524892  0.566502 -0.583604  0.012125  0.826729  1.518163  0.901882  0.390380 -0.398843 -0.723934  0.381441 -0.170178  1.148843  0.058401  0.029318  0.150226 -0.861510 -0.163730 -0.210010 -0.245811  0.605932 -0.486416  108.86      0\n",
       "234612  148046.0  1.632977 -0.650973 -0.700894  1.498131 -0.548833 -0.505637 -0.043126 -0.114222  0.870073  0.130682 -1.093137  0.001141 -0.584909  0.245689  0.420884  0.157755 -0.510354  0.006759 -0.594176  0.041657  0.142117  0.172234  0.036681 -0.121723 -0.148125 -0.681985  0.008653 -0.007497  179.00      0\n",
       "69669    53524.0 -1.244625 -0.862845  0.902662 -0.220987 -1.363494  0.435640  0.255022  0.640365 -1.588047 -0.069806  0.856695  0.639223  0.512782  0.286660 -0.121909 -0.716399 -0.501456  1.866949 -2.285268  0.056128  0.227404  0.313352  0.719519 -0.067816 -0.091712 -0.451338 -0.153241 -0.125369  310.96      0\n",
       "80277    58411.0  1.216248  0.217858 -0.185325  0.771201  0.106515  0.003741 -0.162653  0.071036  0.308806 -0.619671  0.665524  0.887186  0.395834 -1.518667 -0.931024  0.517252  0.555034  0.737507  0.580231 -0.003541 -0.177230 -0.274791 -0.216183 -0.543854  0.644877  0.443618 -0.000127  0.025547   12.31      0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid = pd.concat([X_valid, Y_valid],axis=1)\n",
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47747</th>\n",
       "      <td>43343.0</td>\n",
       "      <td>1.209971</td>\n",
       "      <td>-0.158081</td>\n",
       "      <td>0.685984</td>\n",
       "      <td>-0.019681</td>\n",
       "      <td>-0.874075</td>\n",
       "      <td>-0.775662</td>\n",
       "      <td>-0.352771</td>\n",
       "      <td>0.015835</td>\n",
       "      <td>0.545579</td>\n",
       "      <td>-0.224426</td>\n",
       "      <td>0.088800</td>\n",
       "      <td>-0.203061</td>\n",
       "      <td>-1.113465</td>\n",
       "      <td>0.410833</td>\n",
       "      <td>1.607339</td>\n",
       "      <td>0.072905</td>\n",
       "      <td>0.100539</td>\n",
       "      <td>-0.831441</td>\n",
       "      <td>-0.446510</td>\n",
       "      <td>-0.176492</td>\n",
       "      <td>-0.096262</td>\n",
       "      <td>-0.294659</td>\n",
       "      <td>0.177728</td>\n",
       "      <td>0.418381</td>\n",
       "      <td>-0.039814</td>\n",
       "      <td>0.918010</td>\n",
       "      <td>-0.061961</td>\n",
       "      <td>0.007276</td>\n",
       "      <td>5.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225706</th>\n",
       "      <td>144357.0</td>\n",
       "      <td>0.107350</td>\n",
       "      <td>0.718755</td>\n",
       "      <td>-0.059117</td>\n",
       "      <td>-0.821294</td>\n",
       "      <td>0.716260</td>\n",
       "      <td>-1.189281</td>\n",
       "      <td>1.338169</td>\n",
       "      <td>-0.395374</td>\n",
       "      <td>-0.185327</td>\n",
       "      <td>-0.841789</td>\n",
       "      <td>-0.908705</td>\n",
       "      <td>0.633981</td>\n",
       "      <td>0.905077</td>\n",
       "      <td>0.104062</td>\n",
       "      <td>-0.451994</td>\n",
       "      <td>-0.476546</td>\n",
       "      <td>-0.429700</td>\n",
       "      <td>-0.639710</td>\n",
       "      <td>0.121597</td>\n",
       "      <td>-0.059895</td>\n",
       "      <td>-0.043964</td>\n",
       "      <td>-0.030030</td>\n",
       "      <td>-0.042275</td>\n",
       "      <td>-0.078641</td>\n",
       "      <td>-0.157494</td>\n",
       "      <td>-0.150633</td>\n",
       "      <td>0.019411</td>\n",
       "      <td>0.036256</td>\n",
       "      <td>31.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255432</th>\n",
       "      <td>157223.0</td>\n",
       "      <td>-0.992778</td>\n",
       "      <td>1.374399</td>\n",
       "      <td>-1.681843</td>\n",
       "      <td>-0.123910</td>\n",
       "      <td>0.711935</td>\n",
       "      <td>-1.394937</td>\n",
       "      <td>2.114597</td>\n",
       "      <td>-0.066849</td>\n",
       "      <td>-0.815940</td>\n",
       "      <td>-2.754625</td>\n",
       "      <td>0.025988</td>\n",
       "      <td>-0.054213</td>\n",
       "      <td>0.620262</td>\n",
       "      <td>-2.687384</td>\n",
       "      <td>0.243924</td>\n",
       "      <td>0.504939</td>\n",
       "      <td>2.327616</td>\n",
       "      <td>1.282721</td>\n",
       "      <td>-0.635943</td>\n",
       "      <td>0.364793</td>\n",
       "      <td>0.196423</td>\n",
       "      <td>0.220383</td>\n",
       "      <td>0.131703</td>\n",
       "      <td>-0.358277</td>\n",
       "      <td>0.402663</td>\n",
       "      <td>-0.552094</td>\n",
       "      <td>-0.015239</td>\n",
       "      <td>0.170879</td>\n",
       "      <td>231.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202435</th>\n",
       "      <td>134327.0</td>\n",
       "      <td>2.084975</td>\n",
       "      <td>-1.678690</td>\n",
       "      <td>-0.492561</td>\n",
       "      <td>-1.592379</td>\n",
       "      <td>-1.541775</td>\n",
       "      <td>-0.284969</td>\n",
       "      <td>-1.310430</td>\n",
       "      <td>-0.051357</td>\n",
       "      <td>-1.320674</td>\n",
       "      <td>1.630477</td>\n",
       "      <td>0.589819</td>\n",
       "      <td>0.279823</td>\n",
       "      <td>1.195581</td>\n",
       "      <td>-0.541423</td>\n",
       "      <td>-0.680839</td>\n",
       "      <td>0.018269</td>\n",
       "      <td>-0.023405</td>\n",
       "      <td>0.356297</td>\n",
       "      <td>0.236777</td>\n",
       "      <td>-0.202740</td>\n",
       "      <td>-0.315913</td>\n",
       "      <td>-0.614923</td>\n",
       "      <td>0.334403</td>\n",
       "      <td>-0.383453</td>\n",
       "      <td>-0.604302</td>\n",
       "      <td>-0.494455</td>\n",
       "      <td>0.023015</td>\n",
       "      <td>-0.032347</td>\n",
       "      <td>95.94</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119363</th>\n",
       "      <td>75422.0</td>\n",
       "      <td>1.176209</td>\n",
       "      <td>0.183813</td>\n",
       "      <td>0.514542</td>\n",
       "      <td>0.450080</td>\n",
       "      <td>-0.197021</td>\n",
       "      <td>-0.187294</td>\n",
       "      <td>-0.091779</td>\n",
       "      <td>0.056852</td>\n",
       "      <td>-0.280994</td>\n",
       "      <td>0.047212</td>\n",
       "      <td>1.773171</td>\n",
       "      <td>1.363238</td>\n",
       "      <td>0.625851</td>\n",
       "      <td>0.381332</td>\n",
       "      <td>0.537814</td>\n",
       "      <td>0.187727</td>\n",
       "      <td>-0.419805</td>\n",
       "      <td>-0.546371</td>\n",
       "      <td>-0.189620</td>\n",
       "      <td>-0.088922</td>\n",
       "      <td>-0.173952</td>\n",
       "      <td>-0.483480</td>\n",
       "      <td>0.149046</td>\n",
       "      <td>0.023991</td>\n",
       "      <td>0.129106</td>\n",
       "      <td>0.105646</td>\n",
       "      <td>-0.013529</td>\n",
       "      <td>0.006163</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6        V7        V8        V9       V10       V11       V12       V13       V14       V15       V16       V17       V18       V19       V20       V21       V22       V23       V24       V25       V26       V27       V28  Amount  Class\n",
       "47747    43343.0  1.209971 -0.158081  0.685984 -0.019681 -0.874075 -0.775662 -0.352771  0.015835  0.545579 -0.224426  0.088800 -0.203061 -1.113465  0.410833  1.607339  0.072905  0.100539 -0.831441 -0.446510 -0.176492 -0.096262 -0.294659  0.177728  0.418381 -0.039814  0.918010 -0.061961  0.007276    5.37      0\n",
       "225706  144357.0  0.107350  0.718755 -0.059117 -0.821294  0.716260 -1.189281  1.338169 -0.395374 -0.185327 -0.841789 -0.908705  0.633981  0.905077  0.104062 -0.451994 -0.476546 -0.429700 -0.639710  0.121597 -0.059895 -0.043964 -0.030030 -0.042275 -0.078641 -0.157494 -0.150633  0.019411  0.036256   31.00      0\n",
       "255432  157223.0 -0.992778  1.374399 -1.681843 -0.123910  0.711935 -1.394937  2.114597 -0.066849 -0.815940 -2.754625  0.025988 -0.054213  0.620262 -2.687384  0.243924  0.504939  2.327616  1.282721 -0.635943  0.364793  0.196423  0.220383  0.131703 -0.358277  0.402663 -0.552094 -0.015239  0.170879  231.05      0\n",
       "202435  134327.0  2.084975 -1.678690 -0.492561 -1.592379 -1.541775 -0.284969 -1.310430 -0.051357 -1.320674  1.630477  0.589819  0.279823  1.195581 -0.541423 -0.680839  0.018269 -0.023405  0.356297  0.236777 -0.202740 -0.315913 -0.614923  0.334403 -0.383453 -0.604302 -0.494455  0.023015 -0.032347   95.94      0\n",
       "119363   75422.0  1.176209  0.183813  0.514542  0.450080 -0.197021 -0.187294 -0.091779  0.056852 -0.280994  0.047212  1.773171  1.363238  0.625851  0.381332  0.537814  0.187727 -0.419805 -0.546371 -0.189620 -0.088922 -0.173952 -0.483480  0.149046  0.023991  0.129106  0.105646 -0.013529  0.006163    0.99      0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.concat([X_test, Y_test],axis=1)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid.to_csv('valid.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47747</th>\n",
       "      <td>43343.0</td>\n",
       "      <td>1.209971</td>\n",
       "      <td>-0.158081</td>\n",
       "      <td>0.685984</td>\n",
       "      <td>-0.019681</td>\n",
       "      <td>-0.874075</td>\n",
       "      <td>-0.775662</td>\n",
       "      <td>-0.352771</td>\n",
       "      <td>0.015835</td>\n",
       "      <td>0.545579</td>\n",
       "      <td>-0.224426</td>\n",
       "      <td>0.088800</td>\n",
       "      <td>-0.203061</td>\n",
       "      <td>-1.113465</td>\n",
       "      <td>0.410833</td>\n",
       "      <td>1.607339</td>\n",
       "      <td>0.072905</td>\n",
       "      <td>0.100539</td>\n",
       "      <td>-0.831441</td>\n",
       "      <td>-0.446510</td>\n",
       "      <td>-0.176492</td>\n",
       "      <td>-0.096262</td>\n",
       "      <td>-0.294659</td>\n",
       "      <td>0.177728</td>\n",
       "      <td>0.418381</td>\n",
       "      <td>-0.039814</td>\n",
       "      <td>0.918010</td>\n",
       "      <td>-0.061961</td>\n",
       "      <td>0.007276</td>\n",
       "      <td>5.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225706</th>\n",
       "      <td>144357.0</td>\n",
       "      <td>0.107350</td>\n",
       "      <td>0.718755</td>\n",
       "      <td>-0.059117</td>\n",
       "      <td>-0.821294</td>\n",
       "      <td>0.716260</td>\n",
       "      <td>-1.189281</td>\n",
       "      <td>1.338169</td>\n",
       "      <td>-0.395374</td>\n",
       "      <td>-0.185327</td>\n",
       "      <td>-0.841789</td>\n",
       "      <td>-0.908705</td>\n",
       "      <td>0.633981</td>\n",
       "      <td>0.905077</td>\n",
       "      <td>0.104062</td>\n",
       "      <td>-0.451994</td>\n",
       "      <td>-0.476546</td>\n",
       "      <td>-0.429700</td>\n",
       "      <td>-0.639710</td>\n",
       "      <td>0.121597</td>\n",
       "      <td>-0.059895</td>\n",
       "      <td>-0.043964</td>\n",
       "      <td>-0.030030</td>\n",
       "      <td>-0.042275</td>\n",
       "      <td>-0.078641</td>\n",
       "      <td>-0.157494</td>\n",
       "      <td>-0.150633</td>\n",
       "      <td>0.019411</td>\n",
       "      <td>0.036256</td>\n",
       "      <td>31.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255432</th>\n",
       "      <td>157223.0</td>\n",
       "      <td>-0.992778</td>\n",
       "      <td>1.374399</td>\n",
       "      <td>-1.681843</td>\n",
       "      <td>-0.123910</td>\n",
       "      <td>0.711935</td>\n",
       "      <td>-1.394937</td>\n",
       "      <td>2.114597</td>\n",
       "      <td>-0.066849</td>\n",
       "      <td>-0.815940</td>\n",
       "      <td>-2.754625</td>\n",
       "      <td>0.025988</td>\n",
       "      <td>-0.054213</td>\n",
       "      <td>0.620262</td>\n",
       "      <td>-2.687384</td>\n",
       "      <td>0.243924</td>\n",
       "      <td>0.504939</td>\n",
       "      <td>2.327616</td>\n",
       "      <td>1.282721</td>\n",
       "      <td>-0.635943</td>\n",
       "      <td>0.364793</td>\n",
       "      <td>0.196423</td>\n",
       "      <td>0.220383</td>\n",
       "      <td>0.131703</td>\n",
       "      <td>-0.358277</td>\n",
       "      <td>0.402663</td>\n",
       "      <td>-0.552094</td>\n",
       "      <td>-0.015239</td>\n",
       "      <td>0.170879</td>\n",
       "      <td>231.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202435</th>\n",
       "      <td>134327.0</td>\n",
       "      <td>2.084975</td>\n",
       "      <td>-1.678690</td>\n",
       "      <td>-0.492561</td>\n",
       "      <td>-1.592379</td>\n",
       "      <td>-1.541775</td>\n",
       "      <td>-0.284969</td>\n",
       "      <td>-1.310430</td>\n",
       "      <td>-0.051357</td>\n",
       "      <td>-1.320674</td>\n",
       "      <td>1.630477</td>\n",
       "      <td>0.589819</td>\n",
       "      <td>0.279823</td>\n",
       "      <td>1.195581</td>\n",
       "      <td>-0.541423</td>\n",
       "      <td>-0.680839</td>\n",
       "      <td>0.018269</td>\n",
       "      <td>-0.023405</td>\n",
       "      <td>0.356297</td>\n",
       "      <td>0.236777</td>\n",
       "      <td>-0.202740</td>\n",
       "      <td>-0.315913</td>\n",
       "      <td>-0.614923</td>\n",
       "      <td>0.334403</td>\n",
       "      <td>-0.383453</td>\n",
       "      <td>-0.604302</td>\n",
       "      <td>-0.494455</td>\n",
       "      <td>0.023015</td>\n",
       "      <td>-0.032347</td>\n",
       "      <td>95.94</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119363</th>\n",
       "      <td>75422.0</td>\n",
       "      <td>1.176209</td>\n",
       "      <td>0.183813</td>\n",
       "      <td>0.514542</td>\n",
       "      <td>0.450080</td>\n",
       "      <td>-0.197021</td>\n",
       "      <td>-0.187294</td>\n",
       "      <td>-0.091779</td>\n",
       "      <td>0.056852</td>\n",
       "      <td>-0.280994</td>\n",
       "      <td>0.047212</td>\n",
       "      <td>1.773171</td>\n",
       "      <td>1.363238</td>\n",
       "      <td>0.625851</td>\n",
       "      <td>0.381332</td>\n",
       "      <td>0.537814</td>\n",
       "      <td>0.187727</td>\n",
       "      <td>-0.419805</td>\n",
       "      <td>-0.546371</td>\n",
       "      <td>-0.189620</td>\n",
       "      <td>-0.088922</td>\n",
       "      <td>-0.173952</td>\n",
       "      <td>-0.483480</td>\n",
       "      <td>0.149046</td>\n",
       "      <td>0.023991</td>\n",
       "      <td>0.129106</td>\n",
       "      <td>0.105646</td>\n",
       "      <td>-0.013529</td>\n",
       "      <td>0.006163</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6        V7        V8        V9       V10       V11       V12       V13       V14       V15       V16       V17       V18       V19       V20       V21       V22       V23       V24       V25       V26       V27       V28  Amount  Class\n",
       "47747    43343.0  1.209971 -0.158081  0.685984 -0.019681 -0.874075 -0.775662 -0.352771  0.015835  0.545579 -0.224426  0.088800 -0.203061 -1.113465  0.410833  1.607339  0.072905  0.100539 -0.831441 -0.446510 -0.176492 -0.096262 -0.294659  0.177728  0.418381 -0.039814  0.918010 -0.061961  0.007276    5.37      0\n",
       "225706  144357.0  0.107350  0.718755 -0.059117 -0.821294  0.716260 -1.189281  1.338169 -0.395374 -0.185327 -0.841789 -0.908705  0.633981  0.905077  0.104062 -0.451994 -0.476546 -0.429700 -0.639710  0.121597 -0.059895 -0.043964 -0.030030 -0.042275 -0.078641 -0.157494 -0.150633  0.019411  0.036256   31.00      0\n",
       "255432  157223.0 -0.992778  1.374399 -1.681843 -0.123910  0.711935 -1.394937  2.114597 -0.066849 -0.815940 -2.754625  0.025988 -0.054213  0.620262 -2.687384  0.243924  0.504939  2.327616  1.282721 -0.635943  0.364793  0.196423  0.220383  0.131703 -0.358277  0.402663 -0.552094 -0.015239  0.170879  231.05      0\n",
       "202435  134327.0  2.084975 -1.678690 -0.492561 -1.592379 -1.541775 -0.284969 -1.310430 -0.051357 -1.320674  1.630477  0.589819  0.279823  1.195581 -0.541423 -0.680839  0.018269 -0.023405  0.356297  0.236777 -0.202740 -0.315913 -0.614923  0.334403 -0.383453 -0.604302 -0.494455  0.023015 -0.032347   95.94      0\n",
       "119363   75422.0  1.176209  0.183813  0.514542  0.450080 -0.197021 -0.187294 -0.091779  0.056852 -0.280994  0.047212  1.773171  1.363238  0.625851  0.381332  0.537814  0.187727 -0.419805 -0.546371 -0.189620 -0.088922 -0.173952 -0.483480  0.149046  0.023991  0.129106  0.105646 -0.013529  0.006163    0.99      0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 코드 생성 후 아래 코드 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/google-asl-study/final_mini_project/kmlee\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 이름 명시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "모델 이름을 이력하세요: dnn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dnn\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    MODEL_NAME=input('모델 이름을 이력하세요:')\n",
    "    if len(MODEL_NAME) < 1:\n",
    "        MODEL_NAME='linear'\n",
    "except ValueError:\n",
    "    MODEL_NAME='linear'\n",
    "os.environ[\"MODEL_NAME\"] = MODEL_NAME\n",
    "print(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will use DNN size of [128, 64, 8]\n",
      "<DatasetV1Adapter shapes: ({Class: (30,)}, ()), types: ({Class: tf.float32}, tf.float32)>\n",
      "NNSIZE:[128, 64, 8]\n",
      "<DatasetV1Adapter shapes: ({Class: (30,)}, ()), types: ({Class: tf.float32}, tf.float32)>\n",
      "NNSIZE:[128, 64, 8]\n",
      "NNSIZE:[128, 64, 8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-12 03:49:02.644881: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "WARNING:tensorflow:From miniproj/trainer/model.py:24: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "WARNING:tensorflow:From miniproj/trainer/model.py:24: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "WARNING:tensorflow:From miniproj/trainer/model.py:273: The name tf.summary.FileWriterCache is deprecated. Please use tf.compat.v1.summary.FileWriterCache instead.\n",
      "\n",
      "INFO:tensorflow:TF_CONFIG environment variable: {u'environment': u'cloud', u'cluster': {}, u'job': {u'args': [u'--train_data_path=/home/jupyter/google-asl-study/final_mini_project/kmlee/train.csv', u'--eval_data_path=/home/jupyter/google-asl-study/final_mini_project/kmlee/valid.csv', u'--output_dir=/home/jupyter/google-asl-study/final_mini_project/kmlee/trained_dnn/miniproj', u'--model=dnn', u'--train_steps=300', u'--feature_length=31', u'--nnsize=128,64,8'], u'job_name': u'miniproj.trainer.task'}, u'task': {}}\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 60, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f306d5c2e50>, '_model_dir': '/home/jupyter/google-asl-study/final_mini_project/kmlee/trained_dnn/miniproj/', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_session_creation_timeout_secs': 7200, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 10, '_experimental_max_worker_delay_secs': None, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_master': ''}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 60.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/training/training_util.py:236: initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/api/_v1/estimator/__init__.py:12: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.decode_csv is deprecated. Please use tf.io.decode_csv instead.\n",
      "\n",
      "WARNING:tensorflow:From miniproj/trainer/model.py:164: make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From miniproj/trainer/model.py:55: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/layers/core.py:187: apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From miniproj/trainer/model.py:242: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From miniproj/trainer/model.py:242: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From miniproj/trainer/model.py:246: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2019-12-12 03:49:05.175327: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-12-12 03:49:05.182769: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
      "2019-12-12 03:49:05.184040: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c52a70efd0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2019-12-12 03:49:05.184065: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2019-12-12 03:49:05.186780: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2019-12-12 03:49:09.187585: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-12 03:49:09.189315: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-12 03:49:09.190010: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c52a7c9700 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2019-12-12 03:49:09.190041: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
      "2019-12-12 03:49:09.190048: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): Tesla K80, Compute Capability 3.7\n",
      "2019-12-12 03:49:09.190721: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-12 03:49:09.191196: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
      "pciBusID: 0000:00:04.0\n",
      "2019-12-12 03:49:09.191284: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-12 03:49:09.191736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
      "pciBusID: 0000:00:05.0\n",
      "2019-12-12 03:49:09.191769: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2019-12-12 03:49:09.193835: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2019-12-12 03:49:09.195109: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2019-12-12 03:49:09.195468: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2019-12-12 03:49:09.197187: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2019-12-12 03:49:09.198644: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2019-12-12 03:49:09.202126: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2019-12-12 03:49:09.202222: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-12 03:49:09.202742: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-12 03:49:09.203227: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-12 03:49:09.203690: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-12 03:49:09.204093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1\n",
      "2019-12-12 03:49:09.204161: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2019-12-12 03:49:10.110400: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-12-12 03:49:10.110463: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1 \n",
      "2019-12-12 03:49:10.110472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N Y \n",
      "2019-12-12 03:49:10.110476: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   Y N \n",
      "2019-12-12 03:49:10.114607: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-12 03:49:10.115277: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-12 03:49:10.115817: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-12 03:49:10.116341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10747 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
      "2019-12-12 03:49:10.117266: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-12 03:49:10.117800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10747 MB memory) -> physical GPU (device: 1, name: Tesla K80, pci bus id: 0000:00:05.0, compute capability: 3.7)\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /home/jupyter/google-asl-study/final_mini_project/kmlee/trained_dnn/miniproj/model.ckpt.\n",
      "2019-12-12 03:49:10.961204: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "INFO:tensorflow:loss = 1.3132617, step = 0\n",
      "INFO:tensorflow:global_step/sec: 35.3886\n",
      "INFO:tensorflow:loss = 0.6931472, step = 10 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 90.624\n",
      "INFO:tensorflow:loss = 0.6931472, step = 20 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.7745\n",
      "INFO:tensorflow:loss = 0.6931472, step = 30 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.221\n",
      "INFO:tensorflow:loss = 0.6931472, step = 40 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.7529\n",
      "INFO:tensorflow:loss = 0.6931472, step = 50 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.3015\n",
      "INFO:tensorflow:loss = 0.6931472, step = 60 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.8973\n",
      "INFO:tensorflow:loss = 0.6931472, step = 70 (0.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.7455\n",
      "INFO:tensorflow:loss = 0.6931472, step = 80 (0.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.3927\n",
      "INFO:tensorflow:loss = 0.6931472, step = 90 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.4003\n",
      "INFO:tensorflow:loss = 0.6931472, step = 100 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 86.7619\n",
      "INFO:tensorflow:loss = 0.6931472, step = 110 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.3702\n",
      "INFO:tensorflow:loss = 0.6931472, step = 120 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.3489\n",
      "INFO:tensorflow:loss = 0.6931472, step = 130 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.1578\n",
      "INFO:tensorflow:loss = 0.6931472, step = 140 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 59.653\n",
      "INFO:tensorflow:loss = 0.6931472, step = 150 (0.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.9484\n",
      "INFO:tensorflow:loss = 0.6931472, step = 160 (0.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.3209\n",
      "INFO:tensorflow:loss = 0.6931472, step = 170 (0.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 59.4771\n",
      "INFO:tensorflow:loss = 0.6931472, step = 180 (0.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.7944\n",
      "INFO:tensorflow:loss = 0.6931472, step = 190 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 59.4283\n",
      "INFO:tensorflow:loss = 0.6931472, step = 200 (0.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.1935\n",
      "INFO:tensorflow:loss = 0.6931472, step = 210 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.4105\n",
      "INFO:tensorflow:loss = 0.6931472, step = 220 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.6528\n",
      "INFO:tensorflow:loss = 0.6931472, step = 230 (0.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 60.5312\n",
      "INFO:tensorflow:loss = 0.6931472, step = 240 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.0368\n",
      "INFO:tensorflow:loss = 0.6931472, step = 250 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.1967\n",
      "INFO:tensorflow:loss = 0.6931472, step = 260 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.9187\n",
      "INFO:tensorflow:loss = 0.6931472, step = 270 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.3525\n",
      "INFO:tensorflow:loss = 0.6931472, step = 280 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.6249\n",
      "INFO:tensorflow:loss = 0.6931472, step = 290 (0.114 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 300 into /home/jupyter/google-asl-study/final_mini_project/kmlee/trained_dnn/miniproj/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From miniproj/trainer/model.py:252: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-12-12T03:49:15Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2019-12-12 03:49:15.626879: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-12 03:49:15.627237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
      "pciBusID: 0000:00:04.0\n",
      "2019-12-12 03:49:15.627328: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-12 03:49:15.627754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
      "pciBusID: 0000:00:05.0\n",
      "2019-12-12 03:49:15.627787: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2019-12-12 03:49:15.627820: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2019-12-12 03:49:15.627836: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2019-12-12 03:49:15.627851: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2019-12-12 03:49:15.627882: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2019-12-12 03:49:15.627897: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2019-12-12 03:49:15.627917: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2019-12-12 03:49:15.627977: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-12 03:49:15.628343: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-12 03:49:15.628823: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-12 03:49:15.629191: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-12 03:49:15.629818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1\n",
      "2019-12-12 03:49:15.629930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-12-12 03:49:15.629940: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1 \n",
      "2019-12-12 03:49:15.629946: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N Y \n",
      "2019-12-12 03:49:15.629950: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   Y N \n",
      "2019-12-12 03:49:15.630424: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-12 03:49:15.630885: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-12 03:49:15.631428: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-12 03:49:15.631766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10747 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
      "2019-12-12 03:49:15.631845: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-12 03:49:15.632283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10747 MB memory) -> physical GPU (device: 1, name: Tesla K80, pci bus id: 0000:00:05.0, compute capability: 3.7)\n",
      "INFO:tensorflow:Restoring parameters from /home/jupyter/google-asl-study/final_mini_project/kmlee/trained_dnn/miniproj/model.ckpt-300\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-12-12-03:49:22\n",
      "INFO:tensorflow:Saving dict for global step 300: accuracy = 0.9981786, global_step = 300, loss = 0.69314593\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 300: /home/jupyter/google-asl-study/final_mini_project/kmlee/trained_dnn/miniproj/model.ckpt-300\n",
      "WARNING:tensorflow:From miniproj/trainer/model.py:171: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default', 'predictions']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "2019-12-12 03:49:22.729693: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-12 03:49:22.730115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
      "pciBusID: 0000:00:04.0\n",
      "2019-12-12 03:49:22.730188: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-12 03:49:22.730609: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
      "pciBusID: 0000:00:05.0\n",
      "2019-12-12 03:49:22.730642: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2019-12-12 03:49:22.730675: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2019-12-12 03:49:22.730689: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2019-12-12 03:49:22.730701: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2019-12-12 03:49:22.730718: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2019-12-12 03:49:22.730764: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2019-12-12 03:49:22.730779: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2019-12-12 03:49:22.730851: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-12 03:49:22.731240: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-12 03:49:22.731690: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-12 03:49:22.732042: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-12 03:49:22.732548: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1\n",
      "2019-12-12 03:49:22.732625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-12-12 03:49:22.732664: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1 \n",
      "2019-12-12 03:49:22.732671: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N Y \n",
      "2019-12-12 03:49:22.732675: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   Y N \n",
      "2019-12-12 03:49:22.733036: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-12 03:49:22.733524: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-12 03:49:22.734029: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-12 03:49:22.734381: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10747 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
      "2019-12-12 03:49:22.734453: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-12 03:49:22.734927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10747 MB memory) -> physical GPU (device: 1, name: Tesla K80, pci bus id: 0000:00:05.0, compute capability: 3.7)\n",
      "INFO:tensorflow:Restoring parameters from /home/jupyter/google-asl-study/final_mini_project/kmlee/trained_dnn/miniproj/model.ckpt-300\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /home/jupyter/google-asl-study/final_mini_project/kmlee/trained_dnn/miniproj/export/exporter/temp-1576122562/saved_model.pb\n",
      "INFO:tensorflow:Loss for final step: 0.6931472.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# MODEL_NAME=linear\n",
    "DATADIR=$(pwd)\n",
    "OUTDIR=$(pwd)/trained_${MODEL_NAME}/${PROJ_NAME}\n",
    "rm -rf $OUTDIR\n",
    "gcloud ai-platform local train \\\n",
    "   --module-name=${PROJ_NAME}.trainer.task \\\n",
    "   --package-path=${PWD}/${PROJ_NAME}.trainer \\\n",
    "   -- \\\n",
    "   --train_data_path=\"${DATADIR}/train.csv\" \\\n",
    "   --eval_data_path=\"${DATADIR}/valid.csv\"  \\\n",
    "   --output_dir=${OUTDIR} \\\n",
    "   --model=${MODEL_NAME} --train_steps=300 --feature_length=$FEATURE_LEN \\\n",
    "   --nnsize='128,64,8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/data/test.csv#1575874206268687...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/data/train.csv#1575874208389297...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/data/valid.csv#1575874205954115...\n",
      "/ [3/3 objects] 100% Done                                                       \n",
      "Operation completed over 3 objects.                                              \n",
      "Copying file:///home/jupyter/google-asl-study/final_mini_project/kmlee/test.csv [Content-Type=text/csv]...\n",
      "Copying file:///home/jupyter/google-asl-study/final_mini_project/kmlee/train.csv [Content-Type=text/csv]...\n",
      "Copying file:///home/jupyter/google-asl-study/final_mini_project/kmlee/valid.csv [Content-Type=text/csv]...\n",
      "| [3/3 files][136.3 MiB/136.3 MiB] 100% Done                                    \n",
      "Operation completed over 3 objects/136.3 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil -m rm -rf gs://${BUCKET}/${PROJ_NAME}/data/*\n",
    "gsutil -m cp $(pwd)/*.csv gs://${BUCKET}/${PROJ_NAME}/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobId: miniproj_dnn_191212_005848\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/dnn/checkpoint#1576062473602531...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/dnn/eval/#1576062486075127...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/dnn/eval/events.out.tfevents.1576062486.cmle-training-12698819006116578485#1576062487987531...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/dnn/events.out.tfevents.1576062400.cmle-training-12698819006116578485#1576062498686361...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/dnn/export/#1576062489043758...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/dnn/export/exporter/#1576062489575046...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/dnn/export/exporter/1576062488/#1576062496257119...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/dnn/export/exporter/1576062488/saved_model.pb#1576062496650334...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/dnn/export/exporter/1576062488/variables/#1576062497085645...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/dnn/export/exporter/1576062488/variables/variables.data-00000-of-00001#1576062497511837...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/dnn/export/exporter/1576062488/variables/variables.index#1576062497943914...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/dnn/graph.pbtxt#1576062403058011...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/dnn/model.ckpt-0.data-00000-of-00001#1576062406588928...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/dnn/model.ckpt-0.index#1576062407120254...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/dnn/model.ckpt-0.meta#1576062409247420...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/dnn/model.ckpt-3000.data-00000-of-00001#1576062471955587...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/dnn/model.ckpt-3000.index#1576062472454401...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/dnn/model.ckpt-3000.meta#1576062474616422...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/dnn/packages/f14e6cfdca3ce3d4ce407ce7e5fdb0a15977609aa2cd6c826c4b27598bdb97ea/trainer-0.0.0.tar.gz#1576062315565699...\n",
      "/ [19/19 objects] 100% Done                                                     \n",
      "Operation completed over 19 objects.                                             \n",
      "Job [miniproj_dnn_191212_005848] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs describe miniproj_dnn_191212_005848\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs stream-logs miniproj_dnn_191212_005848\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "for MODEL in dnn; do\n",
    "  OUTDIR=gs://${BUCKET}/${PROJ_NAME}/${MODEL}\n",
    "  JOBNAME=${PROJ_NAME}_${MODEL}_$(date -u +%y%m%d_%H%M%S)\n",
    "  gsutil -m rm -rf $OUTDIR\n",
    "  gcloud ai-platform jobs submit training $JOBNAME \\\n",
    "     --region=$REGION \\\n",
    "     --module-name=trainer.task \\\n",
    "     --package-path=${PWD}/${PROJ_NAME}/trainer \\\n",
    "     --job-dir=$OUTDIR \\\n",
    "     --scale-tier=BASIC \\\n",
    "     --runtime-version=$TFVERSION \\\n",
    "     -- \\\n",
    "     --train_data_path=\"gs://${BUCKET}/${PROJ_NAME}/data/train.csv\" \\\n",
    "     --eval_data_path=\"gs://${BUCKET}/${PROJ_NAME}/data/valid.csv\"  \\\n",
    "     --output_dir=$OUTDIR \\\n",
    "     --nnsize='128,64' \\\n",
    "     --train_steps=3000 --feature_length=$FEATURE_LEN --model=$MODEL\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/dnn'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OUTDIR='gs://{}/{}/{}'.format(BUCKET,PROJ_NAME,'dnn')\n",
    "OUTDIR   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/dnn/export/exporter/1576112569/variables/variables\n"
     ]
    }
   ],
   "source": [
    "loaded_model = tf.contrib.predictor.from_saved_model('gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/dnn/export/exporter/1576112569')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vaild data Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[45486     0]\n",
      " [   83     0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_predictions(loaded_model, input_fn):\n",
    "    result =loaded_model({'Class':input_fn})\n",
    "    return result['probabilities']\n",
    "\n",
    "def eval_input_fn(csv_path):\n",
    "    from numpy import genfromtxt\n",
    "    data = genfromtxt(csv_path, delimiter=',')\n",
    "    data = data[1:,:-1]\n",
    "    return data\n",
    "\n",
    "LABELS = [\"0\", \"1\"]\n",
    "\n",
    "df_eval = pd.read_csv('./valid.csv')\n",
    "\n",
    "# Create a confusion matrix on training data.\n",
    "with tf.Graph().as_default():\n",
    "    cm = tf.confusion_matrix(df_eval[\"Class\"],get_predictions(loaded_model, eval_input_fn('./valid.csv')))\n",
    "    with tf.Session() as session:\n",
    "        cm_out = session.run(cm)\n",
    "        print(cm_out)\n",
    "\n",
    "# Normalize the confusion matrix so that each row sums to 1.\n",
    "cm_out = cm_out.astype(float) \n",
    "# / cm_out.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "sns.heatmap(cm_out, annot=True, xticklabels=LABELS, yticklabels=LABELS);\n",
    "plt.xlabel(\"Predicted\");\n",
    "plt.ylabel(\"True\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[56858     0]\n",
      " [  104     0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEKCAYAAADzQPVvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAGy1JREFUeJzt3XucV1W9//HXewYveGMoDWEgseRUZHnJEK3MSwJeEj0VaSYcteb3S/On1u+UZOVPzPJY6olCO3QkQUulTh5IMUC8cgyFFEVQY7wyA0gJqIkKM/P5/fFd0Fecy3dgZr6X/X762I/57s9ee++1AT/fNWuvvbYiAjMzq2xVxa6AmZl1Pyd7M7MMcLI3M8sAJ3szswxwsjczywAnezOzDHCyNzPLACd7M7MMcLI3M8uAXsWuQFs2/e1ZP9pr79B7wKeKXQUrQU0bG7W9x+hMztlhz/dt9/l6mlv2ZmYZULItezOzHtXSXOwadCsnezMzgOamYtegWznZm5kBES3FrkK3crI3MwNocbI3M6t8btmbmWWAb9CamWWAW/ZmZpUvPBrHzCwDfIPWzCwD3I1jZpYBvkFrZpYBbtmbmWWAb9CamWWAb9CamVW+CPfZm5lVPvfZm5llgLtxzMwywC17M7MMaN5U7Bp0Kyd7MzNwN46ZWSZUeDdOVbErYGZWElpaCl86IOl5SUskLZa0KMXeJWmupOXpZ98Ul6SJkuolPS7p4LzjjEvll0salxf/WDp+fdpXHdXJyd7MDLo02SdHRcSBEXFIWr8ImBcRQ4B5aR3gOGBIWuqA6yD35QBcAhwKDAMu2fwFkcp8NW+/UR1VxsnezAyI5k0FL9toNDA1fZ4KnJwXnxY5C4AaSf2BkcDciFgbEeuAucCotG2PiFgQEQFMyztWm5zszcwg12df6FLA0YA5kv4sqS7F+kXEqvR5NdAvfa4FVuTt25Bi7cUbWom3yzdozcygU6NxUgKvywtNjojJeeufjIhGSe8B5kp6Kn//iAhJsV317SQnezMz6NRonJTYJ7ezvTH9XCPpNnJ97i9J6h8Rq1JXzJpUvBEYlLf7wBRrBI7cKn5vig9spXy73I1jZgZddoNW0q6Sdt/8GRgBPAHMBDaPqBkHzEifZwJj06ic4cArqbtnNjBCUt90Y3YEMDtte1XS8DQKZ2zesdrklr2ZGXTlOPt+wG1pNGQv4DcR8UdJC4Hpks4GXgDGpPKzgOOBemADcCZARKyVdBmwMJWbEBFr0+dzgBuA3sCdaWmXk72ZGUBT17y8JCKeBQ5oJf4ycEwr8QDObeNYU4AprcQXAft3pl5O9mZmUPFP0DrZm5mB58YxM8sEt+zNzDLALXszswxwy97MLAO6aDROqXKyNzMDiB6dvaDHOdmbmYH77M3MMsHJ3swsA3yD1swsA5qbi12DbuVkb2YG7sYxM8sEJ3szswxwn72ZWeWLFo+zNzOrfO7GMTPLAI/GMTPLALfsrbNGfG4cu+6yC1VVVVRXVzN9ysS3bZ/y699xx5x7AGhububZF1bwwB230GeP3bf5nBs3bmT8ZVex7Onl1PTZg59MGE9t/35btq9avYaTvvy/OOes0znzS5/f5vNYaRg54kiuvnoC1VVVTPnVzVz540nFrlL5c7K3bTHlZ1fQt6ZPq9vOOv3znHV6LuHeO38B027974ITfeOql7j48qu44edXvi3++9vnsMfuu3Hn9CnMuuterr52ClddNn7L9it/NplPDT9kG6/GSklVVRUTf3o5o44/jYaGVSz40yz+cPscnnxyebGrVt48Edq2kfRBYDRQm0KNwMyIeLK7zlmOZt11H8cf++kt63+YfTe//u0MNm1q4qMf/gDf/ea5VFdXd3icux/4E+ec/WUARhz5KX549XVEBJKYd/+D1Pbfm969d+6267CeM+zjB/HMM8/z3HMvAjB9+gxO+uxIJ/vtVeEt+6ruOKikbwO3AAIeTouAmyVd1B3nLCWSqLvwYsacdR6/nTGrzXJvvPkm8xcs4tgjPwnAM8+/yB/n3ceNv7iK/5o6iaqqKm5P3T0dWfPXl9n7PXsC0KtXNbvtugvrX3mVDRveYMpNv+Wcs07f/guzkjCgdm9WNKzcst7QuIoBA/YuYo0qREsUvpSh7mrZnw18OCI25QclXQ0sBa7opvOWhGnX/YR+e+3Jy+vW89ULvsO++wzikAM/8o5y985/iIM+OnRLF85Dixaz7Kl6Tj37fADeeust3tW3BoD/M34CjStfYlPTJla99Fc+N+5cAL48ZjSnnDCizbpMmnITZ3zxFHbZpXdXX6ZZZfFonG3SAgwAXtgq3j9ta5WkOqAO4NqrfsBXxp7WTdXrXv32yrWw3923hmOOOJwly55uNdnfOe8+jv/MkVvWI4KTjvsMF37tzHeUnfij7wNt99m/Z693s3rN39j7PXvR1NTM31/fQE2fPViy9Gnm3jOfq6+9ntf+/jqS2GnHHfnS50/qwiu2nrSycTWDBg7Ysj6wtj8rV64uYo0qQ1R4N053JfsLgHmSlgMrUuy9wH7A19vaKSImA5MBNv3t2bL8XWnDG28SLS3suusubHjjTR58+BG+duaX3lHutb+/zqJHl3DF97+1JTb8kAM576IJjD31FN7dt4ZXXn2N1zdsYMDe/d6x/9aO+uRwZsy6iwP3/xBz7n2AQz92AJKYdt1PtpSZdP1N7NJ7Zyf6Mrdw0WL2229fBg8eRGPjasaMGc0ZY88tdrXKX5l2zxSqW5J9RPxR0j8Bw3j7DdqFEVHRvyu9vHYd53/nMgCam5o5fsSRfHL4Idx62x0AfPGUEwCYd9+DHD7sYHbJu2n6/n334byvjqXugotpiRZ26NWLi79xTkHJ/p9PHMn4y37McWPOos8eu/PjSyv+1khmNTc3c/4F32XWHb+huqqKG6beyrJlfyl2tcpfhc+NoyjR4Ubl2rK37tV7wKeKXQUrQU0bG7W9x3h9wukF55xdv//r7T5fT/M4ezMzgKaK7nRwsjczAyq+G6dbxtmbmZWdLh5nL6la0qOSbk/r+0p6SFK9pFsl7ZjiO6X1+rR9cN4xxqf405JG5sVHpVh9oc8uOdmbmZEbelnoUqDzgfwZA/4NuCYi9gPWkXseifRzXYpfk8ohaShwKvBhYBRwbfoCqQYmAccBQ4HTUtl2OdmbmUGXtuwlDQROAP4zrQs4GvhdKjIVODl9Hp3WSduPSeVHA7dExFsR8RxQT26E4zCgPiKejYiN5GYrGN1RnZzszcygq7tx/h34Fv94iPTdwPqIaErrDfxjWHot6XmktP2VVH5LfKt92oq3y8nezAxy0yUUuEiqk7Qob6nbfBhJJwJrIuLPRbyad/BoHDMzOvcO2vyn/VvxCeAkSccDOwN7AD8FaiT1Sq33geQeNCX9HAQ0SOoF9AFezotvlr9PW/E2uWVvZgZd1o0TEeMjYmBEDCZ3g/XuiDgduAfY/OagccCM9HlmWidtvztyT7vOBE5No3X2BYaQm0F4ITAkje7ZMZ1jZkeX55a9mRn0xHz23wZukfQD4FHg+hS/HrhRUj2wllzyJiKWSpoOLAOagHM3Tzcj6evAbKAamBIRSzs6uadLsLLi6RKsNV0xXcJr5xxXcM7Z/do7PV2CmVlZ8qyXZmaVL5ore7oEJ3szM3DL3swsCzoz9LIcOdmbmYFb9mZmmVDZXfZO9mZmANFU2dneyd7MDNyyNzPLAt+gNTPLArfszcwqn1v2ZmZZ4Ja9mVnl2/IOqQrlZG9mBoRb9mZmGeBkb2ZW+dyyNzPLACd7M7MMiOaye/lUpzjZm5nhlr2ZWSZEi1v2ZmYVzy17M7MMiHDL3sys4rllb2aWAS0ejWNmVvl8g9bMLAOc7M3MMiAqezp7J3szM3DL3swsEyp96GVVoQUl7dSdFTEzK6bmZhW8tEfSzpIelvSYpKWSLk3xfSU9JKle0q2SdkzxndJ6fdo+OO9Y41P8aUkj8+KjUqxe0kWFXF+HyV7SMElLgOVp/QBJPyvk4GZm5SJCBS8deAs4OiIOAA4ERkkaDvwbcE1E7AesA85O5c8G1qX4NakckoYCpwIfBkYB10qqllQNTAKOA4YCp6Wy7SqkZT8ROBF4OfcHEo8BRxWwn5lZ2YgWFby0e5ycv6fVHdISwNHA71J8KnBy+jw6rZO2HyNJKX5LRLwVEc8B9cCwtNRHxLMRsRG4JZVtVyHJvioiXtgq1lzAfmZmZSOi8KUjqQW+GFgDzAWeAdZHbHnTbQNQmz7XAitydYgm4BXg3fnxrfZpK96uQpL9CknDgEgXcAHwlwL2MzMrG51p2Uuqk7Qob6l727EimiPiQGAguZb4B4tyUXkKGY3zNXJdOe8FXgLuSjEzs4rR3FLweBUiYjIwuYBy6yXdAxwG1EjqlVrvA4HGVKwRGAQ0SOoF9CHXbb45vln+Pm3F29Th1UXEmog4NSL2TMupEfG3jvYzMysnXdWNI2kvSTXpc2/gWOBJ4B7g86nYOGBG+jwzrZO23x0RkeKnptE6+wJDgIeBhcCQNLpnR3I3cWd2dH0dtuwl/ZLczYW3iYi6VoqbmZWllq4bZ98fmJpGzVQB0yPidknLgFsk/QB4FLg+lb8euFFSPbCWXPImIpZKmg4sA5qAcyOiGUDS14HZQDUwJSKWdlQpRQdfU5K+mLe6M3AKsCIizivsurfNpr89W+EPL9u26D3gU8WugpWgpo2N252pH33v6IJzzkEvzii7J7A6bNlHxK3565JuBOZ3W43MzIrAc+O8075Av66uyNbcgjOzntSF3TglqZA++3X8o8++ilyfUkGP55qZlYvOjMYpR+0m+/QU1wH8Y1hPS3TUyW9mVoYqPbG1m+wjIiTNioj9e6pCZmbFUOndOIX83rJY0kHdXhMzsyLqwonQSlKbLfu8J70OAhZKegZ4HRC5Rv/BPVRHM7Nu11LsCnSz9rpxHgYOBk7qobqYmRVNUJ4t9kK1l+wFEBHP9FBdzMyKpqlMu2cK1V6y30vSN9raGBFXd0N9zMyKIsst+2pgN6jwPwEzM7LdZ78qIib0WE3MzIooyy37yr5yM7M8WW7ZH9NjtTAzK7LmCm/ftpnsI2JtT1bEzKyYOniPeNnbllkvzcwqTktWW/ZmZlmS6YnQzMyyIss3aM3MMqNF7sYxM6t4zcWuQDdzsjczw6NxzMwywaNxzMwywKNxzMwywN04ZmYZ4KGXZmYZ0OyWvZlZ5XPL3swsA5zszcwyoMJfQetkb2YGld+yryp2BczMSkFzJ5b2SBok6R5JyyQtlXR+ir9L0lxJy9PPvikuSRMl1Ut6XNLBeccal8ovlzQuL/4xSUvSPhOljif2cbI3MyM3zr7QpQNNwDcjYigwHDhX0lDgImBeRAwB5qV1gOOAIWmpA66D3JcDcAlwKDAMuGTzF0Qq89W8/UZ1VCknezMzct04hS7tiYhVEfFI+vwa8CRQC4wGpqZiU4GT0+fRwLTIWQDUSOoPjATmRsTaiFgHzAVGpW17RMSCiAhgWt6x2uRkb2ZG55K9pDpJi/KWutaOKWkwcBDwENAvIlalTauBfulzLbAib7eGFGsv3tBKvF2+QWtmRufmxomIycDk9spI2g34L+CCiHg1v1s9IkJSj07H45a9mRld2mePpB3IJfpfR8TvU/il1AVD+rkmxRuBQXm7D0yx9uIDW4m3y8nezIwuHY0j4HrgyYi4Om/TTGDziJpxwIy8+Ng0Kmc48Erq7pkNjJDUN92YHQHMTttelTQ8nWts3rHa5G4cMzOgpesmOf4EcAawRNLiFPsOcAUwXdLZwAvAmLRtFnA8UA9sAM4EiIi1ki4DFqZyEyJibfp8DnAD0Bu4My3tcrI3M6PrHqqKiPnQ5ptQjmmlfADntnGsKcCUVuKLgP07Uy8nezMz/PISM7NMqPTpEpzszcyApp4dCdnjnOzNzHA3jplZJrgbx8wsA7pw6GVJcrI3M8PdOGZmmeBuHDOzDGiu8La9k72ZGW7Zm5llQrhlb2ZW+Sq9Ze8pjnvILydfxcqGx1j86LwuOd4ZZ3yBJ5fO58ml8znjjC8A0Lv3zsz872k8seQ+Hlt8Nz+8fHyXnMtKz8gRR7L0ift5atl8vvWvrc6hZZ3UQhS8lCMn+x4ybdp0Tjjx9E7vN2/ub9lnn4Fvi/XtW8P3Lr6Qwz95Iod94gS+d/GF1NT0AeDqa37B/h/5NId8fCSHH/ZxRo08qkvqb6WjqqqKiT+9nBM/+2U+csBRfPGLJ/OhDw0pdrXKXnRiKUdO9j3kgfkPsXbd+rfF3ve+fbjjDzfx0II7uffu3/OBD7y/oGONGPFp7pr3AOvWrWf9+le4a94DjBx5JG+88Sb33vcgAJs2beKRR5dQW9u/y6/FimvYxw/imWee57nnXmTTpk1Mnz6Dkz47stjVKntNRMFLOerxZC/pzJ4+Z6n6xbVXcv6F3+PQ4cfxrW9fxs8n/qig/WoH7E1Dw8ot642Nq6gdsPfbyvTpswcnnnAsd98zv0vrbMU3oHZvVuT9/Tc0rmLAVn//1nnRif/KUTFu0F4K/Kq1DekN7XUAqu5DVdWuPVmvHrXrrrtw2GEf45ab/2NLbKeddgRg3NgxnHfeVwDY7/2D+cPMG9m4cRPPP/8in//CVzo8dnV1Nb++cRI/nzSF5557sXsuwKzCVPoN2m5J9pIeb2sT0K+t/fLf2N5rx9ry/PosUFVVFevXv8ohHx/xjm1Tp01n6rTpQK7P/qyvXMgLLzRs2d64cjWfPuLwLeu1tf257/4Ht6z/4rorWV7/HBN/9p/deAVWLCsbVzNo4IAt6wNr+7Ny5eoi1qgylGuLvVDd1Y3Tj9xLcD/byvJyN52zrLz22t95/vkVfO5zJ26JffSjQwvad86c+zj2M0dQU9OHmpo+HPuZI5gz5z4AJlz6Lfr02Z1vfPOSbqm3Fd/CRYvZb799GTx4EDvssANjxozmD7fPKXa1yl5LJ5Zy1F3dOLcDu0XE4q03SLq3m85Z0m66cRKfPuIw9tzzXTz/7CIunfATzhj3dSb97Ed8Z/z57LBDL6ZPn8Hjjy/r8Fjr1q3n8h/+OwsevAOAH1x+DevWrae2tj/fGX8+Tz61nIUPzwbg2mt/xZRf3dyt12Y9q7m5mfMv+C6z7vgN1VVV3DD1VpYt+0uxq1X2mqOyW/aKEr3ASu/GMbOu07Sxsa0XfBfsS/ucUnDO+c0Lt233+Xqan6A1M6Py++yd7M3MKN+++EI52ZuZ4TdVmZllgrtxzMwyoNJH4zjZm5nhbhwzs0zwDVozswyo9D57T3FsZkbXvrxE0hRJayQ9kRd7l6S5kpann31TXJImSqqX9Likg/P2GZfKL5c0Li/+MUlL0j4TJXX4kJeTvZkZEBEFLwW4ARi1VewiYF5EDAHmpXWA44AhaakDroPclwNwCXAoMAy4ZPMXRCrz1bz9tj7XOzjZm5kBzUTBS0ci4n5g7Vbh0cDU9HkqcHJefFrkLABqJPUHRgJzI2JtRKwD5gKj0rY9ImJB5L55puUdq03uszczo0dG4/SLiFXp82r+Md17LbAir1xDirUXb2gl3i637M3M6Fw3jqQ6SYvylrpOnqvHX2frlr2ZGZ1r2ee/aKkTXpLUPyJWpa6YNSneCAzKKzcwxRqBI7eK35viA1sp3y637M3M6JF30M4ENo+oGQfMyIuPTaNyhgOvpO6e2cAISX3TjdkRwOy07VVJw9MonLF5x2qTW/ZmZnTtdAmSbibXKt9TUgO5UTVXANMlnQ28AIxJxWcBxwP1wAbgTICIWCvpMmBhKjchIjbf9D2H3Iif3sCdaWm/Tn55iZmVu654ecknao8uOOf8T+PdfnmJmVk58tw4ZmYZUKq9HF3Fyd7MDLfszcwyodInQnOyNzMDmqOyJzl2sjczw332ZmaZ4D57M7MMcJ+9mVkGtLgbx8ys8rllb2aWAR6NY2aWAe7GMTPLAHfjmJllgFv2ZmYZ4Ja9mVkGNEdzsavQrZzszczwdAlmZpng6RLMzDLALXszswzwaBwzswzwaBwzswzwdAlmZhngPnszswxwn72ZWQa4ZW9mlgEeZ29mlgFu2ZuZZYBH45iZZUCl36CtKnYFzMxKQUQUvHRE0ihJT0uql3RRD1S/Q072ZmbknqAt9L/2SKoGJgHHAUOB0yQN7YFLaJeTvZkZXdqyHwbUR8SzEbERuAUY3e0X0AH32ZuZ0aV99rXAirz1BuDQrjr4tirZZN+0sVHFrkOpkFQXEZOLXQ8rLf530bU6k3Mk1QF1eaHJpf534W6c8lDXcRHLIP+7KJKImBwRh+Qt+Ym+ERiUtz4wxYrKyd7MrGstBIZI2lfSjsCpwMwi16l0u3HMzMpRRDRJ+jowG6gGpkTE0iJXy8m+TJR0X6AVjf9dlKiImAXMKnY98qnS54MwMzP32ZuZZYKTfYkrxceurbgkTZG0RtITxa6LlQ8n+xJWqo9dW9HdAIwqdiWsvDjZl7aSfOzaiisi7gfWFrseVl6c7Etba49d1xapLmZWxpzszcwywMm+tJXkY9dmVn6c7EtbST52bWblx8m+hEVEE7D5sesngeml8Ni1FZekm4E/AR+Q1CDp7GLXyUqfn6A1M8sAt+zNzDLAyd7MLAOc7M3MMsDJ3swsA5zszcwywMneupykZkmLJT0h6beSdtmOYx0p6fb0+aT2Zv6UVCPpnG04x/+T9H+3tY5m5cDJ3rrDGxFxYETsD2wE/nf+RuV0+t9eRMyMiCvaKVIDdDrZm2WBk711tweA/SQNTvPyTwOeAAZJGiHpT5IeSb8B7AZb5vB/StIjwD9vPpCkf5H08/S5n6TbJD2WlsOBK4D3p98qfpzK/aukhZIel3Rp3rEulvQXSfOBD/TYn4ZZkfgdtNZtJPUiNxf/H1NoCDAuIhZI2hP4LvCZiHhd0reBb0i6EvglcDRQD9zaxuEnAvdFxClp3v/dgIuA/SPiwHT+EemcwwABMyUdAbxObuqJA8n9P/AI8OeuvXqz0uJkb92ht6TF6fMDwPXAAOCFiFiQ4sPJvZDlfyQB7EhuCoAPAs9FxHIASTcBda2c42hgLEBENAOvSOq7VZkRaXk0re9GLvnvDtwWERvSOTzfkFU8J3vrDm9sbl1vlhL66/khYG5EnLZVubftt50E/Cgi/mOrc1zQhecwKwvus7diWQB8QtJ+AJJ2lfRPwFPAYEnvT+VOa2P/ecDX0r7VkvoAr5FrtW82Gzgr715AraT3APcDJ0vqLWl34LNdfG1mJcfJ3ooiIv4K/Atws6THSV04EfEmuW6bO9IN2jVtHOJ84ChJS8j1tw+NiJfJdQs9IenHETEH+A3wp1Tud8DuEfEIuXsBjwF3kptK2qyiedZLM7MMcMvezCwDnOzNzDLAyd7MLAOc7M3MMsDJ3swsA5zszcwywMnezCwDnOzNzDLg/wO8+LnqdZMPAgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_predictions(estimator, input_fn):\n",
    "    result =loaded_model({'Class':input_fn})\n",
    "    return result['probabilities']\n",
    "\n",
    "def eval_input_fn(csv_path):\n",
    "    from numpy import genfromtxt\n",
    "    data = genfromtxt(csv_path, delimiter=',')\n",
    "    data = data[1:,:-1]\n",
    "    return data\n",
    "\n",
    "LABELS = [\"0\", \"1\"]\n",
    "\n",
    "df_eval = pd.read_csv('./test.csv')\n",
    "\n",
    "# Create a confusion matrix on training data.\n",
    "with tf.Graph().as_default():\n",
    "    cm = tf.confusion_matrix(df_eval[\"Class\"],get_predictions(loaded_model, eval_input_fn('./test.csv')))\n",
    "    with tf.Session() as session:\n",
    "        cm_out = session.run(cm)\n",
    "        print(cm_out)\n",
    "\n",
    "# Normalize the confusion matrix so that each row sums to 1.\n",
    "cm_out = cm_out.astype(float) \n",
    "# / cm_out.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "sns.heatmap(cm_out, annot=True, xticklabels=LABELS, yticklabels=LABELS);\n",
    "plt.xlabel(\"Predicted\");\n",
    "plt.ylabel(\"True\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Hyperparameter tuning</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting hyperparam.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile hyperparam.yaml\n",
    "trainingInput:\n",
    "    scaleTier: PREMIUM_1\n",
    "    hyperparameters:\n",
    "        hyperparameterMetricTag: RMSE\n",
    "        goal: MINIMIZE\n",
    "        maxTrials: 2\n",
    "        maxParallelTrials: 1\n",
    "        enableTrialEarlyStopping: True\n",
    "        params:\n",
    "        - parameterName: nnsize\n",
    "          type: CATEGORICAL\n",
    "          categoricalValues:\n",
    "          - 128,64,32\n",
    "          - 64,32,8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "모델 이름을 이력하세요: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dnn\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    MODEL_NAME=input('모델 이름을 이력하세요:')\n",
    "    if len(MODEL_NAME) < 1:\n",
    "        MODEL_NAME='dnn'\n",
    "except ValueError:\n",
    "    MODEL_NAME='dnn'\n",
    "os.environ[\"MODEL_NAME\"] = MODEL_NAME\n",
    "print(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/hyperparam us-central1 miniproj_dnn_191210_072035\n",
      "jobId: miniproj_dnn_191210_072035\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/hyperparam/#1575953639865533...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/hyperparam/1/#1575953640317340...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/hyperparam/1/checkpoint#1575953690939529...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/hyperparam/1/eval/#1575953701512394...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/hyperparam/1/eval/events.out.tfevents.1575953701.cmle-training-master-af2eb73225-0-c7j8h#1575953703618727...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/hyperparam/1/events.out.tfevents.1575953640.cmle-training-worker-af2eb73225-0-bd447#1575953690589276...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/hyperparam/1/events.out.tfevents.1575953641.cmle-training-master-af2eb73225-0-c7j8h#1575953641764378...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/hyperparam/1/export/#1575953704636085...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/hyperparam/1/export/exporter/#1575953704952813...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/hyperparam/1/export/exporter/1575953703/#1575953711425360...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/hyperparam/1/export/exporter/1575953703/saved_model.pb#1575953711816310...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/hyperparam/1/export/exporter/1575953703/variables/#1575953712221540...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/hyperparam/1/export/exporter/1575953703/variables/variables.data-00000-of-00001#1575953712537669...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/hyperparam/1/export/exporter/1575953703/variables/variables.index#1575953712930516...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/hyperparam/1/graph.pbtxt#1575953662610329...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/hyperparam/1/model.ckpt-0.data-00000-of-00009#1575953672429879...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/hyperparam/1/model.ckpt-0.data-00001-of-00009#1575953672019788...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/hyperparam/1/model.ckpt-0.data-00002-of-00009#1575953671572915...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/hyperparam/1/model.ckpt-0.data-00003-of-00009#1575953670297578...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/hyperparam/1/model.ckpt-0.data-00004-of-00009#1575953669790607...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/hyperparam/1/model.ckpt-0.data-00005-of-00009#1575953671136199...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/hyperparam/1/model.ckpt-0.data-00006-of-00009#1575953669361731...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/hyperparam/1/model.ckpt-0.data-00007-of-00009#1575953670701510...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/hyperparam/1/model.ckpt-0.data-00008-of-00009#1575953668910747...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/hyperparam/1/model.ckpt-0.index#1575953672871414...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/hyperparam/1/model.ckpt-0.meta#1575953676552963...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/hyperparam/1/model.ckpt-3008.data-00000-of-00009#1575953687765947...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/hyperparam/1/model.ckpt-3008.data-00001-of-00009#1575953686788626...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/hyperparam/1/model.ckpt-3008.data-00002-of-00009#1575953685956891...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/hyperparam/1/model.ckpt-3008.data-00003-of-00009#1575953685299444...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/hyperparam/1/model.ckpt-3008.data-00004-of-00009#1575953686382805...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/hyperparam/1/model.ckpt-3008.data-00005-of-00009#1575953687210591...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/hyperparam/1/model.ckpt-3008.data-00006-of-00009#1575953684786009...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/hyperparam/1/model.ckpt-3008.data-00007-of-00009#1575953684331657...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/hyperparam/1/model.ckpt-3008.data-00008-of-00009#1575953683766346...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/hyperparam/1/model.ckpt-3008.index#1575953688196029...\n",
      "Removing gs://qwiklabs-gcp-ml-8d503f4cdc07/miniproj/hyperparam/1/model.ckpt-3008.meta#1575953691807146...\n",
      "/ [37/37 objects] 100% Done                                                     \n",
      "Operation completed over 37 objects.                                             \n",
      "Job [miniproj_dnn_191210_072035] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs describe miniproj_dnn_191210_072035\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs stream-logs miniproj_dnn_191210_072035\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://${BUCKET}/${PROJ_NAME}/hyperparam\n",
    "JOBNAME=${PROJ_NAME}_${MODEL_NAME}_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ai-platform jobs submit training $JOBNAME \\\n",
    "    --region=$REGION \\\n",
    "    --module-name=trainer.task \\\n",
    "    --package-path=${PWD}/${PROJ_NAME}/trainer \\\n",
    "    --job-dir=$OUTDIR \\\n",
    "    --staging-bucket=gs://$BUCKET \\\n",
    "    --scale-tier=PREMIUM_1 \\\n",
    "    --config=hyperparam.yaml \\\n",
    "    --runtime-version=$TFVERSION \\\n",
    "    -- \\\n",
    "    --train_data_path=\"gs://${BUCKET}/${PROJ_NAME}/data/train.csv\" \\\n",
    "    --eval_data_path=\"gs://${BUCKET}/${PROJ_NAME}/data/valid.csv\"  \\\n",
    "    --output_dir=$OUTDIR \\\n",
    "    --train_steps=3000 --feature_length=$FEATURE_LEN --model=$MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://${BUCKET}/${PROJ_NAME}/trained_model_${MODEL_NAME}_tuned\n",
    "JOBNAME=${PROJ_NAME}_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ai-platform jobs submit training $JOBNAME \\\n",
    "    --region=$REGION \\\n",
    "    --module-name=trainer.task \\\n",
    "    --package-path=${PWD}/${PROJ_NAME}/trainer \\\n",
    "    --job-dir=$OUTDIR \\\n",
    "    --staging-bucket=gs://$BUCKET \\\n",
    "    --scale-tier=PREMIUM_1 \\\n",
    "    --config=hyperparam.yaml \\\n",
    "    --runtime-version=$TFVERSION \\\n",
    "    -- \\\n",
    "    --train_data_path=\"gs://${BUCKET}/${PROJ_NAME}/data/train.csv\" \\\n",
    "    --eval_data_path=\"gs://${BUCKET}/${PROJ_NAME}/data/valid.csv\"  \\\n",
    "    --output_dir=$OUTDIR \\\n",
    "    --train_steps=3000 --feature_length=$FEATURE_LEN --model=$MODEL_NAME \\\n",
    "    --train_batch_size= --nnsize=''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 코드 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p ${PROJ_NAME}/trainer\n",
    "touch ${PROJ_NAME}/__init__.py\n",
    "touch ${PROJ_NAME}/trainer/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting miniproj/trainer/task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {PROJ_NAME}/trainer/task.py\n",
    "# Copyright 2017 Google Inc. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "\"\"\"Example implementation of code to run on the Cloud ML service.\n",
    "\"\"\"\n",
    "\n",
    "import traceback\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "from . import model\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  parser = argparse.ArgumentParser()\n",
    "  # Input Arguments\n",
    "  parser.add_argument(\n",
    "      '--train_data_path',\n",
    "      help='GCS or local path to training data',\n",
    "      required=True\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      '--eval_data_path',\n",
    "      help='GCS or local path to evaluation data',\n",
    "      required=True\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      '--train_batch_size',\n",
    "      help='Batch size for training steps',\n",
    "      type=int,\n",
    "      default=100\n",
    "  )\n",
    "  parser.add_argument(\n",
    "        \"--nnsize\",\n",
    "        help=\"Hidden layer sizes to use for DNN feature columns -- provide \\\n",
    "        space-separated layers\",\n",
    "        type=str,\n",
    "        default='128,32,4'\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      '--learning_rate',\n",
    "      help='Initial learning rate for training',\n",
    "      type=float,\n",
    "      default=0.01\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      '--train_steps',\n",
    "      help=\"\"\"\\\n",
    "      Steps to run the training job for. A step is one batch-size,\\\n",
    "      \"\"\",\n",
    "      type=int,\n",
    "      default=0\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      '--feature_length',\n",
    "      help=\"\"\"\\\n",
    "      This model works with fixed length sequences. 1-(N-1) are inputs, last is output\n",
    "      \"\"\",\n",
    "      type=int,\n",
    "      default=10\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      '--output_dir',\n",
    "      help='GCS location to write checkpoints and export models',\n",
    "      required=True\n",
    "  )\n",
    "  model_names = [name.replace('_model','') \\\n",
    "                   for name in dir(model) \\\n",
    "                     if name.endswith('_model')]\n",
    "  parser.add_argument(\n",
    "      '--model',\n",
    "      help='Type of model. Supported types are {}'.format(model_names),\n",
    "      required=True\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      '--job-dir',\n",
    "      help='this model ignores this field, but it is required by gcloud',\n",
    "      default='junk'\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      '--eval_delay_secs',\n",
    "      help='How long to wait before running first evaluation',\n",
    "      default=10,\n",
    "      type=int\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      '--min_eval_frequency',\n",
    "      help='Minimum number of training steps between evaluations',\n",
    "      default=60,\n",
    "      type=int\n",
    "  )\n",
    "\n",
    "  args = parser.parse_args()\n",
    "  hparams = args.__dict__\n",
    "  \n",
    "  # unused args provided by service\n",
    "  hparams.pop('job_dir', None)\n",
    "  hparams.pop('job-dir', None)\n",
    "\n",
    "  output_dir = hparams.pop('output_dir')\n",
    "  model.BATCH_SIZE = hparams['train_batch_size']\n",
    "  model.NNSIZE = list(map(int, hparams.pop(\"nnsize\").split(\",\")))\n",
    "  print (\"Will use DNN size of {}\".format(model.NNSIZE))\n",
    "\n",
    "  # Append trial_id to path if we are doing hptuning\n",
    "  # This code can be removed if you are not using hyperparameter tuning\n",
    "  output_dir = os.path.join(\n",
    "      output_dir,\n",
    "      json.loads(\n",
    "          os.environ.get('TF_CONFIG', '{}')\n",
    "      ).get('task', {}).get('trial', '')\n",
    "  )\n",
    "\n",
    "  # calculate train_steps if not provided\n",
    "  if hparams['train_steps'] < 1:\n",
    "     # 1,000 steps at batch_size of 100\n",
    "     hparams['train_steps'] = (1000 * 100) // hparams['train_batch_size']\n",
    "     print (\"Training for {} steps\".format(hparams['train_steps']))\n",
    "\n",
    "  model.init(hparams)\n",
    "\n",
    "  # Run the training job\n",
    "  model.train_and_evaluate(output_dir, hparams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {PROJ_NAME}/trainer/model.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "# Copyright 2017 Google Inc. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "LABLE_COL = 'Class'\n",
    "NCLASSES = 2\n",
    "N_OUTPUTS = 1  # in each sequence, 1-49 are features, and 50 is label\n",
    "FEATURE_LEN = None\n",
    "DEFAULTS = None\n",
    "N_INPUTS = None\n",
    "BATCH_SIZE = 512\n",
    "NNSIZE = [64, 16, 4]\n",
    "\n",
    "\n",
    "def init(hparams):\n",
    "    global FEATURE_LEN, DEFAULTS, N_INPUTS\n",
    "    FEATURE_LEN = hparams['feature_length']\n",
    "    DEFAULTS = [[0.0] for x in range(0, FEATURE_LEN-1)] +[[0.0]]\n",
    "    N_INPUTS = FEATURE_LEN - N_OUTPUTS\n",
    "\n",
    "\n",
    "def linear_model(features, mode, params):\n",
    "    X = features[LABLE_COL]\n",
    "    predictions = tf.layers.dense(X, NCLASSES, activation=None)\n",
    "    return predictions, NCLASSES\n",
    "\n",
    "\n",
    "def dnn_model(features, mode, params):\n",
    "    X = features[LABLE_COL]\n",
    "    #X = tf.Print(X, [tf.shape(X)], summarize=-1, message=\"X features\\n\\n\")\n",
    "    #X = tf.reshape(tensor = X, shape = [-1, N_INPUTS])\n",
    "    print('NNSIZE:{}'.format(NNSIZE))\n",
    "    for unit_num in NNSIZE:\n",
    "        X = tf.layers.dense(X, units=unit_num, activation=tf.nn.relu)\n",
    "#     predictions = tf.layers.dense(X, 1, activation=tf.nn.sigmoid)  \n",
    "    predictions = tf.layers.dense(X, 1, activation=None) # linear output: regression\n",
    "    #predictions = tf.Print(predictions, [tf.shape(predictions)], summarize=-1, message=\"\\n\\npredictions shape\")\n",
    "    return predictions, NCLASSES\n",
    "\n",
    "def cnn_model(features, mode, params):\n",
    "    X = tf.reshape(features[LABLE_COL],\n",
    "                   [-1, N_INPUTS, 1])  # as a 1D \"sequence\" with only one time-series observation (height)\n",
    "    c1 = tf.layers.conv1d(X, filters=N_INPUTS // 2,\n",
    "                          kernel_size=3, strides=1,\n",
    "                          padding='same', activation=tf.nn.relu)\n",
    "    p1 = tf.layers.max_pooling1d(c1, pool_size=2, strides=2)\n",
    "\n",
    "    c2 = tf.layers.conv1d(p1, filters=N_INPUTS // 2,\n",
    "                          kernel_size=3, strides=1,\n",
    "                          padding='same', activation=tf.nn.relu)\n",
    "    p2 = tf.layers.max_pooling1d(c2, pool_size=2, strides=2)\n",
    "\n",
    "    outlen = p2.shape[1] * p2.shape[2]\n",
    "    c2flat = tf.reshape(p2, [-1, outlen])\n",
    "    h1 = tf.layers.dense(c2flat, 3, activation=tf.nn.relu)\n",
    "    predictions = tf.layers.dense(h1, 1, activation=None)  # linear output: regression\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def rnn_model(features, mode, params):\n",
    "    CELL_SIZE = N_INPUTS // 3  # size of the internal state in each of the cells\n",
    "\n",
    "    # 1. dynamic_rnn needs 3D shape: [BATCH_SIZE, N_INPUTS, 1]\n",
    "    x = tf.reshape(features[LABLE_COL], [-1, N_INPUTS, 1])\n",
    "\n",
    "    # 2. configure the RNN\n",
    "    cell = tf.nn.rnn_cell.GRUCell(CELL_SIZE)\n",
    "    outputs, state = tf.nn.dynamic_rnn(cell, x, dtype=tf.float32)\n",
    "\n",
    "    # 3. pass rnn output through a dense layer\n",
    "    h1 = tf.layers.dense(state, N_INPUTS // 2, activation=tf.nn.relu)\n",
    "    predictions = tf.layers.dense(h1, 1, activation=None)  # (?, 1)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "# 2-layer RNN\n",
    "def rnn2_model(features, mode, params):\n",
    "    # dynamic_rnn needs 3D shape: [BATCH_SIZE, N_INPUTS, 1]\n",
    "    x = tf.reshape(features[LABLE_COL], [-1, N_INPUTS, 1])\n",
    "\n",
    "    # 2. configure the RNN\n",
    "    cell1 = tf.nn.rnn_cell.GRUCell(N_INPUTS * 2)\n",
    "    cell2 = tf.nn.rnn_cell.GRUCell(N_INPUTS // 2)\n",
    "    cells = tf.nn.rnn_cell.MultiRNNCell([cell1, cell2])\n",
    "    outputs, state = tf.nn.dynamic_rnn(cells, x, dtype=tf.float32)\n",
    "    # 'state' is now a tuple containing the final state of each cell layer\n",
    "    # we use state[1] below to extract the final state of the final layer\n",
    "    \n",
    "    # 3. pass rnn output through a dense layer\n",
    "    h1 = tf.layers.dense(state[1], cells.output_size // 2, activation=tf.nn.relu)\n",
    "    predictions = tf.layers.dense(h1, 1, activation=None)  # (?, 1)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "# create N-1 predictions\n",
    "def rnnN_model(features, mode, params):\n",
    "    # dynamic_rnn needs 3D shape: [BATCH_SIZE, N_INPUTS, 1]\n",
    "    x = tf.reshape(features[LABLE_COL], [-1, N_INPUTS, 1])\n",
    "\n",
    "    # 2. configure the RNN\n",
    "    cell1 = tf.nn.rnn_cell.GRUCell(N_INPUTS * 2)\n",
    "    cell2 = tf.nn.rnn_cell.GRUCell(N_INPUTS // 2)\n",
    "    cells = tf.nn.rnn_cell.MultiRNNCell([cell1, cell2])\n",
    "    outputs, state = tf.nn.dynamic_rnn(cells, x, dtype=tf.float32)\n",
    "    # 'outputs' contains the state of the final layer for every time step\n",
    "    # not just the last time step (?,N_INPUTS, final cell size)\n",
    "    \n",
    "    # 3. pass state for each time step through a DNN, to get a prediction\n",
    "    # for each time step \n",
    "    h1 = tf.layers.dense(outputs, cells.output_size, activation=tf.nn.relu)\n",
    "    h2 = tf.layers.dense(h1, cells.output_size // 2, activation=tf.nn.relu)\n",
    "    predictions = tf.layers.dense(h2, 1, activation=None)  # (?, N_INPUTS, 1)\n",
    "    predictions = tf.reshape(predictions, [-1, N_INPUTS])\n",
    "    return predictions # return prediction for each time step\n",
    "\n",
    "\n",
    "# read data and convert to needed format\n",
    "def read_dataset(filename, mode, batch_size=512):\n",
    "    def _input_fn():\n",
    "        def decode_csv(row):\n",
    "            # row is a string tensor containing the contents of one row\n",
    "            features = tf.decode_csv(row, record_defaults=DEFAULTS)  # string tensor -> list of 50 rank 0 float tensors\n",
    "            label = features.pop()  # remove last feature and use as label\n",
    "            features = tf.stack(features)  # list of rank 0 tensors -> single rank 1 tensor\n",
    "            return {LABLE_COL: features}, label\n",
    "\n",
    "        # Create list of file names that match \"glob\" pattern (i.e. data_file_*.csv)\n",
    "        dataset = tf.data.Dataset.list_files(filename)\n",
    "        # Read in data from files\n",
    "        dataset = dataset.flat_map(tf.data.TextLineDataset)\n",
    "        # Parse text lines as comma-separated values (CSV)\n",
    "        \n",
    "        dataset = dataset.skip(1).map(decode_csv)\n",
    "        print(dataset)\n",
    "\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            num_epochs = None  # loop indefinitely\n",
    "            dataset = dataset.shuffle(buffer_size=10 * batch_size)\n",
    "        else:\n",
    "            num_epochs = 1  # end-of-input after this\n",
    "\n",
    "        dataset = dataset.repeat(num_epochs).batch(batch_size)\n",
    "        return dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "    return _input_fn\n",
    "\n",
    "\n",
    "def serving_input_fn():\n",
    "    feature_placeholders = {\n",
    "        LABLE_COL: tf.placeholder(tf.float32, [None, FEATURE_LEN-1])\n",
    "    }\n",
    "\n",
    "    features = {\n",
    "        key: tf.expand_dims(tensor, axis=-1)\n",
    "        for key, tensor in feature_placeholders.items()\n",
    "    }\n",
    "    \n",
    "#     features[LABLE_COL] = tf.expand_dims(features[LABLE_COL], axis = 0)\n",
    "#     features[LABLE_COL] = {LABLE_COL: tf.expand_dims(input = feature_placeholders[LABLE_COL], axis = -1)} \n",
    "    features[LABLE_COL] = tf.squeeze(features[LABLE_COL], axis=[2])\n",
    "#     features[LABLE_COL] = tf.Print(features[LABLE_COL], [tf.shape(features[LABLE_COL])], summarize=-1, message=\"\\n\\nfeatures[LABLE_COL]\")\n",
    "#     features[LABLE_COL] = {LABLE_COL: tf.expand_dims(input = feature_placeholders[LABLE_COL], axis = -1)} \n",
    "#     features = {LABLE_COL: tf.expand_dims(input = feature_placeholders[LABLE_COL], axis = -1)} \n",
    "    \n",
    "\n",
    "    return tf.estimator.export.ServingInputReceiver(features, feature_placeholders)\n",
    "\n",
    "\n",
    "def compute_errors(features, labels, predictions):\n",
    "    labels = tf.expand_dims(labels, -1)  # rank 1 -> rank 2 to match rank of predictions\n",
    "\n",
    "    if predictions.shape[1] == 1:\n",
    "        loss = tf.losses.mean_squared_error(labels, predictions)\n",
    "        rmse = tf.metrics.root_mean_squared_error(labels, predictions)\n",
    "        return loss, rmse\n",
    "    else:\n",
    "        # one prediction for every input in sequence\n",
    "        # get 1-N of (x + label)\n",
    "        labelsN = tf.concat([features[LABLE_COL], labels], axis=1)\n",
    "        labelsN = labelsN[:, 1:]\n",
    "        # loss is computed from the last 1/3 of the series\n",
    "        N = (2 * N_INPUTS) // 3\n",
    "        loss = tf.losses.mean_squared_error(labelsN[:, N:], predictions[:, N:])\n",
    "        # rmse is computed from last prediction and last label\n",
    "        lastPred = predictions[:, -1]\n",
    "        rmse = tf.metrics.root_mean_squared_error(labels, lastPred)\n",
    "        return loss, rmse\n",
    "\n",
    "# RMSE when predicting same as last value\n",
    "def same_as_last_benchmark(features, labels):\n",
    "    predictions = features[LABLE_COL][:,-1] # last value in input sequence\n",
    "    return tf.metrics.root_mean_squared_error(labels, predictions)\n",
    "\n",
    "\n",
    "# create the inference model\n",
    "def data_regressor(features, labels, mode, params):\n",
    "    # 1. run the appropriate model\n",
    "    model_functions = {\n",
    "        'linear': linear_model,\n",
    "        'dnn': dnn_model,\n",
    "        'cnn': cnn_model,\n",
    "        'rnn': rnn_model,\n",
    "        'rnn2': rnn2_model,\n",
    "        'rnnN': rnnN_model}\n",
    "    model_function = model_functions[params['model']]\n",
    "    ylogits, nclasses = model_function(features, mode, params)\n",
    "#     ylogits = tf.Print(ylogits, [tf.shape(ylogits), ylogits], summarize=-1, message=\"\\n\\nylogits shape\")\n",
    "#     labels = tf.expand_dims(labels, -1)\n",
    "#     labels = tf.Print(labels, [tf.shape(labels), labels], summarize=-1, message=\"\\n\\nlabels shape\")\n",
    "    probabilities = ylogits #tf.nn.softmax(logits = ylogits) #ylogits\n",
    "    class_ids = tf.cast(x = tf.argmax(input = ylogits, axis = 1), dtype = tf.uint8)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN or mode == tf.estimator.ModeKeys.EVAL:\n",
    "        loss = tf.reduce_mean(input_tensor = tf.nn.sigmoid_cross_entropy_with_logits(logits = ylogits,\n",
    "                                                                                        labels = tf.expand_dims(labels, -1)))\n",
    "#         loss = tf.reduce_mean(input_tensor = tf.nn.softmax_cross_entropy_with_logits_v2(logits = ylogits,\n",
    "#                                                                                         labels = tf.one_hot(indices = labels, depth = NCLASSES)))\n",
    "        \n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            # This is needed for batch normalization, but has no effect otherwise\n",
    "            update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "            with tf.control_dependencies(update_ops):\n",
    "                train_op = tf.contrib.layers.optimize_loss(\n",
    "                    loss = loss, \n",
    "                    global_step = tf.train.get_global_step(),\n",
    "                    learning_rate = params[\"learning_rate\"], \n",
    "                    optimizer = \"Adam\")\n",
    "            eval_metric_ops = None\n",
    "        else:\n",
    "            train_op = None\n",
    "            eval_metric_ops =  {\"accuracy\": tf.metrics.accuracy(labels = labels,\n",
    "                                                                predictions = class_ids)}\n",
    "#             eval_metric_ops =  {\"accuracy\": tf.metrics.accuracy(labels = tf.argmax(input = labels, axis = 1),\n",
    "#                                                                 predictions = class_ids)}\n",
    "    else:\n",
    "        loss = None\n",
    "        train_op = None\n",
    "        eval_metric_ops = None\n",
    " \n",
    "    predictions_dict = {\"probabilities\": probabilities}\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode = mode,\n",
    "        predictions=predictions_dict,  #\"class_ids\": class_ids},\n",
    "        loss = loss,\n",
    "        train_op = train_op,\n",
    "        eval_metric_ops = eval_metric_ops,\n",
    "        export_outputs = {\"predictions\":tf.estimator.export.PredictOutput(predictions_dict)}\n",
    "    )\n",
    "\n",
    "\n",
    "def train_and_evaluate(output_dir, hparams):\n",
    "    tf.summary.FileWriterCache.clear() # ensure filewriter cache is clear for TensorBoard events file\n",
    "    get_train = read_dataset(hparams['train_data_path'],\n",
    "                             tf.estimator.ModeKeys.TRAIN,\n",
    "                             hparams['train_batch_size'])\n",
    "    get_valid = read_dataset(hparams['eval_data_path'],\n",
    "                             tf.estimator.ModeKeys.EVAL,\n",
    "                             100)\n",
    "    estimator = tf.estimator.Estimator(model_fn=data_regressor,\n",
    "                                       params=hparams,\n",
    "                                       config=tf.estimator.RunConfig(\n",
    "                                           log_step_count_steps=10,\n",
    "                                           save_checkpoints_secs=\n",
    "                                           hparams['min_eval_frequency']),\n",
    "                                       model_dir=output_dir)\n",
    "    train_spec = tf.estimator.TrainSpec(input_fn=get_train,\n",
    "                                        max_steps=hparams['train_steps'])\n",
    "    exporter = tf.estimator.LatestExporter('exporter', serving_input_fn)\n",
    "    eval_spec = tf.estimator.EvalSpec(input_fn=get_valid,\n",
    "                                      steps=None,\n",
    "                                      exporters=exporter,\n",
    "                                      start_delay_secs=0, #hparams['eval_delay_secs'],\n",
    "                                      throttle_secs=1, #hparams['min_eval_frequency']\n",
    "                                     )\n",
    "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
