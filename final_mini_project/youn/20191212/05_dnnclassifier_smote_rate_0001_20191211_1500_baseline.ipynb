{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV_COLUMN_NAMES:['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount', 'Class']\n",
      "CSV_DEFAULTS:[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0]]\n"
     ]
    }
   ],
   "source": [
    "CSV_COLUMN_NAMES = [\"Time\"]+['V'+(i+1).astype(np.str) for i in np.array(range(28))]+['Amount','Class']\n",
    "CSV_DEFAULTS = [[0.0] for i in np.array(range(30))]+[[0]]\n",
    "print('CSV_COLUMN_NAMES:{}\\nCSV_DEFAULTS:{}'.format(CSV_COLUMN_NAMES,CSV_DEFAULTS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumericColumn(key='V1', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V2', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V3', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V4', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V5', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V6', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V7', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V8', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V9', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V10', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V11', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V12', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V13', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V14', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V15', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V16', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V17', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V18', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V19', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V20', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V21', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V22', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V23', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V24', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V25', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V26', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V27', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V28', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='Amount', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n"
     ]
    }
   ],
   "source": [
    "FEATURE_NAMES = CSV_COLUMN_NAMES[1:-1] # all but first column\n",
    "feature_cols = [tf.feature_column.numeric_column(key = k) for k in FEATURE_NAMES]\n",
    "for i in feature_cols:\n",
    "    print(i)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_row(row):\n",
    "    fields = tf.decode_csv(records = row, record_defaults = CSV_DEFAULTS)\n",
    "    features = dict(zip(CSV_COLUMN_NAMES, fields))\n",
    "    features.pop(\"Time\")\n",
    "    label = features.pop(\"Class\")\n",
    "    return features, label\n",
    "\n",
    "def read_dataset(csv_path):\n",
    "    dataset = tf.data.TextLineDataset(filenames = csv_path).skip(count = 1) # skip header\n",
    "    dataset = dataset.map(map_func = parse_row)\n",
    "    return dataset\n",
    "\n",
    "def train_input_fn(csv_path, batch_size = 128):\n",
    "    dataset = read_dataset(csv_path)\n",
    "    dataset = dataset.shuffle(buffer_size = 1000).repeat(count = None).batch(batch_size = batch_size)\n",
    "    return dataset\n",
    "\n",
    "def eval_input_fn(csv_path, batch_size = 128):\n",
    "    dataset = read_dataset(csv_path)\n",
    "    dataset = dataset.batch(batch_size = batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제 데이터 확인\n",
    "# tf.enable_eager_execution() 선언되어 있어야 함.\n",
    "#train_data_check = train_input_fn(csv_path = './input/train_smote.csv')\n",
    "#print(train_data_check.make_one_shot_iterator().get_next()[0][\"Amount\"][:10])\n",
    "#print(train_data_check.make_one_shot_iterator().get_next()[1][:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(estimator, input_fn):\n",
    "    return [x[\"class_ids\"][0] for x in model.predict(input_fn=input_fn)]\n",
    "\n",
    "def confusion_display(model, filename):\n",
    "    LABELS = [\"0\", \"1\"]\n",
    "\n",
    "    df_eval = pd.read_csv(filename)\n",
    "\n",
    "    # Create a confusion matrix on training data.\n",
    "    with tf.Graph().as_default():\n",
    "        cm = tf.confusion_matrix(df_eval[\"Class\"],get_predictions(model,  lambda: eval_input_fn(filename)))\n",
    "        with tf.Session() as session:\n",
    "            cm_out = session.run(cm)\n",
    "            print(cm_out)\n",
    "\n",
    "    # Normalize the confusion matrix so that each row sums to 1.\n",
    "    cm_out = cm_out.astype(float) \n",
    "    # / cm_out.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    print()\n",
    "    print('Class1')\n",
    "    print('precision :',cm_out[1][1]/(cm_out[0][1]+cm_out[1][1]))\n",
    "    print('recall :',cm_out[1][1]/(cm_out[1][0]+cm_out[1][1]))\n",
    "\n",
    "    #sns.heatmap(cm_out, annot=True, xticklabels=LABELS, yticklabels=LABELS);\n",
    "    #plt.xlabel(\"Predicted\");\n",
    "    #plt.ylabel(\"True\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outdir_fn(OUTDIR, unit):\n",
    "    for i, j in enumerate(unit):\n",
    "        OUTDIR = OUTDIR + \"_\" + str(j)\n",
    "    return OUTDIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_global_id_in_cluster': 0, '_task_type': 'worker', '_log_step_count_steps': 100, '_keep_checkpoint_max': 5, '_device_fn': None, '_num_worker_replicas': 1, '_model_dir': 'credit_trained_LC_LR0001_100_10', '_service': None, '_eval_distribute': None, '_experimental_distribute': None, '_evaluation_master': '', '_session_creation_timeout_secs': 7200, '_keep_checkpoint_every_n_hours': 10000, '_master': '', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2878ccf9e8>, '_train_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_save_summary_steps': 100, '_save_checkpoints_secs': None, '_protocol': None, '_is_chief': True, '_num_ps_replicas': 0, '_save_checkpoints_steps': 1000, '_task_id': 0, '_tf_random_seed': None}\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.decode_csv is deprecated. Please use tf.io.decode_csv instead.\n",
      "\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/feature_column/feature_column_v2.py:305: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/canned/linear.py:308: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into credit_trained_LC_LR0001_100_10/model.ckpt.\n",
      "INFO:tensorflow:loss = 88.722855, step = 1\n",
      "INFO:tensorflow:global_step/sec: 23.9949\n",
      "INFO:tensorflow:loss = 12.990965, step = 101 (4.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.7839\n",
      "INFO:tensorflow:loss = 11.470682, step = 201 (3.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.0313\n",
      "INFO:tensorflow:loss = 9.508873, step = 301 (3.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.4881\n",
      "INFO:tensorflow:loss = 19.987617, step = 401 (3.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.8093\n",
      "INFO:tensorflow:loss = 5.2515907, step = 501 (3.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.5567\n",
      "INFO:tensorflow:loss = 5.2179585, step = 601 (3.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.856\n",
      "INFO:tensorflow:loss = 5.64832, step = 701 (3.044 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.6069\n",
      "INFO:tensorflow:loss = 8.887987, step = 801 (3.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.41\n",
      "INFO:tensorflow:loss = 8.470151, step = 901 (3.288 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into credit_trained_LC_LR0001_100_10/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 26.6983\n",
      "INFO:tensorflow:loss = 9.733507, step = 1001 (3.746 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.4192\n",
      "INFO:tensorflow:loss = 10.202332, step = 1101 (3.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.0731\n",
      "INFO:tensorflow:loss = 9.698803, step = 1201 (3.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.6153\n",
      "INFO:tensorflow:loss = 6.176306, step = 1301 (3.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.1548\n",
      "INFO:tensorflow:loss = 19.017647, step = 1401 (3.682 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.6163\n",
      "INFO:tensorflow:loss = 10.125354, step = 1501 (3.616 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.5055\n",
      "INFO:tensorflow:loss = 11.651612, step = 1601 (3.514 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.5691\n",
      "INFO:tensorflow:loss = 10.821454, step = 1701 (3.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.7057\n",
      "INFO:tensorflow:loss = 15.30035, step = 1801 (3.609 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.2161\n",
      "INFO:tensorflow:loss = 5.3687315, step = 1901 (3.429 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into credit_trained_LC_LR0001_100_10/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5.7869196.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/ops/metrics_impl.py:2026: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-12-11T05:03:12Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from credit_trained_LC_LR0001_100_10/model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-12-11-05:03:27\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.9910027, accuracy_baseline = 0.9981786, auc = 0.9735337, auc_precision_recall = 0.7578409, average_loss = 0.05757692, global_step = 2000, label/mean = 0.0018214136, loss = 7.3493633, precision = 0.15286624, prediction/mean = 0.03526151, recall = 0.8674699\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: credit_trained_LC_LR0001_100_10/model.ckpt-2000\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from credit_trained_LC_LR0001_100_10/model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "[[45087   399]\n",
      " [   11    72]]\n",
      "\n",
      "Class1\n",
      "precision : 0.15286624203821655\n",
      "recall : 0.8674698795180723\n"
     ]
    }
   ],
   "source": [
    "unit = [100,10]\n",
    "OUTDIR = \"credit_trained_LC_LR0001\"\n",
    "OUTDIR = outdir_fn(OUTDIR, unit)\n",
    "\n",
    "config = tf.estimator.RunConfig(\n",
    "    model_dir=OUTDIR,\n",
    "#    tf_random_seed = 1,\n",
    "    keep_checkpoint_max=5,\n",
    "    save_summary_steps=100,\n",
    "    save_checkpoints_steps=1000\n",
    ")\n",
    "model = tf.estimator.LinearClassifier(feature_columns=feature_cols,\n",
    "                                      config = config\n",
    "                                     )\n",
    "os.system ('rm -r {}'.format(OUTDIR))\n",
    "model.train(input_fn = lambda : train_input_fn('./input/train_smote.csv'), max_steps = 2000)\n",
    "model.evaluate(input_fn = lambda: eval_input_fn('./input/valid.csv'))\n",
    "confusion_display(model, './input/valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_global_id_in_cluster': 0, '_task_type': 'worker', '_log_step_count_steps': 100, '_keep_checkpoint_max': 5, '_device_fn': None, '_num_worker_replicas': 1, '_model_dir': 'credit_trained_LC_LR0001_100_10', '_service': None, '_eval_distribute': None, '_experimental_distribute': None, '_evaluation_master': '', '_session_creation_timeout_secs': 7200, '_keep_checkpoint_every_n_hours': 10000, '_master': '', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f284c3489b0>, '_train_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_save_summary_steps': 100, '_save_checkpoints_secs': None, '_protocol': None, '_is_chief': True, '_num_ps_replicas': 0, '_save_checkpoints_steps': 1000, '_task_id': 0, '_tf_random_seed': None}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into credit_trained_LC_LR0001_100_10/model.ckpt.\n",
      "INFO:tensorflow:loss = 88.722855, step = 1\n",
      "INFO:tensorflow:global_step/sec: 23.1052\n",
      "INFO:tensorflow:loss = 2.45907, step = 101 (4.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.2302\n",
      "INFO:tensorflow:loss = 9.122219, step = 201 (3.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.2784\n",
      "INFO:tensorflow:loss = 1.0749319, step = 301 (3.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.175\n",
      "INFO:tensorflow:loss = 0.8890673, step = 401 (3.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.5155\n",
      "INFO:tensorflow:loss = 1.2448571, step = 501 (3.508 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.8882\n",
      "INFO:tensorflow:loss = 1.1273569, step = 601 (3.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.8508\n",
      "INFO:tensorflow:loss = 0.9080088, step = 701 (3.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.5272\n",
      "INFO:tensorflow:loss = 0.6327678, step = 801 (3.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.8328\n",
      "INFO:tensorflow:loss = 0.6078675, step = 901 (3.353 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into credit_trained_LC_LR0001_100_10/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 25.6899\n",
      "INFO:tensorflow:loss = 0.5468205, step = 1001 (3.892 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.0667\n",
      "INFO:tensorflow:loss = 0.4746819, step = 1101 (3.563 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.2736\n",
      "INFO:tensorflow:loss = 4.987054, step = 1201 (3.666 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.1209\n",
      "INFO:tensorflow:loss = 0.2357521, step = 1301 (3.687 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.746\n",
      "INFO:tensorflow:loss = 0.36284372, step = 1401 (3.742 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.2842\n",
      "INFO:tensorflow:loss = 0.4383648, step = 1501 (3.661 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.2105\n",
      "INFO:tensorflow:loss = 0.52924025, step = 1601 (3.675 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.6913\n",
      "INFO:tensorflow:loss = 0.5410459, step = 1701 (3.616 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.4322\n",
      "INFO:tensorflow:loss = 0.28051925, step = 1801 (3.512 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.7206\n",
      "INFO:tensorflow:loss = 0.26000988, step = 1901 (3.057 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into credit_trained_LC_LR0001_100_10/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.40488768.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-12-11T05:26:44Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from credit_trained_LC_LR0001_100_10/model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-12-11-05:26:56\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.99910027, accuracy_baseline = 0.9981786, auc = 0.9147738, auc_precision_recall = 0.68185854, average_loss = 0.009678838, global_step = 2000, label/mean = 0.0018214136, loss = 1.2354481, precision = 0.7916667, prediction/mean = 0.004445402, recall = 0.686747\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: credit_trained_LC_LR0001_100_10/model.ckpt-2000\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from credit_trained_LC_LR0001_100_10/model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "[[45471    15]\n",
      " [   26    57]]\n",
      "\n",
      "Class1\n",
      "precision : 0.7916666666666666\n",
      "recall : 0.6867469879518072\n"
     ]
    }
   ],
   "source": [
    "unit = [100,10]\n",
    "OUTDIR = \"credit_trained_LC_LR0001\"\n",
    "OUTDIR = outdir_fn(OUTDIR, unit)\n",
    "\n",
    "config = tf.estimator.RunConfig(\n",
    "    model_dir=OUTDIR,\n",
    "#    tf_random_seed = 1,\n",
    "    keep_checkpoint_max=5,\n",
    "    save_summary_steps=100,\n",
    "    save_checkpoints_steps=1000\n",
    ")\n",
    "model = tf.estimator.LinearClassifier(feature_columns=feature_cols,\n",
    "                                      config = config,\n",
    "                                      #optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "                                     )\n",
    "os.system ('rm -r {}'.format(OUTDIR))\n",
    "model.train(input_fn = lambda : train_input_fn('./input/train.csv'), max_steps = 2000)\n",
    "model.evaluate(input_fn = lambda: eval_input_fn('./input/valid.csv'))\n",
    "confusion_display(model, './input/valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit = [100,10]\n",
    "OUTDIR = \"credit_trained_LC_LR0001\"\n",
    "OUTDIR = outdir_fn(OUTDIR, unit)\n",
    "\n",
    "config = tf.estimator.RunConfig(\n",
    "    model_dir=OUTDIR,\n",
    "#    tf_random_seed = 1,\n",
    "    keep_checkpoint_max=5,\n",
    "    save_summary_steps=100,\n",
    "    save_checkpoints_steps=1000\n",
    ")\n",
    "model = tf.estimator.LinearClassifier(feature_columns=feature_cols,\n",
    "                                      config = config,\n",
    "                                      #optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "                                     )\n",
    "os.system ('rm -r {}'.format(OUTDIR))\n",
    "model.train(input_fn = lambda : train_input_fn('./input/train.csv'), max_steps = 2000)\n",
    "model.evaluate(input_fn = lambda: eval_input_fn('./input/valid.csv'))\n",
    "confusion_display(model, './input/valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "               Accuracy /     Recall /  Precision /         F1 /    MCC(매튜상관계수)\n",
    "LR         :    0.99923 /    0.63636 /    0.92308 /    0.75336 /    0.76609 0.6383266872319615\n",
    "Up LR      :    0.97839 /    0.88636 /    0.07130 /    0.13198 /    0.24795 0.7962401455427532\n",
    "Down LR    :    0.96500 /    0.88636 /    0.04510 /    0.08584 /    0.19550 0.7481955172850449\n",
    "smote LR   :    0.97747 /    0.88636 /    0.06858 /    0.12731 /    0.24304 0.7927680128807191"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
