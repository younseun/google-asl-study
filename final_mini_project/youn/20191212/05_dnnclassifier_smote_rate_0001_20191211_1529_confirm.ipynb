{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV_COLUMN_NAMES:['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount', 'Class']\n",
      "CSV_DEFAULTS:[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0]]\n"
     ]
    }
   ],
   "source": [
    "CSV_COLUMN_NAMES = [\"Time\"]+['V'+(i+1).astype(np.str) for i in np.array(range(28))]+['Amount','Class']\n",
    "CSV_DEFAULTS = [[0.0] for i in np.array(range(30))]+[[0]]\n",
    "print('CSV_COLUMN_NAMES:{}\\nCSV_DEFAULTS:{}'.format(CSV_COLUMN_NAMES,CSV_DEFAULTS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumericColumn(key='V1', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V2', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V3', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V4', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V5', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V6', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V7', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V8', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V9', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V10', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V11', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V12', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V13', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V14', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V15', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V16', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V17', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V18', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V19', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V20', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V21', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V22', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V23', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V24', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V25', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V26', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V27', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='V28', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='Amount', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n"
     ]
    }
   ],
   "source": [
    "FEATURE_NAMES = CSV_COLUMN_NAMES[1:-1] # all but first column\n",
    "feature_cols = [tf.feature_column.numeric_column(key = k) for k in FEATURE_NAMES]\n",
    "for i in feature_cols:\n",
    "    print(i)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_row(row):\n",
    "    fields = tf.decode_csv(records = row, record_defaults = CSV_DEFAULTS)\n",
    "    features = dict(zip(CSV_COLUMN_NAMES, fields))\n",
    "    features.pop(\"Time\")\n",
    "    label = features.pop(\"Class\")\n",
    "    return features, label\n",
    "\n",
    "def read_dataset(csv_path):\n",
    "    dataset = tf.data.TextLineDataset(filenames = csv_path).skip(count = 1) # skip header\n",
    "    dataset = dataset.map(map_func = parse_row)\n",
    "    return dataset\n",
    "\n",
    "def train_input_fn(csv_path, batch_size = 128):\n",
    "    dataset = read_dataset(csv_path)\n",
    "    dataset = dataset.shuffle(buffer_size = 1000).repeat(count = None).batch(batch_size = batch_size)\n",
    "    return dataset\n",
    "\n",
    "def eval_input_fn(csv_path, batch_size = 128):\n",
    "    dataset = read_dataset(csv_path)\n",
    "    dataset = dataset.batch(batch_size = batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제 데이터 확인\n",
    "# tf.enable_eager_execution() 선언되어 있어야 함.\n",
    "#train_data_check = train_input_fn(csv_path = './input/train_smote.csv')\n",
    "#print(train_data_check.make_one_shot_iterator().get_next()[0][\"Amount\"][:10])\n",
    "#print(train_data_check.make_one_shot_iterator().get_next()[1][:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(estimator, input_fn):\n",
    "    return [x[\"class_ids\"][0] for x in model.predict(input_fn=input_fn)]\n",
    "\n",
    "def confusion_display(model, filename):\n",
    "    LABELS = [\"0\", \"1\"]\n",
    "\n",
    "    df_eval = pd.read_csv(filename)\n",
    "\n",
    "    # Create a confusion matrix on training data.\n",
    "    with tf.Graph().as_default():\n",
    "        cm = tf.confusion_matrix(df_eval[\"Class\"],get_predictions(model,  lambda: eval_input_fn(filename)))\n",
    "        with tf.Session() as session:\n",
    "            cm_out = session.run(cm)\n",
    "            print(cm_out)\n",
    "\n",
    "    # Normalize the confusion matrix so that each row sums to 1.\n",
    "    cm_out = cm_out.astype(float) \n",
    "    # / cm_out.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    print()\n",
    "    print('Class1')\n",
    "    print('precision :',cm_out[1][1]/(cm_out[0][1]+cm_out[1][1]))\n",
    "    print('recall :',cm_out[1][1]/(cm_out[1][0]+cm_out[1][1]))\n",
    "\n",
    "    #sns.heatmap(cm_out, annot=True, xticklabels=LABELS, yticklabels=LABELS);\n",
    "    #plt.xlabel(\"Predicted\");\n",
    "    #plt.ylabel(\"True\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outdir_fn(OUTDIR, unit):\n",
    "    for i, j in enumerate(unit):\n",
    "        OUTDIR = OUTDIR + \"_\" + str(j)\n",
    "    return OUTDIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_eval_distribute': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f88a34ad4a8>, '_evaluation_master': '', '_device_fn': None, '_task_type': 'worker', '_service': None, '_experimental_max_worker_delay_secs': None, '_tf_random_seed': None, '_experimental_distribute': None, '_train_distribute': None, '_log_step_count_steps': 100, '_save_checkpoints_secs': None, '_protocol': None, '_save_summary_steps': 100, '_model_dir': 'credit_trained_LR0001_100_10', '_session_creation_timeout_secs': 7200, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_master': '', '_global_id_in_cluster': 0, '_task_id': 0, '_keep_checkpoint_every_n_hours': 10000, '_num_worker_replicas': 1, '_save_checkpoints_steps': 1000, '_is_chief': True, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      "}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into credit_trained_LR0001_100_10/model.ckpt.\n",
      "INFO:tensorflow:loss = 1197.3269, step = 1\n",
      "INFO:tensorflow:global_step/sec: 19.8259\n",
      "INFO:tensorflow:loss = 58.80391, step = 101 (5.046 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6036\n",
      "INFO:tensorflow:loss = 42.812096, step = 201 (4.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.114\n",
      "INFO:tensorflow:loss = 29.963598, step = 301 (4.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.3806\n",
      "INFO:tensorflow:loss = 25.649075, step = 401 (4.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.3296\n",
      "INFO:tensorflow:loss = 17.091848, step = 501 (4.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.7981\n",
      "INFO:tensorflow:loss = 36.094444, step = 601 (4.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.8124\n",
      "INFO:tensorflow:loss = 14.628234, step = 701 (4.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8744\n",
      "INFO:tensorflow:loss = 24.635742, step = 801 (4.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.556\n",
      "INFO:tensorflow:loss = 14.179332, step = 901 (4.240 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into credit_trained_LR0001_100_10/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 23.1271\n",
      "INFO:tensorflow:loss = 11.96709, step = 1001 (4.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.6783\n",
      "INFO:tensorflow:loss = 21.776005, step = 1101 (4.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.5124\n",
      "INFO:tensorflow:loss = 14.600983, step = 1201 (4.079 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.3917\n",
      "INFO:tensorflow:loss = 14.942844, step = 1301 (4.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.2038\n",
      "INFO:tensorflow:loss = 9.962015, step = 1401 (4.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.9088\n",
      "INFO:tensorflow:loss = 7.5002584, step = 1501 (3.860 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2487\n",
      "INFO:tensorflow:loss = 4.1812105, step = 1601 (3.960 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.5699\n",
      "INFO:tensorflow:loss = 15.382193, step = 1701 (4.071 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.0943\n",
      "INFO:tensorflow:loss = 6.2782536, step = 1801 (3.690 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.7474\n",
      "INFO:tensorflow:loss = 7.496848, step = 1901 (4.045 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into credit_trained_LR0001_100_10/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 7.918438.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-12-11T05:38:43Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from credit_trained_LR0001_100_10/model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-12-11-05:38:59\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.9955452, accuracy_baseline = 0.9981786, auc = 0.95506275, auc_precision_recall = 0.7787886, average_loss = 0.055212133, global_step = 2000, label/mean = 0.0018214136, loss = 7.0475116, precision = 0.27272728, prediction/mean = 0.038631983, recall = 0.8674699\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: credit_trained_LR0001_100_10/model.ckpt-2000\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from credit_trained_LR0001_100_10/model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "[[45294   192]\n",
      " [   11    72]]\n",
      "\n",
      "Class1\n",
      "precision : 0.2727272727272727\n",
      "recall : 0.8674698795180723\n"
     ]
    }
   ],
   "source": [
    "unit = [100,10]\n",
    "OUTDIR = \"credit_trained_LR0001\"\n",
    "OUTDIR = outdir_fn(OUTDIR, unit)\n",
    "\n",
    "config = tf.estimator.RunConfig(\n",
    "    model_dir=OUTDIR,\n",
    "    tf_random_seed = 1,\n",
    "    keep_checkpoint_max=5,\n",
    "    save_summary_steps=100,\n",
    "    save_checkpoints_steps=1000\n",
    ")\n",
    "model = tf.estimator.DNNClassifier(\n",
    "                                  hidden_units=unit,\n",
    "                                  feature_columns=feature_cols,\n",
    "                                  optimizer = tf.train.AdamOptimizer(learning_rate=0.001),\n",
    "                                  dropout=0.2,\n",
    "                                  config = config)\n",
    "\n",
    "os.system ('rm -r {}'.format(OUTDIR))\n",
    "model.train(input_fn = lambda : train_input_fn('./input/train_smote.csv'), max_steps = 2000)\n",
    "model.evaluate(input_fn = lambda: eval_input_fn('./input/valid.csv'))\n",
    "confusion_display(model, './input/valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
