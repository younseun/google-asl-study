{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = \"qwiklabs-gcp-ml-49b827b781ab\"  # Replace with your PROJECT\n",
    "BUCKET = \"qwiklabs-gcp-ml-49b827b781ab\"  # Replace with your BUCKET\n",
    "REGION = \"us-central1\"            # Choose an available region for AI Platform Training Service\n",
    "TFVERSION = \"1.14\"                # TF version for AI Platform Training Service to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Creating gs://qwiklabs-gcp-ml-49b827b781ab/...\n",
      "ServiceException: 409 Bucket qwiklabs-gcp-ml-49b827b781ab already exists.\n",
      "CommandException: No URLs matched: *.csv\n",
      "CommandException: 1 file/object could not be transferred.\n"
     ]
    }
   ],
   "source": [
    "!gcloud config set project {PROJECT}\n",
    "!gsutil mb -l {REGION} gs://{BUCKET}\n",
    "!gsutil -m cp *.csv gs://{BUCKET}/taxifare/smallinput/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://cloud-training-demos/taxifare/small/taxi-test.csv...\n",
      "Copying gs://cloud-training-demos/taxifare/small/taxi-train.csv...              \n",
      "Copying gs://cloud-training-demos/taxifare/small/taxi-valid.csv...              \n",
      "/ [3 files][ 10.9 MiB/ 10.9 MiB]                                                \n",
      "Operation completed over 3 objects/10.9 MiB.                                     \n",
      "-rw-r--r-- 1 jupyter jupyter 1799474 Dec  5 14:27 taxi-test.csv\n",
      "-rw-r--r-- 1 jupyter jupyter 7986353 Dec  5 14:27 taxi-train.csv\n",
      "-rw-r--r-- 1 jupyter jupyter 1673742 Dec  5 14:27 taxi-valid.csv\n"
     ]
    }
   ],
   "source": [
    "!gsutil cp gs://cloud-training-demos/taxifare/small/*.csv .\n",
    "!ls -l *.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir taxifaremodel\n",
    "touch taxifaremodel/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing taxifaremodel/model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile taxifaremodel/model.py\n",
    "import tensorflow as tf\n",
    "import shutil\n",
    "\n",
    "CSV_COLUMN_NAMES = [\"fare_amount\",\"dayofweek\",\"hourofday\",\"pickuplon\",\"pickuplat\",\"dropofflon\",\"dropofflat\"]\n",
    "CSV_DEFAULTS = [[0.0],[1],[0],[-74.0], [40.0], [-74.0], [40.7]]\n",
    "FEATURE_NAMES = CSV_COLUMN_NAMES[1:]\n",
    "\n",
    "def parse_row(row):\n",
    "    fields = tf.decode_csv(records = row, record_defaults = CSV_DEFAULTS)\n",
    "    features = dict(zip(CSV_COLUMN_NAMES, fields))\n",
    "    label = features.pop(\"fare_amount\")\n",
    "    return features, label\n",
    "\n",
    "def read_dataset(csv_path):\n",
    "    dataset = tf.data.Dataset.list_files(file_pattern = csv_path)\n",
    "    dataset = dataset.flat_map(lambda filename: tf.data.TextLineDataset(filenames = filename).skip(count = 1))\n",
    "    dataset = dataset.map(map_func = parse_row)\n",
    "    return dataset\n",
    "\n",
    "def train_input_fn(csv_path, batch_size = 128):\n",
    "    dataset = read_dataset(csv_path)\n",
    "    dataset = dataset.shuffle(buffer_size = 1000).repeat(count = None).batch(batch_size = batch_size)\n",
    "    return dataset\n",
    "\n",
    "def eval_input_fn(csv_path, batch_size = 128):\n",
    "    dataset = read_dataset(csv_path)\n",
    "    dataset = dataset.batch(batch_size = batch_size)\n",
    "    return dataset\n",
    "  \n",
    "def serving_input_receiver_fn():\n",
    "    receiver_tensors = {\n",
    "        \"dayofweek\" : tf.placeholder(dtype = tf.int32, shape = [None]), \n",
    "        \"hourofday\" : tf.placeholder(dtype = tf.int32, shape = [None]),\n",
    "        \"pickuplon\" : tf.placeholder(dtype = tf.float32, shape = [None]), \n",
    "        \"pickuplat\" : tf.placeholder(dtype = tf.float32, shape = [None]),\n",
    "        \"dropofflat\" : tf.placeholder(dtype = tf.float32, shape = [None]),\n",
    "        \"dropofflon\" : tf.placeholder(dtype = tf.float32, shape = [None])\n",
    "    }\n",
    "    \n",
    "    features = receiver_tensors\n",
    "    \n",
    "    return tf.estimator.export.ServingInputReceiver(features = features, receiver_tensors = receiver_tensors)\n",
    "      \n",
    "def my_rmse(labels, predictions):\n",
    "    pred_values = tf.squeeze(input = predictions[\"predictions\"], axis = -1)\n",
    "    return {\"rmse\": tf.metrics.root_mean_squared_error(labels = labels, predictions = pred_values)}\n",
    "\n",
    "def create_model(model_dir, train_steps):\n",
    "    config = tf.estimator.RunConfig(\n",
    "        tf_random_seed = 1,\n",
    "        save_checkpoints_steps = max(10, train_steps // 10),\n",
    "        model_dir = model_dir\n",
    "    )\n",
    "    \n",
    "    feature_cols = [tf.feature_column.numeric_column(key = k) for k in FEATURE_NAMES]\n",
    "    \n",
    "    model = tf.estimator.DNNRegressor(\n",
    "        hidden_units = [10,10],\n",
    "        feature_columns = feature_cols, \n",
    "        config = config\n",
    "    )\n",
    "    \n",
    "    model = tf.contrib.estimator.add_metrics(model, my_rmse)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_and_evaluate(params):\n",
    "    OUTDIR = params[\"output_dir\"]\n",
    "    TRAIN_DATA_PATH = params[\"train_data_path\"]\n",
    "    EVAL_DATA_PATH = params[\"eval_data_path\"]\n",
    "    TRAIN_STEPS = params[\"train_steps\"]\n",
    "\n",
    "    model = create_model(OUTDIR, TRAIN_STEPS)\n",
    "\n",
    "    train_spec = tf.estimator.TrainSpec(\n",
    "        input_fn = lambda: train_input_fn(TRAIN_DATA_PATH),\n",
    "        max_steps = TRAIN_STEPS\n",
    "    )    \n",
    "    exporter = tf.estimator.FinalExporter(name = \"exporter\", serving_input_receiver_fn = serving_input_receiver_fn)\n",
    "    \n",
    "    eval_spec = tf.estimator.EvalSpec(\n",
    "        input_fn = lambda: eval_input_fn(EVAL_DATA_PATH),\n",
    "        steps = None,\n",
    "        start_delay_secs = 1,\n",
    "        throttle_secs = 1,\n",
    "        exporters = exporter\n",
    "    )\n",
    "    \n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "    \n",
    "    shutil.rmtree(path = OUTDIR, ignore_errors = True)\n",
    "\n",
    "    tf.estimator.train_and_evaluate(estimator = model, train_spec = train_spec, eval_spec = eval_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing taxifaremodel/task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile taxifaremodel/task.py\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "\n",
    "from . import model\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    parser.add_argument(\n",
    "        \"--train_data_path\",\n",
    "        help = \"GCS or local path to training data\",\n",
    "        required = True\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--train_steps\",\n",
    "        help = \"Steps to run the training job for (default: 1000)\",\n",
    "        type = int,\n",
    "        default = 1000\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--eval_data_path\",\n",
    "        help = \"GCS or local path to evaluation data\",\n",
    "        required = True\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--output_dir\",\n",
    "        help = \"GCS location to write checkpoints and export models\",\n",
    "        required = True\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--job-dir\",\n",
    "        help = \"This is not used by our model, but it is required by gcloud\",\n",
    "    )\n",
    "    args = parser.parse_args().__dict__\n",
    "\n",
    "    model.train_and_evaluate(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From taxifaremodel/model.py:89: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "WARNING:tensorflow:From taxifaremodel/model.py:89: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 10 or save_checkpoints_secs None.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/training/training_util.py:236: initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/data/util/random_seed.py:58: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/api/_v1/estimator/__init__.py:12: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.decode_csv is deprecated. Please use tf.io.decode_csv instead.\n",
      "\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling __init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/canned/head.py:437: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/training/adagrad.py:76: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2019-12-05 14:27:38.335256: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  AVX2 FMA\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2019-12-05 14:27:38.343808: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
      "2019-12-05 14:27:38.344861: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561211cf3890 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2019-12-05 14:27:38.344891: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2019-12-05 14:27:38.345737: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into taxi_trained/model.ckpt.\n",
      "INFO:tensorflow:loss = 115167.44, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 1 into taxi_trained/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "WARNING:tensorflow:From taxifaremodel/model.py:46: The name tf.metrics.root_mean_squared_error is deprecated. Please use tf.compat.v1.metrics.root_mean_squared_error instead.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-12-05T14:27:39Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from taxi_trained/model.ckpt-1\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-12-05-14:27:42\n",
      "INFO:tensorflow:Saving dict for global step 1: average_loss = 217.2701, global_step = 1, label/mean = 11.229713, loss = 27765.2, prediction/mean = -0.03998277, rmse = 14.740085\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1: taxi_trained/model.ckpt-1\n",
      "INFO:tensorflow:Performing the final export in the end of training.\n",
      "WARNING:tensorflow:From taxifaremodel/model.py:32: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO:tensorflow:'serving_default' : Regression input must be a single string Tensor; got {'dayofweek': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=int32>, 'pickuplat': <tf.Tensor 'Placeholder_3:0' shape=(?,) dtype=float32>, 'dropofflat': <tf.Tensor 'Placeholder_4:0' shape=(?,) dtype=float32>, 'hourofday': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=int32>, 'pickuplon': <tf.Tensor 'Placeholder_2:0' shape=(?,) dtype=float32>, 'dropofflon': <tf.Tensor 'Placeholder_5:0' shape=(?,) dtype=float32>}\n",
      "INFO:tensorflow:'regression' : Regression input must be a single string Tensor; got {'dayofweek': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=int32>, 'pickuplat': <tf.Tensor 'Placeholder_3:0' shape=(?,) dtype=float32>, 'dropofflat': <tf.Tensor 'Placeholder_4:0' shape=(?,) dtype=float32>, 'hourofday': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=int32>, 'pickuplon': <tf.Tensor 'Placeholder_2:0' shape=(?,) dtype=float32>, 'dropofflon': <tf.Tensor 'Placeholder_5:0' shape=(?,) dtype=float32>}\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "INFO:tensorflow:Restoring parameters from taxi_trained/model.ckpt-1\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: taxi_trained/export/exporter/temp-1575556063/saved_model.pb\n",
      "INFO:tensorflow:Loss for final step: 115167.44.\n",
      "CPU times: user 180 ms, sys: 72 ms, total: 252 ms\n",
      "Wall time: 8.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!gcloud ai-platform local train \\\n",
    "    --package-path=taxifaremodel \\\n",
    "    --module-name=taxifaremodel.task \\\n",
    "    -- \\\n",
    "    --train_data_path=taxi-train.csv \\\n",
    "    --eval_data_path=taxi-valid.csv  \\\n",
    "    --train_steps=1 \\\n",
    "    --output_dir=taxi_trained "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTDIR = \"gs://{}/taxifare/trained_small\".format(BUCKET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gs://qwiklabs-gcp-ml-49b827b781ab/taxifare/trained_small/#1574401743465196...\n",
      "Removing gs://qwiklabs-gcp-ml-49b827b781ab/taxifare/trained_small/checkpoint#1574401874746997...\n",
      "Removing gs://qwiklabs-gcp-ml-49b827b781ab/taxifare/trained_small/eval/#1574401765858330...\n",
      "Removing gs://qwiklabs-gcp-ml-49b827b781ab/taxifare/trained_small/eval/events.out.tfevents.1574401765.cmle-training-12332736599289437873#1574401881625500...\n",
      "Removing gs://qwiklabs-gcp-ml-49b827b781ab/taxifare/trained_small/events.out.tfevents.1574401743.cmle-training-12332736599289437873#1574401892297394...\n",
      "Removing gs://qwiklabs-gcp-ml-49b827b781ab/taxifare/trained_small/export/#1574401882654989...\n",
      "Removing gs://qwiklabs-gcp-ml-49b827b781ab/taxifare/trained_small/export/exporter/#1574401883071670...\n",
      "Removing gs://qwiklabs-gcp-ml-49b827b781ab/taxifare/trained_small/export/exporter/1574401881/#1574401890248355...\n",
      "Removing gs://qwiklabs-gcp-ml-49b827b781ab/taxifare/trained_small/export/exporter/1574401881/saved_model.pb#1574401890590319...\n",
      "Removing gs://qwiklabs-gcp-ml-49b827b781ab/taxifare/trained_small/export/exporter/1574401881/variables/#1574401890906140...\n",
      "Removing gs://qwiklabs-gcp-ml-49b827b781ab/taxifare/trained_small/export/exporter/1574401881/variables/variables.data-00000-of-00002#1574401891229293...\n",
      "Removing gs://qwiklabs-gcp-ml-49b827b781ab/taxifare/trained_small/export/exporter/1574401881/variables/variables.data-00001-of-00002#1574401891595082...\n",
      "Removing gs://qwiklabs-gcp-ml-49b827b781ab/taxifare/trained_small/export/exporter/1574401881/variables/variables.index#1574401891899637...\n",
      "Removing gs://qwiklabs-gcp-ml-49b827b781ab/taxifare/trained_small/graph.pbtxt#1574401745724109...\n",
      "Removing gs://qwiklabs-gcp-ml-49b827b781ab/taxifare/trained_small/model.ckpt-1000.data-00000-of-00002#1574401873228933...\n",
      "Removing gs://qwiklabs-gcp-ml-49b827b781ab/taxifare/trained_small/model.ckpt-1000.data-00001-of-00002#1574401872712685...\n",
      "Removing gs://qwiklabs-gcp-ml-49b827b781ab/taxifare/trained_small/model.ckpt-1000.index#1574401873640988...\n",
      "Removing gs://qwiklabs-gcp-ml-49b827b781ab/taxifare/trained_small/model.ckpt-1000.meta#1574401876423644...\n",
      "Removing gs://qwiklabs-gcp-ml-49b827b781ab/taxifare/trained_small/model.ckpt-600.data-00000-of-00002#1574401821902193...\n",
      "Removing gs://qwiklabs-gcp-ml-49b827b781ab/taxifare/trained_small/model.ckpt-600.data-00001-of-00002#1574401821496359...\n",
      "Removing gs://qwiklabs-gcp-ml-49b827b781ab/taxifare/trained_small/model.ckpt-600.index#1574401822394072...\n",
      "Removing gs://qwiklabs-gcp-ml-49b827b781ab/taxifare/trained_small/model.ckpt-600.meta#1574401825028981...\n",
      "Removing gs://qwiklabs-gcp-ml-49b827b781ab/taxifare/trained_small/model.ckpt-700.data-00000-of-00002#1574401834948716...\n",
      "Removing gs://qwiklabs-gcp-ml-49b827b781ab/taxifare/trained_small/model.ckpt-700.data-00001-of-00002#1574401834187986...\n",
      "Removing gs://qwiklabs-gcp-ml-49b827b781ab/taxifare/trained_small/model.ckpt-700.index#1574401835379234...\n",
      "Removing gs://qwiklabs-gcp-ml-49b827b781ab/taxifare/trained_small/model.ckpt-800.data-00000-of-00002#1574401847869129...\n",
      "Removing gs://qwiklabs-gcp-ml-49b827b781ab/taxifare/trained_small/model.ckpt-800.data-00001-of-00002#1574401847471966...\n",
      "Removing gs://qwiklabs-gcp-ml-49b827b781ab/taxifare/trained_small/model.ckpt-800.index#1574401848382997...\n",
      "Removing gs://qwiklabs-gcp-ml-49b827b781ab/taxifare/trained_small/model.ckpt-800.meta#1574401851220234...\n",
      "Removing gs://qwiklabs-gcp-ml-49b827b781ab/taxifare/trained_small/model.ckpt-900.data-00000-of-00002#1574401860641584...\n",
      "Removing gs://qwiklabs-gcp-ml-49b827b781ab/taxifare/trained_small/model.ckpt-900.data-00001-of-00002#1574401860249141...\n",
      "Removing gs://qwiklabs-gcp-ml-49b827b781ab/taxifare/trained_small/model.ckpt-700.meta#1574401838217027...\n",
      "Removing gs://qwiklabs-gcp-ml-49b827b781ab/taxifare/trained_small/model.ckpt-900.index#1574401861011314...\n",
      "Removing gs://qwiklabs-gcp-ml-49b827b781ab/taxifare/trained_small/model.ckpt-900.meta#1574401863667056...\n",
      "/ [34/34 objects] 100% Done                                                     \n",
      "Operation completed over 34 objects.                                             \n",
      "Job [taxifare_191205_142839] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs describe taxifare_191205_142839\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs stream-logs taxifare_191205_142839\n",
      "jobId: taxifare_191205_142839\n",
      "state: QUEUED\n"
     ]
    }
   ],
   "source": [
    "!gsutil -m rm -rf {OUTDIR} # start fresh each time\n",
    "!gcloud ai-platform jobs submit training taxifare_$(date -u +%y%m%d_%H%M%S) \\\n",
    "    --package-path=taxifaremodel \\\n",
    "    --module-name=taxifaremodel.task \\\n",
    "    --job-dir=gs://{BUCKET}/taxifare \\\n",
    "    --python-version=3.5 \\\n",
    "    --runtime-version={TFVERSION} \\\n",
    "    --region={REGION} \\\n",
    "    -- \\\n",
    "    --train_data_path=gs://{BUCKET}/taxifare/smallinput/taxi-train.csv \\\n",
    "    --eval_data_path=gs://{BUCKET}/taxifare/smallinput/taxi-valid.csv  \\\n",
    "    --train_steps=1000 \\\n",
    "    --output_dir={OUTDIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
