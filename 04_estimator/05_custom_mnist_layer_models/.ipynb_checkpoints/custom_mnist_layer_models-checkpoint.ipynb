{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import shutil\n",
    "import os\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist/data/train-images-idx3-ubyte.gz\n",
      "Extracting mnist/data/train-labels-idx1-ubyte.gz\n",
      "Extracting mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting mnist/data/t10k-labels-idx1-ubyte.gz\n",
      "(55000, 28, 28, 1)\n",
      "(55000, 10)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"mnist/data\", one_hot = True, reshape = False)\n",
    "print(mnist.train.images.shape)\n",
    "print(mnist.train.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 28\n",
    "WIDTH = 28\n",
    "NCLASSES = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "IMGNO = 12\n",
    "plt.imshow(mnist.test.images[IMGNO].reshape(HEIGHT, WIDTH));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Keras Model Using Keras Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_model(img, mode, hparams):\n",
    "    X = tf.reshape(tensor = img, shape = [-1,HEIGHT * WIDTH]) #flatten\n",
    "    ylogits = tf.layers.dense(input = X, units = NCLASSES, activation = None)\n",
    "    return ylogits, NCLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnn_model(img, mode, hparams):\n",
    "    X = tf.reshape(tensor = img, shape = [-1, HEIGHT * WIDTH]) #flatten\n",
    "    h1 = tf.layers.dense(inputs = X, units = 300, activation = tf.nn.relu)\n",
    "    h2 = tf.layers.dense(inputs = h1, units = 100, activation = tf.nn.relu)\n",
    "    h3 = tf.layers.dense(inputs = h2, units = 30, activation = tf.nn.relu)\n",
    "    ylogits = tf.layers.dense(inputs = h3, units = NCLASSES, activation = None)\n",
    "    return ylogits, NCLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnn_dropout_model(img, mode, hparams):\n",
    "    dprob = hparams.get(\"dprob\", 0.1)\n",
    "\n",
    "    X = tf.reshape(tensor = img, shape = [-1, HEIGHT * WIDTH]) #flatten\n",
    "    h1 = tf.layers.dense(inputs = X, units = 300, activation = tf.nn.relu)\n",
    "    h2 = tf.layers.dense(inputs = h1, units = 100, activation = tf.nn.relu)\n",
    "    h3 = tf.layers.dense(inputs = h2, units = 30, activation = tf.nn.relu)\n",
    "    h3d = tf.layers.dropout(inputs = h3, rate = dprob, training = (mode == tf.estimator.ModeKeys.TRAIN)) #only dropout when training\n",
    "    ylogits = tf.layers.dense(inputs = h3d, units = NCLASSES, activation = None)\n",
    "    return ylogits, NCLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model(img, mode, hparams):\n",
    "    ksize1 = hparams.get(\"ksize1\", 5)\n",
    "    ksize2 = hparams.get(\"ksize2\", 5)\n",
    "    nfil1 = hparams.get(\"nfil1\", 10)\n",
    "    nfil2 = hparams.get(\"nfil2\", 20)\n",
    "    dprob = hparams.get(\"dprob\", 0.25)\n",
    "\n",
    "    c1 = tf.layers.conv2d(inputs = img, filters = nfil1,\n",
    "                          kernel_size = ksize1, strides = 1,\n",
    "                          padding = \"same\", activation = tf.nn.relu) # shape = (batch_size, HEIGHT, WIDTH, nfil1)\n",
    "    \n",
    "    p1 = tf.layers.max_pooling2d(inputs = c1, pool_size = 2, strides = 2) # shape = (batch_size, HEIGHT // 2, WIDTH // 2, nfil1)\n",
    "    \n",
    "    c2 = tf.layers.conv2d(inputs = p1, filters = nfil2,\n",
    "                          kernel_size = ksize2, strides = 1, \n",
    "                          padding = \"same\", activation = tf.nn.relu) # shape = (batch_size, HEIGHT // 2, WIDTH // 2, nfil2)\n",
    "    \n",
    "    p2 = tf.layers.max_pooling2d(inputs = c2, pool_size = 2, strides = 2) # shape = (batch_size, HEIGHT // 4, WIDTH // 4, nfil2)\n",
    "\n",
    "    outlen = p2.shape[1] * p2.shape[2] * p2.shape[3] # HEIGHT // 4 * WIDTH // 4 * nfil2\n",
    "    p2flat = tf.reshape(tensor = p2, shape = [-1, outlen]) # shape = (batch_size, HEIGHT // 4 * WIDTH // 4 * nfil2)\n",
    "\n",
    "    # Apply batch normalization\n",
    "    if hparams[\"batch_norm\"]:\n",
    "        h3 = tf.layers.dense(inputs = p2flat, units = 300, activation = None)\n",
    "        h3 = tf.layers.batch_normalization(inputs = h3, training = (mode == tf.estimator.ModeKeys.TRAIN)) # only batchnorm when training\n",
    "        h3 = tf.nn.relu(features = h3)\n",
    "    else:  \n",
    "        h3 = tf.layers.dense(inputs = p2flat, units = 300, activation = tf.nn.relu)\n",
    "  \n",
    "    # Apply dropout\n",
    "    h3d = tf.layers.dropout(inputs = h3, rate = dprob, training = (mode == tf.estimator.ModeKeys.TRAIN))\n",
    "\n",
    "    ylogits = tf.layers.dense(inputs = h3d, units = NCLASSES, activation = None)\n",
    "  \n",
    "    # Apply batch normalization once more\n",
    "    if hparams[\"batch_norm\"]:\n",
    "        ylogits = tf.layers.batch_normalization(inputs = ylogits, training = (mode == tf.estimator.ModeKeys.TRAIN))\n",
    "\n",
    "    return ylogits, NCLASSES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write Input Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_fn():\n",
    "    # Input will be rank 3\n",
    "    feature_placeholders = {\"image\": tf.placeholder(dtype = tf.float32, shape = [None, HEIGHT, WIDTH])}\n",
    "    # But model function requires rank 4\n",
    "    features = {\"image\": tf.expand_dims(input = feature_placeholders[\"image\"], axis = -1)} \n",
    "    return tf.estimator.export.ServingInputReceiver(features = features, receiver_tensors = feature_placeholders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write Custom Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_classifier(features, labels, mode, params):\n",
    "    model_functions = {\n",
    "        \"linear\": linear_model,\n",
    "        \"dnn\": dnn_model,\n",
    "        \"dnn_dropout\": dnn_dropout_model,\n",
    "        \"cnn\": cnn_model}\n",
    "    \n",
    "    model_function = model_functions[params[\"model\"]]\n",
    "    \n",
    "    ylogits, nclasses = model_function(features[\"image\"], mode, params)\n",
    "\n",
    "    probabilities = tf.nn.softmax(logits = ylogits)\n",
    "    class_ids = tf.cast(x = tf.argmax(input = probabilities, axis = 1), dtype = tf.uint8)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN or mode == tf.estimator.ModeKeys.EVAL:\n",
    "        loss = tf.reduce_mean(input_tensor = tf.nn.softmax_cross_entropy_with_logits_v2(logits = ylogits, labels = labels))\n",
    "        \n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            # This is needed for batch normalization, but has no effect otherwise\n",
    "            update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "            with tf.control_dependencies(update_ops):\n",
    "                train_op = tf.contrib.layers.optimize_loss(\n",
    "                    loss = loss, \n",
    "                    global_step = tf.train.get_global_step(),\n",
    "                    learning_rate = params[\"learning_rate\"], \n",
    "                    optimizer = \"Adam\")\n",
    "            eval_metric_ops = None\n",
    "        else:\n",
    "            train_op = None\n",
    "            eval_metric_ops =  {\"accuracy\": tf.metrics.accuracy(labels = tf.argmax(input = labels, axis = 1), predictions = class_ids)}\n",
    "    else:\n",
    "        loss = None\n",
    "        train_op = None\n",
    "        eval_metric_ops = None\n",
    " \n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode = mode,\n",
    "        predictions = {\"probabilities\": probabilities, \"class_ids\": class_ids},\n",
    "        loss = loss,\n",
    "        train_op = train_op,\n",
    "        eval_metric_ops = eval_metric_ops,\n",
    "        export_outputs = {\"predictions\":tf.estimator.export.PredictOutput({\"probabilities\": probabilities, \"class_ids\": class_ids})}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(output_dir, hparams):\n",
    "    tf.summary.FileWriterCache.clear() # ensure filewriter cache is clear for TensorBoard events file\n",
    "    \n",
    "    EVAL_INTERVAL = 60\n",
    "    \n",
    "    mnist = input_data.read_data_sets(\"mnist/data\", one_hot = True, reshape = False)\n",
    "    \n",
    "    train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x = {\"image\": mnist.train.images},\n",
    "        y = mnist.train.labels,\n",
    "        batch_size = 100,\n",
    "        num_epochs = None,\n",
    "        shuffle = True,\n",
    "        queue_capacity = 5000\n",
    "    )\n",
    "\n",
    "    eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x = {\"image\": mnist.test.images},\n",
    "        y = mnist.test.labels,\n",
    "        batch_size = 100,\n",
    "        num_epochs = 1,\n",
    "        shuffle = False,\n",
    "        queue_capacity = 5000\n",
    "    )\n",
    "\n",
    "    estimator = tf.estimator.Estimator(\n",
    "        model_fn = image_classifier,\n",
    "        model_dir = output_dir,\n",
    "        params = hparams)\n",
    "\n",
    "    train_spec = tf.estimator.TrainSpec(\n",
    "        input_fn = train_input_fn,\n",
    "        max_steps = hparams[\"train_steps\"])\n",
    "\n",
    "    exporter = tf.estimator.LatestExporter(name = \"exporter\", serving_input_receiver_fn = serving_input_fn)\n",
    "\n",
    "    eval_spec = tf.estimator.EvalSpec(\n",
    "        input_fn = eval_input_fn,\n",
    "        steps = None,\n",
    "        exporters = exporter)\n",
    "\n",
    "    tf.estimator.train_and_evaluate(estimator = estimator, train_spec = train_spec, eval_spec = eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델별로 실행(linear / dnn / dnn_dropout / cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> mnist/learned_linear\n",
      "Extracting mnist/data/train-images-idx3-ubyte.gz\n",
      "Extracting mnist/data/train-labels-idx1-ubyte.gz\n",
      "Extracting mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting mnist/data/t10k-labels-idx1-ubyte.gz\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'mnist/learned_linear', '_experimental_distribute': None, '_keep_checkpoint_every_n_hours': 10000, '_eval_distribute': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe0d51a46a0>, '_save_checkpoints_steps': None, '_service': None, '_tf_random_seed': None, '_device_fn': None, '_master': '', '_evaluation_master': '', '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_keep_checkpoint_max': 5, '_train_distribute': None, '_task_type': 'worker', '_is_chief': True, '_global_id_in_cluster': 0, '_log_step_count_steps': 100, '_session_creation_timeout_secs': 7200, '_save_checkpoints_secs': 600, '_protocol': None, '_experimental_max_worker_delay_secs': None, '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "dense() got an unexpected keyword argument 'input'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-e8b931763c58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTDIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_errors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# start fresh each time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'>>>>'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mOUTDIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOUTDIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-107-80ba0d3ecd7d>\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(output_dir, hparams)\u001b[0m\n\u001b[1;32m     40\u001b[0m         exporters = exporter)\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(estimator, train_spec, eval_spec)\u001b[0m\n\u001b[1;32m    471\u001b[0m         '(with task id 0).  Given task id {}'.format(config.task_id))\n\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    611\u001b[0m         config.task_type != run_config_lib.TaskType.EVALUATOR):\n\u001b[1;32m    612\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Running training and evaluation locally (non-distributed).'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m     \u001b[0;31m# Distributed case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\u001b[0m in \u001b[0;36mrun_local\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m         \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_hooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m         saving_listeners=saving_listeners)\n\u001b[0m\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m     eval_result = listener_for_eval.eval_result or _EvalResult(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1159\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1189\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m       estimator_spec = self._call_model_fn(\n\u001b[0;32m-> 1191\u001b[0;31m           features, labels, ModeKeys.TRAIN, self.config)\n\u001b[0m\u001b[1;32m   1192\u001b[0m       \u001b[0mglobal_step_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_global_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-106-312799b8bea2>\u001b[0m in \u001b[0;36mimage_classifier\u001b[0;34m(features, labels, mode, params)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmodel_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_functions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mylogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mylogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-101-8c7a569d368b>\u001b[0m in \u001b[0;36mlinear_model\u001b[0;34m(img, mode, hparams)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mHEIGHT\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mWIDTH\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#flatten\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mylogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNCLASSES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mylogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNCLASSES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: dense() got an unexpected keyword argument 'input'"
     ]
    }
   ],
   "source": [
    "hparams = {\"model\": \"linear\",            \n",
    "           \"ksize1\": 5,               \"nfil1\": 10,\n",
    "           \"ksize2\": 5,               \"nfil2\": 20,\n",
    "           \"batch_norm\": False,       \"dprob\": 0.25,\n",
    "           \"train_steps\": 1000,       \"learning_rate\": 0.01,\n",
    "          }\n",
    "OUTDIR = \"mnist/learned_\"+hparams[\"model\"]\n",
    "shutil.rmtree(path = OUTDIR, ignore_errors = True) # start fresh each time\n",
    "print('>>>>',OUTDIR)\n",
    "train_and_evaluate(OUTDIR, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist/data/train-images-idx3-ubyte.gz\n",
      "Extracting mnist/data/train-labels-idx1-ubyte.gz\n",
      "Extracting mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting mnist/data/t10k-labels-idx1-ubyte.gz\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'mnist/learned_dnn', '_experimental_distribute': None, '_keep_checkpoint_every_n_hours': 10000, '_eval_distribute': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe0d5096e80>, '_save_checkpoints_steps': None, '_service': None, '_tf_random_seed': None, '_device_fn': None, '_master': '', '_evaluation_master': '', '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_keep_checkpoint_max': 5, '_train_distribute': None, '_task_type': 'worker', '_is_chief': True, '_global_id_in_cluster': 0, '_log_step_count_steps': 100, '_session_creation_timeout_secs': 7200, '_save_checkpoints_secs': 600, '_protocol': None, '_experimental_max_worker_delay_secs': None, '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into mnist/learned_dnn/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.3538442, step = 1\n",
      "INFO:tensorflow:global_step/sec: 88.45\n",
      "INFO:tensorflow:loss = 0.24278404, step = 101 (1.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.082\n",
      "INFO:tensorflow:loss = 0.26634565, step = 201 (0.653 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.106\n",
      "INFO:tensorflow:loss = 0.18414763, step = 301 (0.888 sec)\n",
      "INFO:tensorflow:global_step/sec: 131.614\n",
      "INFO:tensorflow:loss = 0.13431522, step = 401 (0.755 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.613\n",
      "INFO:tensorflow:loss = 0.13544491, step = 501 (0.871 sec)\n",
      "INFO:tensorflow:global_step/sec: 122.305\n",
      "INFO:tensorflow:loss = 0.09129722, step = 601 (0.817 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.005\n",
      "INFO:tensorflow:loss = 0.24258643, step = 701 (0.736 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.351\n",
      "INFO:tensorflow:loss = 0.12547821, step = 801 (0.861 sec)\n",
      "INFO:tensorflow:global_step/sec: 131.591\n",
      "INFO:tensorflow:loss = 0.08966415, step = 901 (0.760 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into mnist/learned_dnn/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-12-07T05:12:32Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from mnist/learned_dnn/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-12-07-05:12:33\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.9632, global_step = 1000, loss = 0.13050275\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: mnist/learned_dnn/model.ckpt-1000\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predictions', 'serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Restoring parameters from mnist/learned_dnn/model.ckpt-1000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: mnist/learned_dnn/export/exporter/temp-b'1575695553'/saved_model.pb\n",
      "INFO:tensorflow:Loss for final step: 0.054607395.\n"
     ]
    }
   ],
   "source": [
    "hparams = {\"model\": \"dnn\",            \n",
    "           \"ksize1\": 5,               \"nfil1\": 10,\n",
    "           \"ksize2\": 5,               \"nfil2\": 20,\n",
    "           \"batch_norm\": False,       \"dprob\": 0.25,\n",
    "           \"train_steps\": 1000,       \"learning_rate\": 0.01,\n",
    "          }\n",
    "OUTDIR = \"mnist/learned_\"+hparams[\"model\"]\n",
    "shutil.rmtree(path = OUTDIR, ignore_errors = True) # start fresh each time\n",
    "\n",
    "train_and_evaluate(OUTDIR, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist/data/train-images-idx3-ubyte.gz\n",
      "Extracting mnist/data/train-labels-idx1-ubyte.gz\n",
      "Extracting mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting mnist/data/t10k-labels-idx1-ubyte.gz\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'mnist/learned_dnn_dropout', '_experimental_distribute': None, '_keep_checkpoint_every_n_hours': 10000, '_eval_distribute': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe0d4e71e80>, '_save_checkpoints_steps': None, '_service': None, '_tf_random_seed': None, '_device_fn': None, '_master': '', '_evaluation_master': '', '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_keep_checkpoint_max': 5, '_train_distribute': None, '_task_type': 'worker', '_is_chief': True, '_global_id_in_cluster': 0, '_log_step_count_steps': 100, '_session_creation_timeout_secs': 7200, '_save_checkpoints_secs': 600, '_protocol': None, '_experimental_max_worker_delay_secs': None, '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into mnist/learned_dnn_dropout/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.3155203, step = 1\n",
      "INFO:tensorflow:global_step/sec: 91.8717\n",
      "INFO:tensorflow:loss = 0.29002923, step = 101 (1.090 sec)\n",
      "INFO:tensorflow:global_step/sec: 139.689\n",
      "INFO:tensorflow:loss = 0.3072261, step = 201 (0.716 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.813\n",
      "INFO:tensorflow:loss = 0.37904888, step = 301 (0.879 sec)\n",
      "INFO:tensorflow:global_step/sec: 132.648\n",
      "INFO:tensorflow:loss = 0.2854817, step = 401 (0.753 sec)\n",
      "INFO:tensorflow:global_step/sec: 120.308\n",
      "INFO:tensorflow:loss = 0.08274948, step = 501 (0.832 sec)\n",
      "INFO:tensorflow:global_step/sec: 125.928\n",
      "INFO:tensorflow:loss = 0.22422127, step = 601 (0.797 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.257\n",
      "INFO:tensorflow:loss = 0.1721133, step = 701 (0.735 sec)\n",
      "INFO:tensorflow:global_step/sec: 129.779\n",
      "INFO:tensorflow:loss = 0.19300418, step = 801 (0.770 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.519\n",
      "INFO:tensorflow:loss = 0.06384071, step = 901 (0.728 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into mnist/learned_dnn_dropout/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-12-07T05:12:43Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from mnist/learned_dnn_dropout/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-12-07-05:12:44\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.9601, global_step = 1000, loss = 0.1568554\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: mnist/learned_dnn_dropout/model.ckpt-1000\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predictions', 'serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Restoring parameters from mnist/learned_dnn_dropout/model.ckpt-1000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: mnist/learned_dnn_dropout/export/exporter/temp-b'1575695564'/saved_model.pb\n",
      "INFO:tensorflow:Loss for final step: 0.061911535.\n"
     ]
    }
   ],
   "source": [
    "hparams = {\"model\": \"dnn_dropout\",            \n",
    "           \"ksize1\": 5,               \"nfil1\": 10,\n",
    "           \"ksize2\": 5,               \"nfil2\": 20,\n",
    "           \"batch_norm\": False,       \"dprob\": 0.25,\n",
    "           \"train_steps\": 1000,       \"learning_rate\": 0.01,\n",
    "          }\n",
    "OUTDIR = \"mnist/learned_\"+hparams[\"model\"]\n",
    "shutil.rmtree(path = OUTDIR, ignore_errors = True) # start fresh each time\n",
    "\n",
    "train_and_evaluate(OUTDIR, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist/data/train-images-idx3-ubyte.gz\n",
      "Extracting mnist/data/train-labels-idx1-ubyte.gz\n",
      "Extracting mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting mnist/data/t10k-labels-idx1-ubyte.gz\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'mnist/learned_cnn', '_experimental_distribute': None, '_keep_checkpoint_every_n_hours': 10000, '_eval_distribute': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe0fdbbc278>, '_save_checkpoints_steps': None, '_service': None, '_tf_random_seed': None, '_device_fn': None, '_master': '', '_evaluation_master': '', '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_keep_checkpoint_max': 5, '_train_distribute': None, '_task_type': 'worker', '_is_chief': True, '_global_id_in_cluster': 0, '_log_step_count_steps': 100, '_session_creation_timeout_secs': 7200, '_save_checkpoints_secs': 600, '_protocol': None, '_experimental_max_worker_delay_secs': None, '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into mnist/learned_cnn/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.2935867, step = 1\n",
      "INFO:tensorflow:global_step/sec: 11.7817\n",
      "INFO:tensorflow:loss = 0.22470497, step = 101 (8.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.9439\n",
      "INFO:tensorflow:loss = 0.17432445, step = 201 (7.722 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4024\n",
      "INFO:tensorflow:loss = 0.034422856, step = 301 (8.774 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.7524\n",
      "INFO:tensorflow:loss = 0.16293985, step = 401 (8.509 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4117\n",
      "INFO:tensorflow:loss = 0.06827125, step = 501 (8.762 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3145\n",
      "INFO:tensorflow:loss = 0.07377939, step = 601 (8.838 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.7459\n",
      "INFO:tensorflow:loss = 0.0050300164, step = 701 (7.845 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.3373\n",
      "INFO:tensorflow:loss = 0.103668325, step = 801 (8.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.7146\n",
      "INFO:tensorflow:loss = 0.025035825, step = 901 (7.865 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into mnist/learned_cnn/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-12-07T05:14:10Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from mnist/learned_cnn/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-12-07-05:14:11\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.9836, global_step = 1000, loss = 0.055612445\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: mnist/learned_cnn/model.ckpt-1000\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predictions', 'serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Restoring parameters from mnist/learned_cnn/model.ckpt-1000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: mnist/learned_cnn/export/exporter/temp-b'1575695652'/saved_model.pb\n",
      "INFO:tensorflow:Loss for final step: 0.08866026.\n"
     ]
    }
   ],
   "source": [
    "hparams = {\"model\": \"cnn\",            \n",
    "           \"ksize1\": 5,               \"nfil1\": 10,\n",
    "           \"ksize2\": 5,               \"nfil2\": 20,\n",
    "           \"batch_norm\": False,       \"dprob\": 0.25,\n",
    "           \"train_steps\": 1000,       \"learning_rate\": 0.01,\n",
    "          }\n",
    "OUTDIR = \"mnist/learned_\"+hparams[\"model\"]\n",
    "shutil.rmtree(path = OUTDIR, ignore_errors = True) # start fresh each time\n",
    "\n",
    "train_and_evaluate(OUTDIR, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
