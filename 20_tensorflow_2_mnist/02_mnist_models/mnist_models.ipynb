{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "PROJECT = \"qwiklabs-gcp-ml-49b827b781ab\"  # REPLACE WITH YOUR PROJECT ID\n",
    "BUCKET = \"qwiklabs-gcp-ml-49b827b781ab\"  # REPLACE WITH YOUR BUCKET NAME\n",
    "REGION = \"us-central1\"  # REPLACE WITH YOUR BUCKET REGION e.g. us-central1\n",
    "\n",
    "# Do not change these\n",
    "os.environ[\"PROJECT\"] = PROJECT\n",
    "os.environ[\"BUCKET\"] = BUCKET\n",
    "os.environ[\"REGION\"] = REGION\n",
    "os.environ[\"IMAGE_URI\"] = os.path.join(\"gcr.io\", PROJECT, \"mnist_trainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, Dense, Dropout, Flatten, MaxPooling2D, Softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH = 28\n",
    "HEIGHT = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(image, label):\n",
    "    \"\"\"Scales images from a 0-255 int range to a 0-1 float range\"\"\"\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255\n",
    "    image = tf.expand_dims(image, -1)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(\n",
    "        data, training=True, buffer_size=5000, batch_size=100, nclasses=10):\n",
    "    \"\"\"Loads MNIST dataset into a tf.data.Dataset\"\"\"\n",
    "    (x_train, y_train), (x_test, y_test) = data\n",
    "    x = x_train if training else x_test\n",
    "    y = y_train if training else y_test\n",
    "    # One-hot encode the classes\n",
    "    y = tf.keras.utils.to_categorical(y, nclasses)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    dataset = dataset.map(scale).batch(batch_size)\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(buffer_size).repeat()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layers(model_type,\n",
    "               nclasses=10,\n",
    "               hidden_layer_1_neurons=400,\n",
    "               hidden_layer_2_neurons=100,\n",
    "               dropout_rate=0.25,\n",
    "               num_filters_1=64,\n",
    "               kernel_size_1=3,\n",
    "               pooling_size_1=2,\n",
    "               num_filters_2=32,\n",
    "               kernel_size_2=3,\n",
    "               pooling_size_2=2):\n",
    "    \"\"\"Constructs layers for a keras model based on a dict of model types.\"\"\"\n",
    "    model_layers = {\n",
    "        'linear': [\n",
    "            Flatten(),\n",
    "            Dense(nclasses),\n",
    "            Softmax()\n",
    "        ],\n",
    "        'dnn': [\n",
    "            Flatten(),\n",
    "            Dense(hidden_layer_1_neurons, activation='relu'),\n",
    "            Dense(hidden_layer_2_neurons, activation='relu'),\n",
    "            Dense(nclasses),\n",
    "            Softmax()\n",
    "        ],\n",
    "        'dnn_dropout': [\n",
    "            Flatten(),\n",
    "            Dense(hidden_layer_1_neurons, activation='relu'),\n",
    "            Dense(hidden_layer_2_neurons, activation='relu'),\n",
    "            Dropout(dropout_rate),\n",
    "            Dense(nclasses),\n",
    "            Softmax()\n",
    "        ],\n",
    "        'cnn': [\n",
    "            Conv2D(num_filters_1, kernel_size=kernel_size_1,\n",
    "                   activation='relu', input_shape=(WIDTH, HEIGHT, 1)),\n",
    "            MaxPooling2D(pooling_size_1),\n",
    "            Conv2D(num_filters_2, kernel_size=kernel_size_2,\n",
    "                   activation='relu'),\n",
    "            MaxPooling2D(pooling_size_2),\n",
    "            Flatten(),\n",
    "            Dense(hidden_layer_1_neurons, activation='relu'),\n",
    "            Dense(hidden_layer_2_neurons, activation='relu'),\n",
    "            Dropout(dropout_rate),\n",
    "            Dense(nclasses),\n",
    "            Softmax()\n",
    "        ]\n",
    "    }\n",
    "    return model_layers[model_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(model_type):\n",
    "    model_layers = get_layers(model_type) \n",
    "\n",
    "    \"\"\"Compiles keras model for image classification.\"\"\"\n",
    "    model = Sequential(model_layers)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, num_epochs, steps_per_epoch, output_dir):\n",
    "\n",
    "    model = build_model(model_type)\n",
    "\n",
    "    \"\"\"Compiles keras model and loads data into it for training.\"\"\"\n",
    "    mnist = tf.keras.datasets.mnist.load_data()\n",
    "    train_data = load_dataset(mnist)\n",
    "    validation_data = load_dataset(mnist, training=False)\n",
    "\n",
    "    callbacks = []\n",
    "    if output_dir:\n",
    "        tensorboard_callback = TensorBoard(log_dir=output_dir)\n",
    "        callbacks = [tensorboard_callback]\n",
    "\n",
    "    history = model.fit(\n",
    "        train_data,\n",
    "        validation_data=validation_data,\n",
    "        epochs=num_epochs,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        verbose=2,\n",
    "        callbacks=callbacks)\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    if output_dir:\n",
    "        export_path = os.path.join(output_dir, 'keras_export')\n",
    "        model.save(export_path, save_format='tf')\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 50 steps, validate for 100 steps\n",
      "Epoch 1/5\n",
      "50/50 - 5s - loss: 1.7332 - accuracy: 0.5036 - val_loss: 1.1921 - val_accuracy: 0.7780\n",
      "Epoch 2/5\n",
      "50/50 - 1s - loss: 0.9730 - accuracy: 0.8144 - val_loss: 0.7970 - val_accuracy: 0.8308\n",
      "Epoch 3/5\n",
      "50/50 - 1s - loss: 0.7351 - accuracy: 0.8384 - val_loss: 0.6437 - val_accuracy: 0.8569\n",
      "Epoch 4/5\n",
      "50/50 - 1s - loss: 0.6302 - accuracy: 0.8484 - val_loss: 0.5590 - val_accuracy: 0.8700\n",
      "Epoch 5/5\n",
      "50/50 - 1s - loss: 0.5363 - accuracy: 0.8692 - val_loss: 0.5074 - val_accuracy: 0.8782\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_68 (Flatten)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_170 (Dense)            multiple                  7850      \n",
      "_________________________________________________________________\n",
      "softmax_68 (Softmax)         multiple                  0         \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "INFO:tensorflow:Assets written to: mnist_trainer/models/linear_191207_093237/keras_export/assets\n"
     ]
    }
   ],
   "source": [
    "model_type = 'linear' # linear / dnn / dnn_dropout / cnn\n",
    "current_time = datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
    "epochs = 5\n",
    "steps_per_epoch = 50\n",
    "output_dir = \"mnist_trainer/models/{}_{}/\".format(model_type, current_time)\n",
    "\n",
    "model_history = train_and_evaluate(image_model, epochs, steps_per_epoch, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 50 steps, validate for 100 steps\n",
      "Epoch 1/5\n",
      "50/50 - 6s - loss: 0.8251 - accuracy: 0.7696 - val_loss: 0.3950 - val_accuracy: 0.8806\n",
      "Epoch 2/5\n",
      "50/50 - 1s - loss: 0.3538 - accuracy: 0.8946 - val_loss: 0.2944 - val_accuracy: 0.9165\n",
      "Epoch 3/5\n",
      "50/50 - 1s - loss: 0.2662 - accuracy: 0.9254 - val_loss: 0.2526 - val_accuracy: 0.9265\n",
      "Epoch 4/5\n",
      "50/50 - 1s - loss: 0.2447 - accuracy: 0.9312 - val_loss: 0.2160 - val_accuracy: 0.9372\n",
      "Epoch 5/5\n",
      "50/50 - 1s - loss: 0.2350 - accuracy: 0.9252 - val_loss: 0.2043 - val_accuracy: 0.9407\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_89 (Flatten)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_221 (Dense)            multiple                  314000    \n",
      "_________________________________________________________________\n",
      "dense_222 (Dense)            multiple                  40100     \n",
      "_________________________________________________________________\n",
      "dense_223 (Dense)            multiple                  1010      \n",
      "_________________________________________________________________\n",
      "softmax_89 (Softmax)         multiple                  0         \n",
      "=================================================================\n",
      "Total params: 355,110\n",
      "Trainable params: 355,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "INFO:tensorflow:Assets written to: mnist_trainer/models/dnn_191207_093539/keras_export/assets\n"
     ]
    }
   ],
   "source": [
    "model_type = 'dnn' # linear / dnn / dnn_dropout / cnn\n",
    "current_time = datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
    "epochs = 5\n",
    "steps_per_epoch = 50\n",
    "output_dir = \"mnist_trainer/models/{}_{}/\".format(model_type, current_time)\n",
    "\n",
    "\n",
    "model_history = train_and_evaluate(image_model, epochs, steps_per_epoch, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 50 steps, validate for 100 steps\n",
      "Epoch 1/5\n",
      "50/50 - 8s - loss: 1.0000 - accuracy: 0.6916 - val_loss: 0.3848 - val_accuracy: 0.8898\n",
      "Epoch 2/5\n",
      "50/50 - 1s - loss: 0.3793 - accuracy: 0.8858 - val_loss: 0.3499 - val_accuracy: 0.8945\n",
      "Epoch 3/5\n",
      "50/50 - 1s - loss: 0.3263 - accuracy: 0.9020 - val_loss: 0.2613 - val_accuracy: 0.9226\n",
      "Epoch 4/5\n",
      "50/50 - 1s - loss: 0.2924 - accuracy: 0.9152 - val_loss: 0.2018 - val_accuracy: 0.9390\n",
      "Epoch 5/5\n",
      "50/50 - 1s - loss: 0.2365 - accuracy: 0.9298 - val_loss: 0.1862 - val_accuracy: 0.9454\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_102 (Flatten)        multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_254 (Dense)            multiple                  314000    \n",
      "_________________________________________________________________\n",
      "dense_255 (Dense)            multiple                  40100     \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_256 (Dense)            multiple                  1010      \n",
      "_________________________________________________________________\n",
      "softmax_102 (Softmax)        multiple                  0         \n",
      "=================================================================\n",
      "Total params: 355,110\n",
      "Trainable params: 355,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "INFO:tensorflow:Assets written to: mnist_trainer/models/dnn_dropout_191207_093603/keras_export/assets\n"
     ]
    }
   ],
   "source": [
    "model_type = 'dnn_dropout' # linear / dnn / dnn_dropout / cnn\n",
    "current_time = datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
    "epochs = 5\n",
    "steps_per_epoch = 50\n",
    "output_dir = \"mnist_trainer/models/{}_{}/\".format(model_type, current_time)\n",
    "\n",
    "model_history = train_and_evaluate(image_model, epochs, steps_per_epoch, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 50 steps, validate for 100 steps\n",
      "Epoch 1/5\n",
      "50/50 - 8s - loss: 1.0630 - accuracy: 0.6692 - val_loss: 0.3409 - val_accuracy: 0.9046\n",
      "Epoch 2/5\n",
      "50/50 - 4s - loss: 0.3096 - accuracy: 0.9062 - val_loss: 0.1724 - val_accuracy: 0.9462\n",
      "Epoch 3/5\n",
      "50/50 - 4s - loss: 0.2010 - accuracy: 0.9370 - val_loss: 0.1295 - val_accuracy: 0.9576\n",
      "Epoch 4/5\n",
      "50/50 - 3s - loss: 0.1730 - accuracy: 0.9484 - val_loss: 0.1073 - val_accuracy: 0.9667\n",
      "Epoch 5/5\n",
      "50/50 - 3s - loss: 0.1489 - accuracy: 0.9532 - val_loss: 0.0904 - val_accuracy: 0.9709\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_52 (Conv2D)           (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_52 (MaxPooling (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 11, 11, 32)        18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_53 (MaxPooling (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_107 (Flatten)        (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_267 (Dense)            (None, 400)               320400    \n",
      "_________________________________________________________________\n",
      "dense_268 (Dense)            (None, 100)               40100     \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_269 (Dense)            (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "softmax_107 (Softmax)        (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 380,614\n",
      "Trainable params: 380,614\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "INFO:tensorflow:Assets written to: mnist_trainer/models/cnn_191207_093621/keras_export/assets\n"
     ]
    }
   ],
   "source": [
    "model_type = 'cnn' # linear / dnn / dnn_dropout / cnn\n",
    "current_time = datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
    "epochs = 5\n",
    "steps_per_epoch = 50\n",
    "output_dir = \"mnist_trainer/models/{}_{}/\".format(model_type, current_time)\n",
    "\n",
    "model_history = train_and_evaluate(image_model, epochs, steps_per_epoch, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
