{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "PROJECT = \"qwiklabs-gcp-ml-49b827b781ab\"  # REPLACE WITH YOUR PROJECT ID\n",
    "BUCKET = \"qwiklabs-gcp-ml-49b827b781ab\"  # REPLACE WITH YOUR BUCKET NAME\n",
    "REGION = \"us-central1\"  # REPLACE WITH YOUR BUCKET REGION e.g. us-central1\n",
    "\n",
    "# Do not change these\n",
    "os.environ[\"PROJECT\"] = PROJECT\n",
    "os.environ[\"BUCKET\"] = BUCKET\n",
    "os.environ[\"REGION\"] = REGION\n",
    "os.environ[\"IMAGE_URI\"] = os.path.join(\"gcr.io\", PROJECT, \"mnist_trainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, Dense, Dropout, Flatten, MaxPooling2D, Softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH = 28\n",
    "HEIGHT = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(image, label):\n",
    "    \"\"\"Scales images from a 0-255 int range to a 0-1 float range\"\"\"\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255\n",
    "    image = tf.expand_dims(image, -1)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(\n",
    "        data, training=True, buffer_size=5000, batch_size=100, nclasses=10):\n",
    "    \"\"\"Loads MNIST dataset into a tf.data.Dataset\"\"\"\n",
    "    (x_train, y_train), (x_test, y_test) = data\n",
    "    x = x_train if training else x_test\n",
    "    y = y_train if training else y_test\n",
    "    # One-hot encode the classes\n",
    "    y = tf.keras.utils.to_categorical(y, nclasses)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    dataset = dataset.map(scale).batch(batch_size)\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(buffer_size).repeat()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layers(model_type,\n",
    "               nclasses=10,\n",
    "               hidden_layer_1_neurons=400,\n",
    "               hidden_layer_2_neurons=100,\n",
    "               dropout_rate=0.25,\n",
    "               num_filters_1=64,\n",
    "               kernel_size_1=3,\n",
    "               pooling_size_1=2,\n",
    "               num_filters_2=32,\n",
    "               kernel_size_2=3,\n",
    "               pooling_size_2=2):\n",
    "    \"\"\"Constructs layers for a keras model based on a dict of model types.\"\"\"\n",
    "    model_layers = {\n",
    "        'linear': [\n",
    "            Flatten(),\n",
    "            Dense(nclasses),\n",
    "            Softmax()\n",
    "        ],\n",
    "        'dnn': [\n",
    "            Flatten(),\n",
    "            Dense(hidden_layer_1_neurons, activation='relu'),\n",
    "            Dense(hidden_layer_2_neurons, activation='relu'),\n",
    "            Dense(nclasses),\n",
    "            Softmax()\n",
    "        ],\n",
    "        'dnn_dropout': [\n",
    "            Flatten(),\n",
    "            Dense(hidden_layer_1_neurons, activation='relu'),\n",
    "            Dense(hidden_layer_2_neurons, activation='relu'),\n",
    "            Dropout(dropout_rate),\n",
    "            Dense(nclasses),\n",
    "            Softmax()\n",
    "        ],\n",
    "        'cnn': [\n",
    "            Conv2D(num_filters_1, kernel_size=kernel_size_1,\n",
    "                   activation='relu', input_shape=(WIDTH, HEIGHT, 1)),\n",
    "            MaxPooling2D(pooling_size_1),\n",
    "            Conv2D(num_filters_2, kernel_size=kernel_size_2,\n",
    "                   activation='relu'),\n",
    "            MaxPooling2D(pooling_size_2),\n",
    "            Flatten(),\n",
    "            Dense(hidden_layer_1_neurons, activation='relu'),\n",
    "            Dense(hidden_layer_2_neurons, activation='relu'),\n",
    "            Dropout(dropout_rate),\n",
    "            Dense(nclasses),\n",
    "            Softmax()\n",
    "        ]\n",
    "    }\n",
    "    return model_layers[model_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(model_type):\n",
    "    model_layers = get_layers(model_type) \n",
    "\n",
    "    \"\"\"Compiles keras model for image classification.\"\"\"\n",
    "    model = Sequential(model_layers)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, num_epochs, steps_per_epoch, output_dir):\n",
    "\n",
    "    model = build_model(model_type)\n",
    "\n",
    "    \"\"\"Compiles keras model and loads data into it for training.\"\"\"\n",
    "    mnist = tf.keras.datasets.mnist.load_data()\n",
    "    train_data = load_dataset(mnist)\n",
    "    validation_data = load_dataset(mnist, training=False)\n",
    "\n",
    "    callbacks = []\n",
    "    if output_dir:\n",
    "        tensorboard_callback = TensorBoard(log_dir=output_dir)\n",
    "        callbacks = [tensorboard_callback]\n",
    "\n",
    "    history = model.fit(\n",
    "        train_data,\n",
    "        validation_data=validation_data,\n",
    "        epochs=num_epochs,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        verbose=2,\n",
    "        callbacks=callbacks)\n",
    "\n",
    "    if output_dir:\n",
    "        export_path = os.path.join(output_dir, 'keras_export')\n",
    "        model.save(export_path, save_format='tf')\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 50 steps, validate for 100 steps\n",
      "Epoch 1/5\n",
      "50/50 - 5s - loss: 1.6879 - accuracy: 0.5494 - val_loss: 1.1528 - val_accuracy: 0.7808\n",
      "Epoch 2/5\n",
      "50/50 - 1s - loss: 0.9790 - accuracy: 0.7970 - val_loss: 0.7845 - val_accuracy: 0.8352\n",
      "Epoch 3/5\n",
      "50/50 - 1s - loss: 0.7361 - accuracy: 0.8362 - val_loss: 0.6376 - val_accuracy: 0.8554\n",
      "Epoch 4/5\n",
      "50/50 - 2s - loss: 0.5891 - accuracy: 0.8646 - val_loss: 0.5558 - val_accuracy: 0.8701\n",
      "Epoch 5/5\n",
      "50/50 - 1s - loss: 0.5355 - accuracy: 0.8714 - val_loss: 0.5054 - val_accuracy: 0.8779\n",
      "INFO:tensorflow:Assets written to: mnist_trainer/models/linear_191207_091507/keras_export/assets\n"
     ]
    }
   ],
   "source": [
    "model_type = 'linear' # linear / dnn / dnn_dropout / cnn\n",
    "current_time = datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
    "epochs = 5\n",
    "steps_per_epoch = 50\n",
    "output_dir = \"mnist_trainer/models/{}_{}/\".format(model_type, current_time)\n",
    "\n",
    "model_history = train_and_evaluate(image_model, epochs, steps_per_epoch, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 50 steps, validate for 100 steps\n",
      "Epoch 1/5\n",
      "50/50 - 6s - loss: 0.7313 - accuracy: 0.7978 - val_loss: 0.3650 - val_accuracy: 0.8916\n",
      "Epoch 2/5\n",
      "50/50 - 1s - loss: 0.3328 - accuracy: 0.8998 - val_loss: 0.2841 - val_accuracy: 0.9157\n",
      "Epoch 3/5\n",
      "50/50 - 1s - loss: 0.2950 - accuracy: 0.9110 - val_loss: 0.2597 - val_accuracy: 0.9234\n",
      "Epoch 4/5\n",
      "50/50 - 1s - loss: 0.2144 - accuracy: 0.9396 - val_loss: 0.2070 - val_accuracy: 0.9376\n",
      "Epoch 5/5\n",
      "50/50 - 1s - loss: 0.2189 - accuracy: 0.9336 - val_loss: 0.1901 - val_accuracy: 0.9420\n",
      "INFO:tensorflow:Assets written to: mnist_trainer/models/dnn_191207_085434/keras_export/assets\n"
     ]
    }
   ],
   "source": [
    "model_type = 'dnn' # linear / dnn / dnn_dropout / cnn\n",
    "current_time = datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
    "epochs = 5\n",
    "steps_per_epoch = 50\n",
    "output_dir = \"mnist_trainer/models/{}_{}/\".format(model_type, current_time)\n",
    "\n",
    "model_layers = get_layers(model_type)\n",
    "image_model = build_model(model_layers)\n",
    "model_history = train_and_evaluate(image_model, epochs, steps_per_epoch, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 50 steps, validate for 100 steps\n",
      "Epoch 1/5\n",
      "50/50 - 6s - loss: 0.8985 - accuracy: 0.7270 - val_loss: 0.3747 - val_accuracy: 0.8949\n",
      "Epoch 2/5\n",
      "50/50 - 1s - loss: 0.3998 - accuracy: 0.8820 - val_loss: 0.2966 - val_accuracy: 0.9123\n",
      "Epoch 3/5\n",
      "50/50 - 1s - loss: 0.2896 - accuracy: 0.9130 - val_loss: 0.2606 - val_accuracy: 0.9218\n",
      "Epoch 4/5\n",
      "50/50 - 1s - loss: 0.2889 - accuracy: 0.9160 - val_loss: 0.2048 - val_accuracy: 0.9413\n",
      "Epoch 5/5\n",
      "50/50 - 1s - loss: 0.2338 - accuracy: 0.9306 - val_loss: 0.1799 - val_accuracy: 0.9460\n",
      "INFO:tensorflow:Assets written to: mnist_trainer/models/dnn_dropout_191207_085449/keras_export/assets\n"
     ]
    }
   ],
   "source": [
    "model_type = 'dnn_dropout' # linear / dnn / dnn_dropout / cnn\n",
    "current_time = datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
    "epochs = 5\n",
    "steps_per_epoch = 50\n",
    "output_dir = \"mnist_trainer/models/{}_{}/\".format(model_type, current_time)\n",
    "\n",
    "model_layers = get_layers(model_type)\n",
    "image_model = build_model(model_layers)\n",
    "model_history = train_and_evaluate(image_model, epochs, steps_per_epoch, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 50 steps, validate for 100 steps\n",
      "Epoch 1/5\n",
      "50/50 - 8s - loss: 0.9803 - accuracy: 0.6892 - val_loss: 0.3236 - val_accuracy: 0.8929\n",
      "Epoch 2/5\n",
      "50/50 - 3s - loss: 0.2832 - accuracy: 0.9120 - val_loss: 0.1647 - val_accuracy: 0.9491\n",
      "Epoch 3/5\n",
      "50/50 - 3s - loss: 0.2015 - accuracy: 0.9376 - val_loss: 0.1164 - val_accuracy: 0.9644\n",
      "Epoch 4/5\n",
      "50/50 - 3s - loss: 0.1563 - accuracy: 0.9532 - val_loss: 0.0893 - val_accuracy: 0.9709\n",
      "Epoch 5/5\n",
      "50/50 - 3s - loss: 0.1423 - accuracy: 0.9534 - val_loss: 0.0887 - val_accuracy: 0.9719\n",
      "INFO:tensorflow:Assets written to: mnist_trainer/models/cnn_191207_085504/keras_export/assets\n"
     ]
    }
   ],
   "source": [
    "model_type = 'cnn' # linear / dnn / dnn_dropout / cnn\n",
    "current_time = datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
    "epochs = 5\n",
    "steps_per_epoch = 50\n",
    "output_dir = \"mnist_trainer/models/{}_{}/\".format(model_type, current_time)\n",
    "\n",
    "model_layers = get_layers(model_type)\n",
    "image_model = build_model(model_layers)\n",
    "model_history = train_and_evaluate(image_model, epochs, steps_per_epoch, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
